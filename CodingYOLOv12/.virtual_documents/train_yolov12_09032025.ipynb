














!nvidia-smi


import torch
print("CUDA Available:", torch.cuda.is_available())
print("Torch Version:", torch.__version__)
print("GPU Name:", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "No GPU detected")






# 1. Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# 2. Di chuy·ªÉn ƒë·∫øn th∆∞ m·ª•c b·∫°n mu·ªën l∆∞u trong Drive
%cd /content/drive/MyDrive


!pip install flash-attn --only-binary :all:





!git clone https://github.com/sunsmarterjie/yolov12.git


!pip install git+https://github.com/sunsmarterjie/yolov12.git roboflow supervision flash-attn





!pip install roboflow supervision flash-attn==2.0.2


!nvcc -V


pip install flash-attn==2.0.2



import os
print(os.getcwd())


from roboflow import Roboflow
import os
import shutil

%cd "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/Dataset/"


rf = Roboflow(api_key="JutTY4tTGxWHjEqJiZNb")
project = rf.workspace("nhan-dien-hanh-vi-trong-lop-hoc").project("student-behavior-recognition")
version = project.version(2)
dataset = version.download("yolov12")

# # T·∫£i version 3 c·ªßa dataset v·ªõi format YOLOv5
print(f"D·ªØ li·ªáu ƒë√£ t·∫£i v·ªÅ: {dataset.location}")

# ƒê∆∞·ªùng d·∫´n l∆∞u tr·ªØ trong Google Drive
# drive_dataset_path = '/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/Dataset/'

# # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a t·ªìn t·∫°i
# os.makedirs(drive_dataset_path, exist_ok=True)

# # Sao ch√©p to√†n b·ªô th∆∞ m·ª•c dataset sang Google Drive
# shutil.copytree(dataset.location, drive_dataset_path, dirs_exist_ok=True)

# print(f"ƒê√£ sao ch√©p dataset ƒë·∫øn: {drive_dataset_path}")

# # In ra c·∫•u tr√∫c th∆∞ m·ª•c ƒë·ªÉ ki·ªÉm tra
# import subprocess
# print("\nC·∫•u tr√∫c th∆∞ m·ª•c:")
# subprocess.run(f"tree {drive_dataset_path}", shell=True)


# In ra c·∫•u tr√∫c th∆∞ m·ª•c ƒë·ªÉ ki·ªÉm tra
import subprocess
print("\nC·∫•u tr√∫c th∆∞ m·ª•c:")
subprocess.run(f"tree {drive_dataset_path}", shell=True)


!ls {drive_dataset_path}





!sed -i '$d' {drive_dataset_path}/data.yaml
!echo -e "test: ../test/images\ntrain: ../train/images\nval: ../valid/images" >> {drive_dataset_path}/data.yaml


!cat {drive_dataset_path}/data.yaml








data_yaml_path = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/Dataset/Student-Behavior-Recognition-2/data.yaml"





import os
import yaml
from collections import defaultdict
from PIL import Image
import matplotlib.pyplot as plt
import cv2
import random
import seaborn as sns

def analyze_dataset(yaml_path):
    # 1. ƒê·ªçc v√† in th√¥ng tin YAML
    print("1. ƒê·ªçc file YAML:")
    with open(yaml_path, 'r') as f:
        data = yaml.safe_load(f)
    # print(f"N·ªôi dung YAML: {data}")

    root_path = os.path.dirname(yaml_path)
    class_names = data['names']
    print(f"\nClasses: {class_names}")

    # 2. Ki·ªÉm tra c·∫•u tr√∫c th∆∞ m·ª•c
    print("\n2. C·∫•u tr√∫c th∆∞ m·ª•c:")
    print(f"Root path: {root_path}")
    print("N·ªôi dung root:")
    print(os.listdir(root_path))

    # 3. Thu th·∫≠p th·ªëng k√™
    stats = {
        'train': defaultdict(lambda: {'count': 0, 'sizes': [], 'examples': []}),
        'valid': defaultdict(lambda: {'count': 0, 'sizes': [], 'examples': []}),
        'test': defaultdict(lambda: {'count': 0, 'sizes': [], 'examples': []})
    }

    for split in ['train', 'valid', 'test']:
        images_dir = os.path.join(root_path, split, 'images')
        labels_dir = os.path.join(root_path, split, 'labels')

        # print(f"\nX·ª≠ l√Ω {split} set:")
        # print(f"Images dir: {images_dir}")
        # print(f"Labels dir: {labels_dir}")

        if not os.path.exists(images_dir) or not os.path.exists(labels_dir):
            print(f"Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c images ho·∫∑c labels cho {split}")
            continue

        # In m·∫´u n·ªôi dung labels
        label_files = os.listdir(labels_dir)
        if label_files:
            print("\nM·∫´u n·ªôi dung labels:")
            for label_file in label_files[:2]:
                # print(f"\nFile: {label_file}")
                with open(os.path.join(labels_dir, label_file), 'r') as f:
                    print(f.read())

        # X·ª≠ l√Ω t·ª´ng ·∫£nh
        for img_file in os.listdir(images_dir):
            if img_file.endswith(('.jpg', '.jpeg', '.png')):
                img_path = os.path.join(images_dir, img_file)
                label_path = os.path.join(labels_dir, img_file.rsplit('.', 1)[0] + '.txt')

                if os.path.exists(label_path):
                    try:
                        img = cv2.imread(img_path)
                        if img is None:
                            print(f"Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {img_path}")
                            continue
                        height, width = img.shape[:2]

                        with open(label_path, 'r') as f:
                            label_content = f.read().strip()
                            if label_content:
                                for line in label_content.split('\n'):
                                    try:
                                        parts = line.strip().split()
                                        if len(parts) == 5:
                                            class_id = int(parts[0])
                                            if class_id < len(class_names):
                                                class_name = class_names[class_id]
                                                stats[split][class_name]['count'] += 1
                                                stats[split][class_name]['sizes'].append((width, height))
                                                stats[split][class_name]['examples'].append((img_path, line))
                                        # else:
                                        #     # print(f"Format label kh√¥ng ƒë√∫ng: {line}")
                                    except ValueError as e:
                                        print(f"L·ªói parse label: {str(e)}")
                    except Exception as e:
                        print(f"L·ªói x·ª≠ l√Ω {img_path}: {str(e)}")

    # 4. Visualize k·∫øt qu·∫£
    # 4.1 Bi·ªÉu ƒë·ªì s·ªë l∆∞·ª£ng objects
    plt.figure(figsize=(12, 6))
    splits = list(stats.keys())
    x = np.arange(len(class_names))
    width = 0.25

    colors = ['#2ecc71', '#3498db', '#e74c3c']
    for i, (split, color) in enumerate(zip(splits, colors)):
        counts = [stats[split][class_name]['count'] for class_name in class_names]
        plt.bar(x + i*width, counts, width, label=split, color=color)

    plt.xlabel('Classes', fontsize=12)
    plt.ylabel('S·ªë l∆∞·ª£ng objects', fontsize=12)
    plt.title('Ph√¢n b·ªë s·ªë l∆∞·ª£ng objects', fontsize=14)
    plt.xticks(x + width, class_names, rotation=45)
    plt.legend()
    plt.tight_layout()
    plt.show()

    # 4.2 Hi·ªÉn th·ªã ·∫£nh m·∫´u
    def plot_samples(split, class_name, num_samples=3):
        examples = stats[split][class_name]['examples']
        if not examples:
            return

        samples = random.sample(examples, min(num_samples, len(examples)))
        fig, axes = plt.subplots(1, len(samples), figsize=(15, 5))
        if len(samples) == 1:
            axes = [axes]

        for ax, (img_path, label) in zip(axes, samples):
            img = cv2.imread(img_path)
            if img is None:
                print(f"Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {img_path}")
                continue

            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            height, width = img.shape[:2]

            try:
                parts = label.strip().split()
                if len(parts) == 5:
                    _, x_center, y_center, w, h = map(float, parts)

                    x1 = int((x_center - w/2) * width)
                    y1 = int((y_center - h/2) * height)
                    x2 = int((x_center + w/2) * width)
                    y2 = int((y_center + h/2) * height)

                    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
            except Exception as e:
                print(f"L·ªói v·∫Ω bbox: {str(e)}")

            ax.imshow(img)
            ax.axis('off')
            ax.set_title(f'{split} - {class_name}')

        plt.tight_layout()
        plt.show()

    print("\nHi·ªÉn th·ªã ·∫£nh m·∫´u:")
    for class_name in class_names:
        for split in splits:
            if stats[split][class_name]['count'] > 0:
                plot_samples(split, class_name)

    # 4.3 Bi·ªÉu ƒë·ªì k√≠ch th∆∞·ªõc ·∫£nh
    plt.figure(figsize=(10, 6))
    for split, color in zip(splits, colors):
        all_sizes = []
        for class_name in class_names:
            all_sizes.extend(stats[split][class_name]['sizes'])
        if all_sizes:
            widths, heights = zip(*all_sizes)
            plt.scatter(widths, heights, alpha=0.6, label=split, color=color)

    plt.xlabel('Width (pixels)')
    plt.ylabel('Height (pixels)')
    plt.title('Ph√¢n b·ªë k√≠ch th∆∞·ªõc ·∫£nh')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

    # 5. In th·ªëng k√™ chi ti·∫øt
    print("\nTh·ªëng k√™ chi ti·∫øt:")
    for split in stats:
        print(f"\n=== {split.upper()} ===")
        total = 0
        for class_name in stats[split]:
            count = stats[split][class_name]['count']
            sizes = stats[split][class_name]['sizes']
            total += count

            if count > 0:
                avg_width = np.mean([s[0] for s in sizes])
                avg_height = np.mean([s[1] for s in sizes])
                print(f"\nClass: {class_name}")
                print(f"- S·ªë l∆∞·ª£ng: {count}")
                print(f"- K√≠ch th∆∞·ªõc trung b√¨nh: {avg_width:.0f}x{avg_height:.0f}")

        print(f"\nT·ªïng s·ªë objects: {total}")
analyze_dataset(data_yaml_path)





import os
import yaml
import cv2
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import random
from collections import defaultdict

def analyze_dataset(yaml_path):
    """Ph√¢n t√≠ch dataset YOLO v·ªõi c√°c t√≠nh nƒÉng:
    - Ki·ªÉm tra label h·ª£p l·ªá
    - Th·ªëng k√™ k√≠ch th∆∞·ªõc bounding box
    - Ph√°t hi·ªán b·∫•t th∆∞·ªùng
    - Tr·ª±c quan h√≥a d·ªØ li·ªáu
    """
    
    # 1. ƒê·ªçc file c·∫•u h√¨nh YAML
    with open(yaml_path, 'r') as f:
        data = yaml.safe_load(f)
    root_dir = os.path.dirname(yaml_path)
    class_names = data['names']
    print(f"‚úÖ ƒê√£ ƒë·ªçc c·∫•u h√¨nh t·ª´ {yaml_path}")
    print(f"üì¶ S·ªë l·ªõp: {len(class_names)} - T√™n l·ªõp: {class_names}")

    # 2. Kh·ªüi t·∫°o c·∫•u tr√∫c l∆∞u tr·ªØ th·ªëng k√™
    stats = {
        split: {
            cls: {
                'count': 0,
                'widths': [],
                'heights': [],
                'areas': [],
                'examples': [],
                'invalid': 0
            } for cls in class_names
        } for split in ['train', 'valid', 'test']
    }

    # 3. Duy·ªát qua c√°c t·∫≠p d·ªØ li·ªáu
    for split in ['train', 'valid', 'test']:
        img_dir = os.path.join(root_dir, split, 'images')
        label_dir = os.path.join(root_dir, split, 'labels')

        if not os.path.exists(img_dir):
            print(f"‚õî Thi·∫øu th∆∞ m·ª•c ·∫£nh {split}")
            continue

        # 4. X·ª≠ l√Ω t·ª´ng ·∫£nh
        for img_file in os.listdir(img_dir):
            if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                continue

            img_path = os.path.join(img_dir, img_file)
            label_path = os.path.join(label_dir, os.path.splitext(img_file)[0] + '.txt')

            if not os.path.exists(label_path):
                continue

            try:
                # 5. ƒê·ªçc k√≠ch th∆∞·ªõc ·∫£nh
                img = cv2.imread(img_path)
                if img is None:
                    print(f"‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh: {img_path}")
                    continue
                img_h, img_w = img.shape[:2]

                # 6. X·ª≠ l√Ω t·ª´ng label
                with open(label_path, 'r') as f:
                    for line in f:
                        line = line.strip()
                        if not line:
                            continue

                        parts = line.split()
                        # 7. Validate ƒë·ªãnh d·∫°ng label
                        if len(parts) != 5:
                            stats[split][class_names[0]]['invalid'] += 1  # Gi·∫£ ƒë·ªãnh l·ªõp ƒë·∫ßu ti√™n cho l·ªói
                            continue

                        try:
                            # 8. Chuy·ªÉn ƒë·ªïi v√† ki·ªÉm tra t·ªça ƒë·ªô
                            class_id, xc, yc, w, h = map(float, parts)
                            if not (0 <= xc <= 1 and 0 <= yc <= 1 and 0 <= w <= 1 and 0 <= h <= 1):
                                stats[split][class_names[int(class_id)]]['invalid'] += 1
                                continue

                            # 9. T√≠nh to√°n k√≠ch th∆∞·ªõc th·ª±c t·∫ø
                            box_w = w * img_w
                            box_h = h * img_h
                            area = box_w * box_h

                            # 10. C·∫≠p nh·∫≠t th·ªëng k√™
                            cls_name = class_names[int(class_id)]
                            stats[split][cls_name]['count'] += 1
                            stats[split][cls_name]['widths'].append(box_w)
                            stats[split][cls_name]['heights'].append(box_h)
                            stats[split][cls_name]['areas'].append(area)
                            stats[split][cls_name]['examples'].append(img_path)

                        except (ValueError, IndexError) as e:
                            print(f"L·ªói x·ª≠ l√Ω label: {str(e)}")
                            continue

            except Exception as e:
                print(f"L·ªói x·ª≠ l√Ω ·∫£nh {img_path}: {str(e)}")

    # 11. Ph√¢n t√≠ch v√† hi·ªÉn th·ªã k·∫øt qu·∫£
    _visualize_distributions(stats, class_names)
    _generate_report(stats, class_names)

def _visualize_distributions(stats, classes):
    """Tr·ª±c quan h√≥a ph√¢n b·ªë k√≠ch th∆∞·ªõc bounding box"""
    n_classes = len(classes)
    n_cols = 2  # S·ªë c·ªôt t√πy ch·ªçn
    n_rows = (n_classes + n_cols - 1) // n_cols  # T√≠nh s·ªë h√†ng c·∫ßn thi·∫øt
    
    plt.figure(figsize=(14, 5*n_rows))  # ƒêi·ªÅu ch·ªânh k√≠ch th∆∞·ªõc theo s·ªë h√†ng
    
    # V·∫Ω bi·ªÉu ƒë·ªì cho t·ª´ng l·ªõp
    for idx, cls in enumerate(classes, 1):
        plt.subplot(n_rows, n_cols, idx)  # S·ª≠a th√†nh grid ƒë·ªông
        
        all_widths = []
        all_heights = []
        for split in ['train', 'valid', 'test']:
            all_widths.extend(stats[split][cls]['widths'])
            all_heights.extend(stats[split][cls]['heights'])
        
        if all_widths:
            sns.histplot(x=all_widths, kde=True, color='blue', label='Width')
            sns.histplot(x=all_heights, kde=True, color='red', label='Height')
            plt.title(f'Ph√¢n b·ªë k√≠ch th∆∞·ªõc - {cls}')
            plt.xlabel('Pixel')
            plt.legend()
    
    plt.tight_layout()
    plt.show()
    
    # Bi·ªÉu ƒë·ªì boxplot
    plt.figure(figsize=(12, 6))
    data = []
    labels = []
    for cls in classes:
        for split in ['train', 'valid', 'test']:
            if stats[split][cls]['areas']:
                data.append(stats[split][cls]['areas'])
                labels.append(f"{cls}_{split}")
    
    plt.boxplot(data, vert=False, patch_artist=True)
    plt.yticks(np.arange(1, len(labels)+1), labels)
    plt.title('Ph√¢n b·ªë di·ªán t√≠ch bounding box')
    plt.xlabel('Di·ªán t√≠ch (pixel¬≤)')
    plt.show()

def _generate_report(stats, classes):
    """T·∫°o b√°o c√°o chi ti·∫øt"""
    print("\nüìà B√ÅO C√ÅO CHI TI·∫æT")
    
    for split in ['train', 'valid', 'test']:
        print(f"\nüîç {split.upper()}")
        total = 0
        
        for cls in classes:
            cls_stats = stats[split][cls]
            if cls_stats['count'] == 0:
                continue
                
            # T√≠nh c√°c ch·ªâ s·ªë th·ªëng k√™
            widths = cls_stats['widths']
            heights = cls_stats['heights']
            areas = cls_stats['areas']
            
            report = {
                'count': cls_stats['count'],
                'width': {
                    'min': np.min(widths),
                    'max': np.max(widths),
                    'mean': np.mean(widths),
                    'median': np.median(widths)
                },
                'height': {
                    'min': np.min(heights),
                    'max': np.max(heights),
                    'mean': np.mean(heights),
                    'median': np.median(heights)
                },
                'area': {
                    'min': np.min(areas),
                    'max': np.max(areas),
                    'mean': np.mean(areas)
                },
                'invalid': cls_stats['invalid']
            }

            # In b√°o c√°o
            print(f"\nüè∑Ô∏è L·ªõp: {cls}")
            print(f"   - S·ªë l∆∞·ª£ng: {report['count']}")
            print(f"   - Chi·ªÅu r·ªông (px):")
            print(f"     Min: {report['width']['min']:.1f} | Max: {report['width']['max']:.1f}")
            print(f"     Trung b√¨nh: {report['width']['mean']:.1f} | Median: {report['width']['median']:.1f}")
            print(f"   - Chi·ªÅu cao (px):")
            print(f"     Min: {report['height']['min']:.1f} | Max: {report['height']['max']:.1f}")
            print(f"     Trung b√¨nh: {report['height']['mean']:.1f} | Median: {report['height']['median']:.1f}")
            print(f"   - Di·ªán t√≠ch (px¬≤):")
            print(f"     Min: {report['area']['min']:.1f} | Max: {report['area']['max']:.1f}")
            print(f"     Trung b√¨nh: {report['area']['mean']:.1f}")
            print(f"   - Label kh√¥ng h·ª£p l·ªá: {report['invalid']}")

            total += report['count']
        
        print(f"\nT·ªïng s·ªë objects: {total}")

# Ch·∫°y ch∆∞∆°ng tr√¨nh
if __name__ == "__main__":
    analyze_dataset(data_yaml_path)





import os
import shutil
import yaml
from collections import defaultdict

def export_invalid_labels(yaml_path, output_dir):
    """
    Export c√°c ·∫£nh v√† label kh√¥ng h·ª£p l·ªá v√†o th∆∞ m·ª•c ri√™ng
    ƒê·ªìng th·ªùi t·∫°o b√°o c√°o chi ti·∫øt
    """
    # 1. ƒê·ªçc c·∫•u h√¨nh dataset
    with open(yaml_path, 'r') as f:
        data = yaml.safe_load(f)
    root_dir = os.path.dirname(yaml_path)
    class_names = data['names']
    
    # 2. T·∫°o th∆∞ m·ª•c output
    invalid_dir = os.path.join(output_dir, 'invalid')
    os.makedirs(os.path.join(invalid_dir, 'images'), exist_ok=True)
    os.makedirs(os.path.join(invalid_dir, 'labels'), exist_ok=True)
    
    report = {
        'total_images': 0,
        'invalid_images': 0,
        'details': []
    }
    
    # 3. Duy·ªát qua c√°c t·∫≠p d·ªØ li·ªáu
    for split in ['train', 'valid', 'test']:
        img_dir = os.path.join(root_dir, split, 'images')
        label_dir = os.path.join(root_dir, split, 'labels')
        
        if not os.path.exists(img_dir):
            continue
            
        # 4. X·ª≠ l√Ω t·ª´ng ·∫£nh
        for img_file in os.listdir(img_dir):
            report['total_images'] += 1
            img_path = os.path.join(img_dir, img_file)
            label_path = os.path.join(label_dir, os.path.splitext(img_file)[0] + '.txt')
            
            invalid_reasons = []
            
            # 5. Ki·ªÉm tra label
            if not os.path.exists(label_path):
                invalid_reasons.append('Missing label file')
            else:
                with open(label_path, 'r') as f:
                    lines = f.readlines()
                    if not lines:
                        invalid_reasons.append('Empty label file')
                    
                    for line_idx, line in enumerate(lines, 1):
                        line = line.strip()
                        parts = line.split()
                        
                        # Ki·ªÉm tra ƒë·ªãnh d·∫°ng
                        if len(parts) != 5:
                            invalid_reasons.append(f'Line {line_idx}: Invalid format')
                            continue
                            
                        try:
                            # Validate gi√° tr·ªã
                            class_id, xc, yc, w, h = map(float, parts)
                            if not (0 <= xc <= 1 and 0 <= yc <= 1 and 0 <= w <= 1 and 0 <= h <= 1):
                                invalid_reasons.append(f'Line {line_idx}: Invalid coordinates')
                            
                            # Ki·ªÉm tra class ID
                            if int(class_id) >= len(class_names):
                                invalid_reasons.append(f'Line {line_idx}: Invalid class ID {class_id}')
                                
                        except ValueError:
                            invalid_reasons.append(f'Line {line_idx}: Conversion error')
            
            # 6. N·∫øu c√≥ l·ªói, copy sang th∆∞ m·ª•c invalid
            if invalid_reasons:
                report['invalid_images'] += 1
                # Copy ·∫£nh
                shutil.copy(img_path, os.path.join(invalid_dir, 'images', img_file))
                # Copy label (n·∫øu t·ªìn t·∫°i)
                if os.path.exists(label_path):
                    shutil.copy(label_path, os.path.join(invalid_dir, 'labels', os.path.basename(label_path)))
                
                # Ghi log l·ªói
                report['details'].append({
                    'image': img_path,
                    'reasons': invalid_reasons
                })
    
    # 7. T·∫°o b√°o c√°o
    with open(os.path.join(output_dir, 'invalid_report.txt'), 'w') as f:
        f.write(f"T·ªïng s·ªë ·∫£nh ƒë√£ ki·ªÉm tra: {report['total_images']}\n")
        f.write(f"S·ªë ·∫£nh c√≥ label kh√¥ng h·ª£p l·ªá: {report['invalid_images']}\n\n")
        
        f.write("Chi ti·∫øt c√°c l·ªói:\n")
        for entry in report['details']:
            f.write(f"\n·∫¢nh: {entry['image']}\n")
            for reason in entry['reasons']:
                f.write(f" - {reason}\n")
    
    print(f"‚úÖ ƒê√£ export {report['invalid_images']} ·∫£nh l·ªói v√†o: {invalid_dir}")
    print(f"‚úÖ B√°o c√°o chi ti·∫øt: {os.path.join(output_dir, 'invalid_report.txt')}")

# S·ª≠ d·ª•ng
output_directory = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/yolov12s09032025_ver-dataset2/_ver1"
export_invalid_labels(data_yaml_path, output_directory)





import os
import cv2

def draw_bounding_boxes_for_image(image_path, label_path):
    """
    ƒê·ªçc m·ªôt ·∫£nh v√† file label t∆∞∆°ng ·ª©ng, sau ƒë√≥ v·∫Ω bounding box l√™n ·∫£nh.
    
    ƒê·ªãnh d·∫°ng file label: m·ªói d√≤ng c√≥ 5 gi√° tr·ªã:
      class_id, xc, yc, w, h
    Trong ƒë√≥:
      - xc, yc: t·ªça ƒë·ªô t√¢m bounding box (ƒë√£ chu·∫©n h√≥a, gi√° tr·ªã t·ª´ 0 ƒë·∫øn 1)
      - w, h: chi·ªÅu r·ªông v√† chi·ªÅu cao (ƒë√£ chu·∫©n h√≥a)
    Tr·∫£ v·ªÅ ·∫£nh ƒë√£ v·∫Ω bounding box (d∆∞·ªõi ƒë·ªãnh d·∫°ng BGR)
    """
    # ƒê·ªçc ·∫£nh
    image = cv2.imread(image_path)
    if image is None:
        print("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh:", image_path)
        return None

    height, width = image.shape[:2]

    # Ki·ªÉm tra s·ª± t·ªìn t·∫°i c·ªßa file label
    if not os.path.exists(label_path):
        print("Kh√¥ng t√¨m th·∫•y file label cho ·∫£nh:", image_path)
        return image  # Tr·∫£ v·ªÅ ·∫£nh g·ªëc n·∫øu kh√¥ng c√≥ label

    # ƒê·ªçc file label
    with open(label_path, 'r') as f:
        lines = f.readlines()

    # V·∫Ω bounding box cho t·ª´ng d√≤ng annotation
    for line in lines:
        line = line.strip()
        if not line:
            continue  # B·ªè qua d√≤ng tr·ªëng

        parts = line.split()
        if len(parts) != 5:
            print(f"ƒê·ªãnh d·∫°ng kh√¥ng h·ª£p l·ªá label_id:{label_path}, gi√° tr·ªã: ", line)
            continue

        try:
            class_id, xc, yc, w, h = map(float, parts)
        except ValueError:
            print("L·ªói chuy·ªÉn ƒë·ªïi s·ªë trong d√≤ng:", line)
            continue

        # Chuy·ªÉn t·ªça ƒë·ªô chu·∫©n h√≥a sang t·ªça ƒë·ªô pixel
        x_min = int((xc - w/2) * width)
        y_min = int((yc - h/2) * height)
        x_max = int((xc + w/2) * width)
        y_max = int((yc + h/2) * height)

        # V·∫Ω bounding box v√† nh√£n (d√πng class_id)
        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)
        label_text = f"Class {int(class_id)}"
        cv2.putText(image, label_text, (x_min, y_min - 10), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    return image

def process_folder(image_folder, label_folder, output_folder):
    """
    Duy·ªát qua folder ch·ª©a ·∫£nh v√† ƒë·ªëi chi·∫øu file label t∆∞∆°ng ·ª©ng t·ª´ folder label.
    ·∫¢nh v√† label ƒë∆∞·ª£c coi l√† t∆∞∆°ng ·ª©ng n·∫øu t√™n file (kh√¥ng ph·∫ßn m·ªü r·ªông) tr√πng nhau.
    ·∫¢nh ƒë√£ x·ª≠ l√Ω (c√≥ bounding box) s·∫Ω ƒë∆∞·ª£c l∆∞u v√†o folder output.
    """
    os.makedirs(output_folder, exist_ok=True)

    for filename in os.listdir(image_folder):
        # Ki·ªÉm tra file c√≥ ph·∫£i l√† ·∫£nh kh√¥ng d·ª±a v√†o ph·∫ßn m·ªü r·ªông
        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):
            image_path = os.path.join(image_folder, filename)
            base, _ = os.path.splitext(filename)
            label_file = base + ".txt"
            label_path = os.path.join(label_folder, label_file)
            print(f"ƒêang x·ª≠ l√Ω ·∫£nh: {image_path}")
            processed_image = draw_bounding_boxes_for_image(image_path, label_path)
            if processed_image is not None:
                output_path = os.path.join(output_folder, filename)
                cv2.imwrite(output_path, processed_image)
                print(f"ƒê√£ l∆∞u ·∫£nh: {output_path}")
        else:
            print("B·ªè qua file kh√¥ng ph·∫£i ·∫£nh:", filename)

if __name__ == "__main__":
    # C·∫≠p nh·∫≠t ƒë∆∞·ªùng d·∫´n t·ªõi folder ch·ª©a ·∫£nh, folder ch·ª©a label v√† folder export
    image_folder = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/yolov12s09032025_ver-dataset2/_ver1/invalid/images"
    label_folder = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/yolov12s09032025_ver-dataset2/_ver1/invalid/labels"
    output_folder = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/yolov12s09032025_ver-dataset2/_ver1/invalid/visualize_images"
    
    process_folder(image_folder, label_folder, output_folder)






import os
import yaml
import cv2
import numpy as np
import shutil
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from collections import defaultdict
from imgaug import augmenters as iaa

# ========================== C·∫§U H√åNH ==========================
MIN_AREA = 100      # Di·ªán t√≠ch t·ªëi thi·ªÉu (pixel¬≤)
MIN_DIM = 10        # K√≠ch th∆∞·ªõc t·ªëi thi·ªÉu (width/height)
AUGMENT_CLASSES = [ # C√°c l·ªõp c·∫ßn tƒÉng c∆∞·ªùng d·ªØ li·ªáu
    "drinking", 
    "raising_hand"
]
# ===============================================================

def analyze_and_improve_dataset(yaml_path, output_dir):
    """X·ª≠ l√Ω to√†n b·ªô pipeline: ph√¢n t√≠ch, l√†m s·∫°ch, c√¢n b·∫±ng d·ªØ li·ªáu"""
    
    # 1. ƒê·ªçc c·∫•u h√¨nh dataset
    with open(yaml_path, 'r') as f:
        data = yaml.safe_load(f)
    root_dir = os.path.dirname(yaml_path)
    class_names = data['names']
    class_ids = {name:i for i, name in enumerate(class_names)}
    
    # 2. Kh·ªüi t·∫°o th∆∞ m·ª•c output
    for split in ['train', 'valid', 'test']:
        os.makedirs(os.path.join(output_dir, split, 'images'), exist_ok=True)
        os.makedirs(os.path.join(output_dir, split, 'labels'), exist_ok=True)

    # 3. Pipeline x·ª≠ l√Ω
    all_files = []
    stats = defaultdict(lambda: defaultdict(int))
    
    # 4. X·ª≠ l√Ω t·ª´ng t·∫≠p d·ªØ li·ªáu g·ªëc
    for split in ['train', 'valid', 'test']:
        img_dir = os.path.join(root_dir, split, 'images')
        label_dir = os.path.join(root_dir, split, 'labels')
        
        if not os.path.exists(img_dir):
            continue
            
        for img_file in os.listdir(img_dir):
            if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                continue
                
            img_path = os.path.join(img_dir, img_file)
            label_path = os.path.join(label_dir, os.path.splitext(img_file)[0] + '.txt')
            
            # 5. L·ªçc v√† chu·∫©n h√≥a labels
            valid_labels, class_dist = process_labels(
                label_path, 
                img_path, 
                class_ids,
                stats[split]
            )
            
            if valid_labels:
                # 6. L∆∞u d·ªØ li·ªáu ƒë√£ l·ªçc
                save_clean_data(
                    img_path,
                    valid_labels,
                    os.path.join(output_dir, split),
                    img_file
                )
                all_files.append((split, class_dist))
                
    # 7. C√¢n b·∫±ng d·ªØ li·ªáu
    balance_dataset(output_dir, class_names, all_files)
    
    # 8. Ph√¢n chia l·∫°i d·ªØ li·ªáu
    stratified_split(output_dir, class_names)
    
    return stats

def process_labels(label_path, img_path, class_ids, stats):
    """X·ª≠ l√Ω v√† l·ªçc labels"""
    valid_labels = []
    class_dist = defaultdict(int)
    
    try:
        img = cv2.imread(img_path)
        if img is None:
            return [], {}
            
        h, w = img.shape[:2]
        
        with open(label_path, 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                
                parts = line.split()
                # Ki·ªÉm tra ƒë·ªãnh d·∫°ng
                if len(parts) != 5:
                    stats['invalid'] += 1
                    continue
                
                try:
                    class_id, xc, yc, bw, bh = map(float, parts)
                    # Validate gi√° tr·ªã
                    if not (0 <= xc <=1 and 0 <= yc <=1 and 0 <= bw <=1 and 0 <= bh <=1):
                        stats['invalid'] += 1
                        continue
                        
                    # T√≠nh k√≠ch th∆∞·ªõc th·ª±c
                    box_w = bw * w
                    box_h = bh * h
                    area = box_w * box_h
                    
                    # L·ªçc outliers
                    if area < MIN_AREA or box_w < MIN_DIM or box_h < MIN_DIM:
                        stats['invalid'] += 1
                        continue
                        
                    # C·∫≠p nh·∫≠t th·ªëng k√™
                    cls_name = class_ids.inverse[int(class_id)]
                    stats[cls_name] += 1
                    class_dist[cls_name] += 1
                    
                    valid_labels.append(line)
                    
                except Exception as e:
                    stats['invalid'] += 1
                    
    except Exception as e:
        print(f"Error processing {label_path}: {str(e)}")
        
    return valid_labels, class_dist

def save_clean_data(img_path, labels, output_dir, img_file):
    """L∆∞u d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch"""
    # Copy ·∫£nh
    shutil.copy(img_path, os.path.join(output_dir, 'images', img_file))
    
    # L∆∞u label
    label_file = os.path.splitext(img_file)[0] + '.txt'
    with open(os.path.join(output_dir, 'labels', label_file), 'w') as f:
        f.write('\n'.join(labels))

def balance_dataset(data_dir, class_names, all_files):
    """C√¢n b·∫±ng d·ªØ li·ªáu b·∫±ng augmentation"""
    seq = iaa.Sequential([
        iaa.Fliplr(0.5),
        iaa.Affine(
            rotate=(-15, 15),
            scale=(0.8, 1.2)
        ),
        iaa.GaussianBlur(sigma=(0, 1.0))
    ])
    
    # T√≠nh to√°n s·ªë l∆∞·ª£ng m·∫´u cho t·ª´ng l·ªõp
    class_counts = defaultdict(int)
    for _, dist in all_files:
        for cls, count in dist.items():
            class_counts[cls] += count

    # N·∫øu kh√¥ng c√≥ m·∫´u h·ª£p l·ªá n√†o, b·ªè qua b∆∞·ªõc augmentation
    if not class_counts:
        print("Kh√¥ng c√≥ m·∫´u h·ª£p l·ªá ƒë·ªÉ c√¢n b·∫±ng. B·ªè qua b∆∞·ªõc augmentation.")
        return

    max_count = max(class_counts.values())
    
    # TƒÉng c∆∞·ªùng cho c√°c l·ªõp thi·∫øu
    for cls in class_names:
        if class_counts[cls] < max_count // 2 and cls in AUGMENT_CLASSES:
            augment_class(
                data_dir, 
                cls, 
                target_count=max_count // 2,
                augmenter=seq
            )


def stratified_split(data_dir, class_names, ratios=(0.7, 0.2, 0.1)):
    """
    Ph√¢n chia d·ªØ li·ªáu theo t·ª∑ l·ªá gi·ªØ nguy√™n ph√¢n ph·ªëi l·ªõp.
    Gi·∫£ s·ª≠ data_dir c√≥ c·∫•u tr√∫c:
        data_dir/
            images/
            labels/
    M·ªói ·∫£nh c√≥ file label c√≥ c√πng t√™n (ƒëu√¥i .txt).
    N·∫øu file label c√≥ nhi·ªÅu d√≤ng, ta s·ª≠ d·ª•ng d√≤ng ƒë·∫ßu ti√™n ƒë·ªÉ l·∫•y nh√£n cho ·∫£nh.
    
    Sau khi t√°ch, c√°c file s·∫Ω ƒë∆∞·ª£c copy sang:
        data_dir/train/images, data_dir/train/labels,
        data_dir/valid/images, data_dir/valid/labels,
        data_dir/test/images, data_dir/test/labels.
    """
    images_dir = os.path.join(data_dir, "images")
    labels_dir = os.path.join(data_dir, "labels")
    
    # L·∫•y danh s√°ch ·∫£nh h·ª£p l·ªá v√† nh√£n t∆∞∆°ng ·ª©ng (s·ª≠ d·ª•ng d√≤ng label ƒë·∫ßu ti√™n)
    image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]
    valid_image_files = []
    image_labels = []  # nh√£n d·∫°ng t√™n l·ªõp
    
    for img_file in image_files:
        base, _ = os.path.splitext(img_file)
        label_file = base + ".txt"
        label_path = os.path.join(labels_dir, label_file)
        if not os.path.exists(label_path):
            continue
        with open(label_path, 'r') as f:
            lines = f.readlines()
        if not lines:
            continue
        # L·∫•y d√≤ng ƒë·∫ßu ti√™n v√† tr√≠ch xu·∫•t class_id
        try:
            first_line = lines[0].strip()
            parts = first_line.split()
            if len(parts) < 1:
                continue
            class_id = int(float(parts[0]))
            if class_id < len(class_names):
                label_name = class_names[class_id]
            else:
                label_name = "unknown"
            image_labels.append(label_name)
            valid_image_files.append(img_file)
        except Exception as e:
            continue

    if not valid_image_files:
        print("Kh√¥ng t√¨m th·∫•y ·∫£nh h·ª£p l·ªá ƒë·ªÉ ph√¢n chia.")
        return

    # B∆∞·ªõc 1: T√°ch th√†nh train v√† temp (v·ªõi t·ªâ l·ªá train:  ratios[0])
    train_files, temp_files, train_labels, temp_labels = train_test_split(
        valid_image_files, image_labels, test_size=(1 - ratios[0]), stratify=image_labels, random_state=42
    )
    # B∆∞·ªõc 2: T√°ch temp th√†nh valid v√† test theo t·ªâ l·ªá valid:test = ratios[1]:ratios[2]
    valid_ratio = ratios[1] / (ratios[1] + ratios[2])
    valid_files, test_files, valid_labels, test_labels = train_test_split(
        temp_files, temp_labels, test_size=(1 - valid_ratio), stratify=temp_labels, random_state=42
    )

    # T·∫°o th∆∞ m·ª•c cho t·ª´ng split
    for split in ['train', 'valid', 'test']:
        os.makedirs(os.path.join(data_dir, split, 'images'), exist_ok=True)
        os.makedirs(os.path.join(data_dir, split, 'labels'), exist_ok=True)

    def copy_files(file_list, split_name):
        for img_file in file_list:
            base, ext = os.path.splitext(img_file)
            src_img = os.path.join(images_dir, img_file)
            src_label = os.path.join(labels_dir, base + ".txt")
            dst_img = os.path.join(data_dir, split_name, 'images', img_file)
            dst_label = os.path.join(data_dir, split_name, 'labels', base + ".txt")
            shutil.copy(src_img, dst_img)
            shutil.copy(src_label, dst_label)

    copy_files(train_files, 'train')
    copy_files(valid_files, 'valid')
    copy_files(test_files, 'test')

    print("Stratified split ho√†n t·∫•t:")
    print(f" - Train: {len(train_files)} ·∫£nh")
    print(f" - Valid: {len(valid_files)} ·∫£nh")
    print(f" - Test:  {len(test_files)} ·∫£nh")


def visualize_improvements(stats_before, stats_after):
    """
    Tr·ª±c quan h√≥a k·∫øt qu·∫£ c·∫£i thi·ªán d·ªØ li·ªáu.
    stats_before v√† stats_after l√† c√°c dictionary c√≥ d·∫°ng:
        { 'class1': count1, 'class2': count2, ... , 'invalid': count_invalid }
    H√†m s·∫Ω t·∫°o bi·ªÉu ƒë·ªì c·ªôt so s√°nh s·ªë l∆∞·ª£ng m·∫´u tr∆∞·ªõc v√† sau c·∫£i thi·ªán.
    """
    # L·∫•y t·∫≠p h·ª£p t·∫•t c·∫£ c√°c key t·ª´ c·∫£ hai dictionary
    all_keys = set(stats_before.keys()).union(set(stats_after.keys()))
    
    data = []
    for key in all_keys:
        data.append({
            'class': key,
            'before': stats_before.get(key, 0),
            'after': stats_after.get(key, 0)
        })
    
    df = pd.DataFrame(data)
    df_melt = df.melt(id_vars='class', value_vars=['before', 'after'], 
                      var_name='stage', value_name='count')
    
    plt.figure(figsize=(10, 6))
    sns.barplot(data=df_melt, x='class', y='count', hue='stage')
    plt.title("So s√°nh s·ªë l∆∞·ª£ng m·∫´u tr∆∞·ªõc v√† sau c·∫£i thi·ªán")
    plt.xlabel("L·ªõp")
    plt.ylabel("S·ªë l∆∞·ª£ng m·∫´u")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

# ====================== CH·∫†Y CH∆Ø∆†NG TR√åNH ======================
if __name__ == "__main__":
    input_yaml = data_yaml_path
    output_dir = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/yolov12s09032025_ver-dataset2/_ver1/invalid/improved_dataset"
    
    print("üîÑ ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...")
    stats = analyze_and_improve_dataset(input_yaml, output_dir)
    
    print("‚úÖ Ho√†n th√†nh! K·∫øt qu·∫£:")
    print(f" - ƒê√£ x·ª≠ l√Ω {sum(stats['train'].values())} m·∫´u hu·∫•n luy·ªán")
    print(f" - Lo·∫°i b·ªè {stats['train']['invalid']} label kh√¥ng h·ª£p l·ªá")
    
     # ƒê√¢y ch·ªâ l√† d·ªØ li·ªáu m·∫´u minh h·ªça
    # stats_before = {"drinking": 120, "raising_hand": 80, "invalid": 30}
    # stats_after  = {"drinking": 150, "raising_hand": 100, "invalid": 10}
    # visualize_improvements(original_stats, stats)





import os
import yaml
import cv2
import numpy as np
import shutil
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.model_selection import train_test_split
from collections import defaultdict
from imgaug import augmenters as iaa

# ========================== C·∫§U H√åNH ==========================
MIN_AREA = 100      # Di·ªán t√≠ch t·ªëi thi·ªÉu (pixel¬≤) c·ªßa bounding box
MIN_DIM = 10        # K√≠ch th∆∞·ªõc t·ªëi thi·ªÉu (chi·ªÅu r·ªông ho·∫∑c chi·ªÅu cao) c·ªßa bounding box
AUGMENT_CLASSES = [ # Danh s√°ch c√°c l·ªõp c·∫ßn tƒÉng c∆∞·ªùng d·ªØ li·ªáu (s·ª≠ d·ª•ng augmentation)
    "drinking", 
    "raising_hand"
]
# ===============================================================

def analyze_and_improve_dataset(yaml_path, output_dir):
    """
    H√†m ch√≠nh x·ª≠ l√Ω to√†n b·ªô pipeline:
      - ƒê·ªçc c·∫•u h√¨nh dataset t·ª´ file YAML
      - L√†m s·∫°ch d·ªØ li·ªáu b·∫±ng c√°ch l·ªçc c√°c label kh√¥ng h·ª£p l·ªá
      - L∆∞u ·∫£nh v√† label ƒë√£ l√†m s·∫°ch v√†o th∆∞ m·ª•c output theo c·∫•u tr√∫c train/valid/test
      - C√¢n b·∫±ng d·ªØ li·ªáu th√¥ng qua augmentation cho c√°c l·ªõp c√≥ s·ªë l∆∞·ª£ng m·∫´u √≠t
      - Ph√¢n chia l·∫°i d·ªØ li·ªáu th√†nh c√°c t·∫≠p train, valid, test v·ªõi ph√¢n ph·ªëi l·ªõp c·ªë ƒë·ªãnh
      
    ƒê·∫ßu v√†o:
        yaml_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file c·∫•u h√¨nh dataset (YAML)
        output_dir: Th∆∞ m·ª•c ƒë·∫ßu ra ch·ª©a d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
    Tr·∫£ v·ªÅ:
        stats: Th·ªëng k√™ k·∫øt qu·∫£ x·ª≠ l√Ω cho t·ª´ng t·∫≠p d·ªØ li·ªáu
    """
    # 1. ƒê·ªçc c·∫•u h√¨nh dataset t·ª´ file YAML
    with open(yaml_path, 'r') as f:
        data = yaml.safe_load(f)
    # L·∫•y th∆∞ m·ª•c g·ªëc c·ªßa dataset t·ª´ ƒë∆∞·ªùng d·∫´n YAML
    root_dir = os.path.dirname(yaml_path)
    # Danh s√°ch t√™n l·ªõp (v√≠ d·ª•: ["drinking", "raising_hand", ...])
    class_names = data['names']
    
    # 2. Kh·ªüi t·∫°o th∆∞ m·ª•c ƒë·∫ßu ra cho t·ª´ng t·∫≠p: train, valid, test
    for split in ['train', 'valid', 'test']:
        os.makedirs(os.path.join(output_dir, split, 'images'), exist_ok=True)
        os.makedirs(os.path.join(output_dir, split, 'labels'), exist_ok=True)

    # 3. Kh·ªüi t·∫°o bi·∫øn l∆∞u danh s√°ch file v√† th·ªëng k√™ d·ªØ li·ªáu
    all_files = []  # Danh s√°ch ch·ª©a tuple (split, class distribution) cho m·ªói ·∫£nh
    stats = defaultdict(lambda: defaultdict(int))  # Th·ªëng k√™ cho t·ª´ng t·∫≠p: v√≠ d·ª•, stats['train']

    # 4. Duy·ªát qua c√°c t·∫≠p d·ªØ li·ªáu g·ªëc (train, valid, test)
    for split in ['train', 'valid', 'test']:
        img_dir = os.path.join(root_dir, split, 'images')
        label_dir = os.path.join(root_dir, split, 'labels')
        
        # N·∫øu th∆∞ m·ª•c ·∫£nh kh√¥ng t·ªìn t·∫°i, b·ªè qua t·∫≠p n√†y
        if not os.path.exists(img_dir):
            continue
            
        # Duy·ªát qua t·ª´ng file ·∫£nh trong th∆∞ m·ª•c
        for img_file in os.listdir(img_dir):
            # Ki·ªÉm tra file c√≥ ph·∫£i l√† ·∫£nh d·ª±a v√†o ph·∫ßn m·ªü r·ªông
            if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                continue
                
            img_path = os.path.join(img_dir, img_file)
            # X√°c ƒë·ªãnh file label t∆∞∆°ng ·ª©ng (gi·∫£ s·ª≠ c√≥ c√πng t√™n file, ƒëu√¥i .txt)
            label_path = os.path.join(label_dir, os.path.splitext(img_file)[0] + '.txt')
            
            # 5. L·ªçc v√† chu·∫©n h√≥a label (ch·ªâ gi·ªØ l·∫°i nh·ªØng d√≤ng label h·ª£p l·ªá)
            valid_labels, class_dist = process_labels(
                label_path, 
                img_path, 
                class_names,
                stats[split]
            )
            
            # N·∫øu c√≥ √≠t nh·∫•t m·ªôt label h·ª£p l·ªá, l∆∞u ·∫£nh v√† label ƒë√£ x·ª≠ l√Ω
            if valid_labels:
                save_clean_data(
                    img_path,
                    valid_labels,
                    os.path.join(output_dir, split),
                    img_file
                )
                # L∆∞u th·ªëng k√™ c·ªßa ·∫£nh v√†o danh s√°ch all_files
                all_files.append((split, class_dist))
            
            #---- Save folder lable kh√¥ng h·ª£p l·ªá
            if invalid_labels:
                save_invalid_data(
                    img_path,
                    invalid_labels,
                    os.path.join(output_dir, split),
                    img_file
                )
            
    # 7. C√¢n b·∫±ng d·ªØ li·ªáu: tƒÉng c∆∞·ªùng d·ªØ li·ªáu cho c√°c l·ªõp c√≥ s·ªë l∆∞·ª£ng m·∫´u th·∫•p
    balance_dataset(output_dir, class_names, all_files)
    
    # 8. Ph√¢n chia l·∫°i d·ªØ li·ªáu th√†nh c√°c t·∫≠p train, valid, test theo ph√¢n ph·ªëi l·ªõp c·ªë ƒë·ªãnh
    stratified_split(output_dir, class_names)
    
    return stats

def process_labels(label_path, img_path, class_names, stats):
    """
    X·ª≠ l√Ω v√† l·ªçc label c·ªßa ·∫£nh.
    
    C√°c b∆∞·ªõc:
      - ƒê·ªçc ·∫£nh ƒë·ªÉ l·∫•y k√≠ch th∆∞·ªõc (width, height)
      - ƒê·ªçc file label, duy·ªát t·ª´ng d√≤ng v√† ki·ªÉm tra:
          * D√≤ng label ph·∫£i c√≥ ƒë√∫ng 5 gi√° tr·ªã: class_id, xc, yc, bw, bh
          * C√°c gi√° tr·ªã xc, yc, bw, bh ph·∫£i n·∫±m trong kho·∫£ng [0, 1]
          * K√≠ch th∆∞·ªõc th·ª±c c·ªßa bounding box (t√≠nh t·ª´ k√≠ch th∆∞·ªõc ·∫£nh) ph·∫£i ƒë·∫°t y√™u c·∫ßu
            (di·ªán t√≠ch >= MIN_AREA, width v√† height >= MIN_DIM)
      - N·∫øu d√≤ng label h·ª£p l·ªá, c·∫≠p nh·∫≠t th·ªëng k√™ v√† th√™m v√†o danh s√°ch valid_labels
      - N·∫øu kh√¥ng h·ª£p l·ªá, tƒÉng th·ªëng k√™ stats['invalid']
    
    ƒê·∫ßu v√†o:
        label_path: ƒê∆∞·ªùng d·∫´n file label
        img_path: ƒê∆∞·ªùng d·∫´n ·∫£nh (ƒë·ªÉ l·∫•y k√≠ch th∆∞·ªõc)
        class_names: Danh s√°ch t√™n l·ªõp
        stats: Dictionary th·ªëng k√™ cho t·∫≠p d·ªØ li·ªáu hi·ªán t·∫°i
    Tr·∫£ v·ªÅ:
        valid_labels: Danh s√°ch d√≤ng label h·ª£p l·ªá
        class_dist: Ph√¢n b·ªë l·ªõp (dictionary) cho ·∫£nh n√†y
    """
    valid_labels = []
    class_dist = defaultdict(int)
    
    try:
        # ƒê·ªçc ·∫£nh ƒë·ªÉ l·∫•y k√≠ch th∆∞·ªõc
        img = cv2.imread(img_path)
        if img is None:
            return [], {}
            
        h, w = img.shape[:2]
        
        # ƒê·ªçc file label
        with open(label_path, 'r') as f:
            for line in f:
                line = line.strip()
                # B·ªè qua d√≤ng tr·ªëng
                if not line:
                    continue
                
                parts = line.split()
                # Ki·ªÉm tra ƒë·ªãnh d·∫°ng: ph·∫£i c√≥ ƒë√∫ng 5 gi√° tr·ªã
                if len(parts) != 5:
                    stats['invalid'] += 1
                    continue
                
                try:
                    # Chuy·ªÉn ƒë·ªïi c√°c gi√° tr·ªã th√†nh float
                    class_id, xc, yc, bw, bh = map(float, parts)
                    # Ki·ªÉm tra c√°c gi√° tr·ªã t·ªça ƒë·ªô v√† k√≠ch th∆∞·ªõc ph·∫£i n·∫±m trong kho·∫£ng [0, 1]
                    if not (0 <= xc <= 1 and 0 <= yc <= 1 and 0 <= bw <= 1 and 0 <= bh <= 1):
                        stats['invalid'] += 1
                        continue
                        
                    # T√≠nh k√≠ch th∆∞·ªõc th·ª±c c·ªßa bounding box d·ª±a v√†o k√≠ch th∆∞·ªõc ·∫£nh
                    box_w = bw * w
                    box_h = bh * h
                    area = box_w * box_h
                    
                    # L·ªçc c√°c box c√≥ k√≠ch th∆∞·ªõc qu√° nh·ªè
                    if area < MIN_AREA or box_w < MIN_DIM or box_h < MIN_DIM:
                        stats['invalid'] += 1
                        continue
                        
                    # L·∫•y t√™n l·ªõp t·ª´ class_id s·ª≠ d·ª•ng danh s√°ch class_names
                    cls_name = class_names[int(class_id)]
                    # C·∫≠p nh·∫≠t th·ªëng k√™ cho l·ªõp n√†y
                    stats[cls_name] += 1
                    class_dist[cls_name] += 1
                    
                    # N·∫øu d√≤ng label h·ª£p l·ªá, th√™m v√†o danh s√°ch valid_labels
                    valid_labels.append(line)
                    
                except Exception as e:
                    stats['invalid'] += 1
                    
    except Exception as e:
        print(f"Error processing {label_path}: {str(e)}")
        
    return valid_labels, class_dist

def save_clean_data(img_path, labels, output_dir, img_file):
    """
    L∆∞u d·ªØ li·ªáu ƒë√£ l√†m s·∫°ch v√†o th∆∞ m·ª•c ƒë·∫ßu ra.
      - Copy ·∫£nh g·ªëc v√†o th∆∞ m·ª•c 'images'
      - Ghi c√°c d√≤ng label h·ª£p l·ªá v√†o file label trong th∆∞ m·ª•c 'labels'
      
    ƒê·∫ßu v√†o:
        img_path: ƒê∆∞·ªùng d·∫´n ·∫£nh g·ªëc
        labels: Danh s√°ch d√≤ng label h·ª£p l·ªá
        output_dir: Th∆∞ m·ª•c ƒë·∫ßu ra c·ªßa t·∫≠p d·ªØ li·ªáu (train/valid/test)
        img_file: T√™n file ·∫£nh
    """
    # Copy ·∫£nh g·ªëc v√†o th∆∞ m·ª•c output/images
    shutil.copy(img_path, os.path.join(output_dir, 'images', img_file))
    
    # T·∫°o t√™n file label d·ª±a tr√™n t√™n file ·∫£nh (ƒë·ªïi ƒëu√¥i th√†nh .txt)
    label_file = os.path.splitext(img_file)[0] + '.txt'
    # Ghi n·ªôi dung c√°c d√≤ng label h·ª£p l·ªá v√†o file label m·ªõi
    with open(os.path.join(output_dir, 'labels', label_file), 'w') as f:
        f.write('\n'.join(labels))

def save_invalid_data(img_path, invalid_labels, output_dir, img_file):
    """
    L∆∞u c√°c label kh√¥ng h·ª£p l·ªá v√†o th∆∞ m·ª•c invalid c·ªßa m·ªói split.
    """
    invalid_images_dir = os.path.join(output_dir, 'invalid', 'images')
    invalid_labels_dir = os.path.join(output_dir, 'invalid', 'labels')
    # Copy ·∫£nh g·ªëc v√†o th∆∞ m·ª•c invalid images
    shutil.copy(img_path, os.path.join(invalid_images_dir, img_file))
    # L∆∞u file label kh√¥ng h·ª£p l·ªá
    label_file = os.path.splitext(img_file)[0] + '.txt'
    with open(os.path.join(invalid_labels_dir, label_file), 'w') as f:
        f.write('\n'.join(invalid_labels))

def augment_class(data_dir, cls, target_count, augmenter, class_names):
    """
    TƒÉng c∆∞·ªùng d·ªØ li·ªáu cho l·ªõp c·ª• th·ªÉ th√¥ng qua augmentation.
    Phi√™n b·∫£n n√†y ƒë∆°n gi·∫£n: t√¨m c√°c ·∫£nh m√† file label ch·ª©a l·ªõp 'cls' v√† √°p d·ª•ng augmentation.
    (L∆∞u √Ω: Trong th·ª±c t·∫ø c·∫ßn c·∫≠p nh·∫≠t l·∫°i t·ªça ƒë·ªô bounding box cho ·∫£nh tƒÉng c∆∞·ªùng)
    
    ƒê·∫ßu v√†o:
        data_dir: Th∆∞ m·ª•c d·ªØ li·ªáu (ch·ª©a t·∫≠p train)
        cls: T√™n l·ªõp c·∫ßn tƒÉng c∆∞·ªùng (v√≠ d·ª•: "drinking")
        target_count: S·ªë l∆∞·ª£ng m·∫´u mong mu·ªën sau khi tƒÉng c∆∞·ªùng cho l·ªõp n√†y
        augmenter: ƒê·ªëi t∆∞·ª£ng augmentation (imgaug)
        class_names: Danh s√°ch t√™n l·ªõp
    """
    print(f"Augmenting class '{cls}' to reach {target_count} samples.")
    # X√°c ƒë·ªãnh th∆∞ m·ª•c ch·ª©a ·∫£nh v√† label c·ªßa t·∫≠p train
    train_images_dir = os.path.join(data_dir, "train", "images")
    train_labels_dir = os.path.join(data_dir, "train", "labels")
    
    # T√¨m danh s√°ch c√°c file label c√≥ ch·ª©a l·ªõp c·∫ßn tƒÉng c∆∞·ªùng
    images_to_augment = []
    for label_file in os.listdir(train_labels_dir):
        label_path = os.path.join(train_labels_dir, label_file)
        with open(label_path, 'r') as f:
            lines = f.readlines()
        # N·∫øu trong file label c√≥ √≠t nh·∫•t m·ªôt d√≤ng ch·ª©a l·ªõp 'cls', th√™m t√™n file ·∫£nh v√†o danh s√°ch
        for line in lines:
            parts = line.strip().split()
            if len(parts) < 1:
                continue
            try:
                class_id = int(float(parts[0]))
                if class_names[class_id] == cls:
                    images_to_augment.append(label_file.replace(".txt", ""))
                    break
            except:
                continue
    
    # T√≠nh s·ªë l∆∞·ª£ng m·∫´u hi·ªán c√≥ v√† s·ªë m·∫´u c·∫ßn tƒÉng c∆∞·ªùng th√™m
    current_count = len(images_to_augment)
    augment_needed = target_count - current_count
    if augment_needed <= 0:
        print(f"Kh√¥ng c·∫ßn tƒÉng c∆∞·ªùng th√™m cho l·ªõp '{cls}'.")
        return
    
    print(f"C·∫ßn tƒÉng c∆∞·ªùng {augment_needed} m·∫´u cho l·ªõp '{cls}'.")
    
    # √Åp d·ª•ng augmentation cho c√°c ·∫£nh c·ªßa l·ªõp 'cls'
    aug_index = 0
    for img_name in images_to_augment:
        # Gi·∫£ s·ª≠ ·∫£nh c√≥ ƒë·ªãnh d·∫°ng .jpg (c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh n·∫øu c·∫ßn)
        img_path = os.path.join(train_images_dir, img_name + ".jpg")
        label_path = os.path.join(train_labels_dir, img_name + ".txt")
        
        # ƒê·ªçc ·∫£nh t·ª´ file
        image = cv2.imread(img_path)
        if image is None:
            continue
        
        # √Åp d·ª•ng augmentation v√†o ·∫£nh
        image_aug = augmenter.augment_image(image)
        
        # T·∫°o t√™n file m·ªõi cho ·∫£nh v√† label tƒÉng c∆∞·ªùng
        new_img_name = f"{img_name}_aug_{aug_index}.jpg"
        new_label_name = f"{img_name}_aug_{aug_index}.txt"
        # L∆∞u ·∫£nh tƒÉng c∆∞·ªùng v√†o th∆∞ m·ª•c train/images
        cv2.imwrite(os.path.join(train_images_dir, new_img_name), image_aug)
        # Copy file label g·ªëc sang t√™n m·ªõi (trong th·ª±c t·∫ø c·∫ßn c·∫≠p nh·∫≠t bounding box n·∫øu ·∫£nh thay ƒë·ªïi)
        shutil.copy(label_path, os.path.join(train_labels_dir, new_label_name))
        
        aug_index += 1
        if aug_index >= augment_needed:
            break

def balance_dataset(data_dir, class_names, all_files):
    """
    C√¢n b·∫±ng d·ªØ li·ªáu b·∫±ng c√°ch tƒÉng c∆∞·ªùng d·ªØ li·ªáu (augmentation) cho c√°c l·ªõp c√≥ s·ªë l∆∞·ª£ng m·∫´u th·∫•p.
    
    ƒê·∫ßu v√†o:
        data_dir: Th∆∞ m·ª•c ch·ª©a d·ªØ li·ªáu ƒë√£ l√†m s·∫°ch (bao g·ªìm c√°c t·∫≠p train, valid, test)
        class_names: Danh s√°ch t√™n l·ªõp
        all_files: Danh s√°ch c√°c tuple (split, class distribution) thu ƒë∆∞·ª£c t·ª´ qu√° tr√¨nh x·ª≠ l√Ω
    """
    # Kh·ªüi t·∫°o ƒë·ªëi t∆∞·ª£ng augmenter v·ªõi c√°c k·ªπ thu·∫≠t augmentation
    seq = iaa.Sequential([
        iaa.Fliplr(0.5),               # L·∫≠t ·∫£nh ngang v·ªõi x√°c su·∫•t 50%
        iaa.Affine(                    # Bi·∫øn ƒë·ªïi affine: xoay v√† scale ·∫£nh
            rotate=(-15, 15),
            scale=(0.8, 1.2)
        ),
        iaa.GaussianBlur(sigma=(0, 1.0)) # √Åp d·ª•ng Gaussian blur v·ªõi sigma t·ª´ 0 ƒë·∫øn 1.0
    ])
    
    # T√≠nh s·ªë l∆∞·ª£ng m·∫´u cho t·ª´ng l·ªõp t·ª´ th·ªëng k√™ ƒë√£ thu th·∫≠p ƒë∆∞·ª£c
    class_counts = defaultdict(int)
    for _, dist in all_files:
        for cls, count in dist.items():
            class_counts[cls] += count

    # N·∫øu kh√¥ng c√≥ m·∫´u h·ª£p l·ªá n√†o, b·ªè qua b∆∞·ªõc augmentation
    if not class_counts:
        print("Kh√¥ng c√≥ m·∫´u h·ª£p l·ªá ƒë·ªÉ c√¢n b·∫±ng. B·ªè qua b∆∞·ªõc augmentation.")
        return

    # L·∫•y s·ªë l∆∞·ª£ng m·∫´u l·ªõn nh·∫•t c·ªßa c√°c l·ªõp
    max_count = max(class_counts.values())
    
    # Duy·ªát qua t·ª´ng l·ªõp, n·∫øu s·ªë m·∫´u c·ªßa l·ªõp nh·ªè h∆°n m·ªôt n·ª≠a c·ªßa l·ªõp c√≥ s·ªë m·∫´u nhi·ªÅu nh·∫•t
    # v√† l·ªõp ƒë√≥ n·∫±m trong danh s√°ch c·∫ßn augmentation, ti·∫øn h√†nh tƒÉng c∆∞·ªùng d·ªØ li·ªáu.
    for cls in class_names:
        if class_counts[cls] < max_count // 2 and cls in AUGMENT_CLASSES:
            augment_class(
                data_dir, 
                cls, 
                target_count=max_count // 2,
                augmenter=seq,
                class_names=class_names
            )

def stratified_split(data_dir, class_names, ratios=(0.7, 0.2, 0.1)):
    """
    Ph√¢n chia d·ªØ li·ªáu th√†nh c√°c t·∫≠p train, valid, test theo t·ª∑ l·ªá gi·ªØ nguy√™n ph√¢n ph·ªëi l·ªõp.
    
    Gi·∫£ s·ª≠ c·∫•u tr√∫c d·ªØ li·ªáu ban ƒë·∫ßu trong data_dir l√†:
        data_dir/
            images/   (ch·ª©a t·∫•t c·∫£ ·∫£nh)
            labels/   (ch·ª©a t·∫•t c·∫£ file label, c√≥ c√πng t√™n v·ªõi ·∫£nh)
    
    M·ªói ·∫£nh ƒë∆∞·ª£c g√°n nh√£n d·ª±a v√†o d√≤ng label ƒë·∫ßu ti√™n trong file label.
    
    Sau khi ph√¢n chia, c√°c file s·∫Ω ƒë∆∞·ª£c copy sang:
        data_dir/train/images, data_dir/train/labels,
        data_dir/valid/images, data_dir/valid/labels,
        data_dir/test/images, data_dir/test/labels.
    """
    images_dir = os.path.join(data_dir, "images")
    labels_dir = os.path.join(data_dir, "labels")
    
    # L·∫•y danh s√°ch c√°c file ·∫£nh h·ª£p l·ªá v√† g√°n nh√£n cho t·ª´ng ·∫£nh t·ª´ file label ƒë·∫ßu ti√™n
    image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]
    valid_image_files = []
    image_labels = []  # Danh s√°ch nh√£n d·∫°ng t√™n l·ªõp
    
    for img_file in image_files:
        base, _ = os.path.splitext(img_file)
        label_file = base + ".txt"
        label_path = os.path.join(labels_dir, label_file)
        # N·∫øu file label kh√¥ng t·ªìn t·∫°i, b·ªè qua ·∫£nh n√†y
        if not os.path.exists(label_path):
            continue
        with open(label_path, 'r') as f:
            lines = f.readlines()
        if not lines:
            continue
        # L·∫•y d√≤ng ƒë·∫ßu ti√™n v√† tr√≠ch xu·∫•t class_id
        try:
            first_line = lines[0].strip()
            parts = first_line.split()
            if len(parts) < 1:
                continue
            class_id = int(float(parts[0]))
            if class_id < len(class_names):
                label_name = class_names[class_id]
            else:
                label_name = "unknown"
            image_labels.append(label_name)
            valid_image_files.append(img_file)
        except Exception as e:
            continue

    if not valid_image_files:
        print("Kh√¥ng t√¨m th·∫•y ·∫£nh h·ª£p l·ªá ƒë·ªÉ ph√¢n chia.")
        return

    # S·ª≠ d·ª•ng train_test_split c√≥ ph√¢n t·∫ßng ƒë·ªÉ chia d·ªØ li·ªáu
    # B∆∞·ªõc 1: T√°ch th√†nh t·∫≠p train v√† t·∫≠p t·∫°m (temp) v·ªõi t·∫≠p train chi·∫øm t·ª∑ l·ªá ratios[0]
    train_files, temp_files, train_labels, temp_labels = train_test_split(
        valid_image_files, image_labels, test_size=(1 - ratios[0]), stratify=image_labels, random_state=42
    )
    # B∆∞·ªõc 2: T√°ch t·∫≠p t·∫°m th√†nh t·∫≠p valid v√† test theo t·ª∑ l·ªá ratios[1]:ratios[2]
    valid_ratio = ratios[1] / (ratios[1] + ratios[2])
    valid_files, test_files, valid_labels, test_labels = train_test_split(
        temp_files, temp_labels, test_size=(1 - valid_ratio), stratify=temp_labels, random_state=42
    )

    # T·∫°o th∆∞ m·ª•c cho t·ª´ng t·∫≠p (train, valid, test)
    for split in ['train', 'valid', 'test']:
        os.makedirs(os.path.join(data_dir, split, 'images'), exist_ok=True)
        os.makedirs(os.path.join(data_dir, split, 'labels'), exist_ok=True)

    # H√†m n·ªôi b·ªô: copy file t·ª´ th∆∞ m·ª•c g·ªëc sang th∆∞ m·ª•c c·ªßa t·ª´ng t·∫≠p
    def copy_files(file_list, split_name):
        for img_file in file_list:
            base, ext = os.path.splitext(img_file)
            src_img = os.path.join(images_dir, img_file)
            src_label = os.path.join(labels_dir, base + ".txt")
            dst_img = os.path.join(data_dir, split_name, 'images', img_file)
            dst_label = os.path.join(data_dir, split_name, 'labels', base + ".txt")
            shutil.copy(src_img, dst_img)
            shutil.copy(src_label, dst_label)

    # Copy file ·∫£nh v√† label sang c√°c th∆∞ m·ª•c t∆∞∆°ng ·ª©ng
    copy_files(train_files, 'train')
    copy_files(valid_files, 'valid')
    copy_files(test_files, 'test')

    print("Stratified split ho√†n t·∫•t:")
    print(f" - Train: {len(train_files)} ·∫£nh")
    print(f" - Valid: {len(valid_files)} ·∫£nh")
    print(f" - Test:  {len(test_files)} ·∫£nh")

def visualize_improvements(stats_before, stats_after):
    """
    Tr·ª±c quan h√≥a k·∫øt qu·∫£ c·∫£i thi·ªán d·ªØ li·ªáu b·∫±ng bi·ªÉu ƒë·ªì c·ªôt so s√°nh s·ªë l∆∞·ª£ng m·∫´u c·ªßa t·ª´ng l·ªõp
    tr∆∞·ªõc v√† sau khi c·∫£i thi·ªán.
    
    ƒê·∫ßu v√†o:
        stats_before: Dictionary th·ªëng k√™ tr∆∞·ªõc khi c·∫£i thi·ªán, v√≠ d·ª•: {"drinking": 120, "raising_hand": 80, "invalid": 30}
        stats_after: Dictionary th·ªëng k√™ sau khi c·∫£i thi·ªán, v√≠ d·ª•: {"drinking": 150, "raising_hand": 100, "invalid": 10}
    """
    # T·∫≠p h·ª£p t·∫•t c·∫£ c√°c l·ªõp xu·∫•t hi·ªán trong c·∫£ stats_before v√† stats_after
    all_keys = set(stats_before.keys()).union(set(stats_after.keys()))
    
    data = []
    # T·∫°o danh s√°ch dictionary v·ªõi th√¥ng tin th·ªëng k√™ c·ªßa t·ª´ng l·ªõp
    for key in all_keys:
        data.append({
            'class': key,
            'before': stats_before.get(key, 0),
            'after': stats_after.get(key, 0)
        })
    
    # Chuy·ªÉn danh s√°ch th√†nh DataFrame ƒë·ªÉ tr·ª±c quan h√≥a b·∫±ng seaborn
    df = pd.DataFrame(data)
    # "Melt" DataFrame ƒë·ªÉ c√≥ ƒë·ªãnh d·∫°ng ph√π h·ª£p cho barplot (d·∫°ng long)
    df_melt = df.melt(id_vars='class', value_vars=['before', 'after'], 
                      var_name='stage', value_name='count')
    
    plt.figure(figsize=(10, 6))
    sns.barplot(data=df_melt, x='class', y='count', hue='stage')
    plt.title("So s√°nh s·ªë l∆∞·ª£ng m·∫´u tr∆∞·ªõc v√† sau c·∫£i thi·ªán")
    plt.xlabel("L·ªõp")
    plt.ylabel("S·ªë l∆∞·ª£ng m·∫´u")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

# ====================== CH·∫†Y CH∆Ø∆†NG TR√åNH ======================
if __name__ == "__main__":
    # C·∫≠p nh·∫≠t ƒë∆∞·ªùng d·∫´n file YAML c·ªßa dataset c·ªßa b·∫°n
    data_yaml_path = "/path/to/dataset.yaml"
    input_yaml = data_yaml_path
    
    # ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c ƒë·∫ßu ra ch·ª©a d·ªØ li·ªáu ƒë√£ c·∫£i thi·ªán
    # output_dir = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/yolov12s09032025_ver-dataset2/_ver1/invalid/improved_dataset"
    output_dir = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/yolov12s09032025_ver-dataset2/Imporved_data"
    
    print("üîÑ ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...")
    # G·ªçi h√†m pipeline x·ª≠ l√Ω v√† nh·∫≠n k·∫øt qu·∫£ th·ªëng k√™
    stats = analyze_and_improve_dataset(input_yaml, output_dir)
    
    print("‚úÖ Ho√†n th√†nh! K·∫øt qu·∫£:")
    print(f" - ƒê√£ x·ª≠ l√Ω {sum(stats['train'].values())} m·∫´u hu·∫•n luy·ªán")
    print(f" - Lo·∫°i b·ªè {stats['train']['invalid']} label kh√¥ng h·ª£p l·ªá")
    
    # V√≠ d·ª• tr·ª±c quan h√≥a c·∫£i thi·ªán (s·ª≠ d·ª•ng d·ªØ li·ªáu m·∫´u minh h·ªça)
    stats_before = {"drinking": 120, "raising_hand": 80, "invalid": 30}
    stats_after  = {"drinking": 150, "raising_hand": 100, "invalid": 10}
    visualize_improvements(stats_before, stats_after)









import os
import shutil
from datetime import datetime
from ultralytics import YOLO
import torch
print(torch.__version__)  # Check PyTorch version
print(torch.cuda.get_device_name(0))  # Check GPU model
print(torch.backends.cuda.flash_sdp_enabled())  # Check if FlashAttention is available



def get_unique_path(base_path):
    """
    T·∫°o ƒë∆∞·ªùng d·∫´n duy nh·∫•t b·∫±ng c√°ch th√™m phi√™n b·∫£n n·∫øu th∆∞ m·ª•c ƒë√£ t·ªìn t·∫°i

    Args:
        base_path (str): ƒê∆∞·ªùng d·∫´n g·ªëc mu·ªën t·∫°o

    Returns:
        str: ƒê∆∞·ªùng d·∫´n duy nh·∫•t
    """
    # N·∫øu th∆∞ m·ª•c ch∆∞a t·ªìn t·∫°i, tr·∫£ v·ªÅ ngay
    if not os.path.exists(base_path):
        return f"{base_path}_ver{1}"

    # N·∫øu ƒë√£ t·ªìn t·∫°i, t√¨m phi√™n b·∫£n ti·∫øp theo
    version = 2
    while True:
        versioned_path = f"{base_path}_ver{version}"
        if not os.path.exists(versioned_path):
            return versioned_path
        version += 1








import torch
print(torch.cuda.is_available())






import torch
print("CUDA Available:", torch.cuda.is_available())
print("CUDA Version:", torch.version.cuda)
print("Torch Version:", torch.__version__)
print("GPU Count:", torch.cuda.device_count())
if torch.cuda.is_available():
    print("GPU Name:", torch.cuda.get_device_name(0))



import pandas as pd
# T·∫°o ƒë∆∞·ªùng d·∫´n l∆∞u tr·ªØ v·ªõi th∆∞ m·ª•c theo ng√†y
current_date = datetime.now().strftime("%d%m%Y")
nameYoloFamily = 'yolov12s'
### base
ver_dataset = 2
base_save_path = f'/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/{nameYoloFamily}{current_date}_ver-dataset{ver_dataset}/'

# L·∫•y ƒë∆∞·ªùng d·∫´n duy nh·∫•t ----------------------------------ƒê∆∞·ªùng d·∫´n n√†y c≈©ng l√† quan tr·ªçng. V√¨ c√°c b√°o c√°o d∆∞·ªõi ƒë·ªÅu c√†n ƒë·∫øn
unique_save_path = get_unique_path(base_save_path)
# T·∫°o th∆∞ m·ª•c
os.makedirs(unique_save_path, exist_ok=True)

# T·∫°o m√¥ h√¨nh v√† hu·∫•n luy·ªán
model_filename = f'{nameYoloFamily}{current_date}.pt'
full_model_path = os.path.join(unique_save_path, model_filename)
# T·∫°o m√¥ h√¨nh YOLO v√† c·∫•u h√¨nh
model = YOLO(f'{nameYoloFamily}.yaml')

# Thay ƒë·ªïi th∆∞ m·ª•c l√†m vi·ªác
%cd "{unique_save_path}"
# Hu·∫•n luy·ªán m√¥ h√¨nh

path_data_yaml = '/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/Dataset/Student-Behavior-Recognition-2/data.yaml'
#------------------ Traning model
'''
Gi·∫£ s·ª≠ b·∫°n b·∫Øt ƒë·∫ßu v·ªõi batch size = 32 v√† learning rate = 0.001.

N·∫øu b·∫°n tƒÉng batch size l√™n 64, b·∫°n c√≥ th·ªÉ tƒÉng learning rate l√™n 0.001 * (64/32) = 0.002.

N·∫øu b·∫°n gi·∫£m batch size xu·ªëng 16, b·∫°n c√≥ th·ªÉ gi·∫£m learning rate xu·ªëng 0.001 * (16/32) = 0.0005.
'''
batch_size = 32
num_epochs = 500
# Kh·ªüi t·∫°o log
log_data = []

results = model.train(
    data = path_data_yaml,
    epochs= num_epochs,
    patience= 50,  # S·ªë epoch ƒë·ª£i ƒë·ªÉ d·ª´ng n·∫øu kh√¥ng c·∫£i thi·ªán
    save_period=-1,  # L∆∞u checkpoint sau m·ªói epoch
    save=True,
    optimizer='Adam',  # L·ª±a ch·ªçn optimizer
    lrf=0.001*(batch_size/32),
    batch=batch_size
)
# L∆∞u m√¥ h√¨nh cu·ªëi c√πng
if not os.path.exists(full_model_path):
    model.save(full_model_path)
else:
  print(f"M√¥ h√¨nh ƒë√£ t·ªìn t·∫°i t·∫°i: {full_model_path}")



# In th√¥ng tin v·ªÅ m√¥ h√¨nh ƒë√£ l∆∞u
print(f"M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {full_model_path}")

# Ki·ªÉm tra v√† in k√≠ch th∆∞·ªõc file
model_size = os.path.getsize(full_model_path) / (1024 * 1024)  # Chuy·ªÉn sang MB
print(f"K√≠ch th∆∞·ªõc m√¥ h√¨nh: {model_size:.2f} MB")


# ƒê·∫£m b·∫£o s·ª≠ d·ª•ng UTF-8 encoding
log_path = os.path.join(unique_save_path, 'training_log_2.txt')
with open(log_path, 'w', encoding='utf-8') as log_file:
    log_file.write(f"M√¥ h√¨nh: {nameYoloFamily}\n")
    log_file.write(f"Ng√†y hu·∫•n luy·ªán: {current_date}\n")
    log_file.write(f"S·ªë epochs: {num_epochs} \n")
    log_file.write(f"K√≠ch th∆∞·ªõc m√¥ h√¨nh: {model_size:.2f} MB\n")
    # log_file.write(f"ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c runs: {runs_destination_path}\n")

print(f"ƒê√£ ghi log t·∫°i: {log_path}")












model = YOLO(f'/{unique_save_path}/runs/detect/train/weights/best.pt')



model_summary = model.info()
if isinstance(model_summary, tuple):
    model_summary = model_summary[0]  # L·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n n·∫øu l√† tuple


!pip install torchinfo





from torchinfo import summary
summary(model)





# Ki·ªÉm tra requires_grad c·ªßa c√°c tham s·ªë
for name, param in model.named_parameters():
    print(f"{name}: {param.requires_grad}")





# M·ªü kh√≥a to√†n b·ªô c√°c tham s·ªë
for param in model.model.parameters():
    param.requires_grad = True
%cd /home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/yolov12s10032025_ver-dataset2/_ver1/runs/detect/train/weights
model.save("unfreezed_model.pt")  # ƒê·ªãnh d·∫°ng m·∫∑c ƒë·ªãnh c·ªßa YOLO
# Ki·ªÉm tra l·∫°i
print(f"Trainable params: {sum(p.numel() for p in model.model.parameters() if p.requires_grad)}")





import matplotlib.pyplot as plt
import networkx as nx
import re

def parse_yolo_summary(summary_text):
    """Ph√¢n t√≠ch YOLO summary th√†nh danh s√°ch c√°c layers v√† k·∫øt n·ªëi."""
    G = nx.DiGraph()
    lines = summary_text.strip().split("\n")[2:-2]  # B·ªè d√≤ng ti√™u ƒë·ªÅ v√† t·ªïng k·∫øt

    prev_layer = None  # Theo d√µi l·ªõp tr∆∞·ªõc ƒë·ªÉ t·∫°o k·∫øt n·ªëi
    layer_colors = {
        'Conv': 'lightblue', 'C3k2': 'lightgreen', 'A2C2f': 'lightcoral',
        'Concat': 'orange', 'Upsample': 'purple', 'Detect': 'red'
    }

    for line in lines:
        match = re.search(r'(\w+): (\d+-\d+)\s+\(([\d,]+)?\)', line)
        if match:
            layer_type, layer_index, params = match.groups()
            params = int(params.replace(",", "")) if params else 0

            # Th√™m node
            G.add_node(layer_index, label=f"{layer_type}\n{layer_index}",
                       color=layer_colors.get(layer_type, 'gray'), size=params)

            # K·∫øt n·ªëi v·ªõi l·ªõp tr∆∞·ªõc ƒë√≥ (gi·∫£ ƒë·ªãnh n·ªëi tuy·∫øn t√≠nh)
            if prev_layer:
                G.add_edge(prev_layer, layer_index)

            prev_layer = layer_index  # C·∫≠p nh·∫≠t l·ªõp tr∆∞·ªõc ƒë√≥

    return G

def visualize_yolo(G):
    """V·∫Ω s∆° ƒë·ªì ki·∫øn tr√∫c YOLO."""
    plt.figure(figsize=(12, 8))
    pos = nx.spring_layout(G, seed=42, k=1.2)

    # K√≠ch th∆∞·ªõc node d·ª±a tr√™n s·ªë l∆∞·ª£ng tham s·ªë
    node_sizes = [max(300, G.nodes[n]['size'] // 20) for n in G.nodes]
    node_colors = [G.nodes[n]['color'] for n in G.nodes]

    nx.draw(G, pos, with_labels=True, labels={n: G.nodes[n]['label'] for n in G.nodes},
            node_size=node_sizes, node_color=node_colors, font_size=10,
            font_weight='bold', edge_color='gray', arrows=True)

    plt.title("YOLOv12 Architecture", fontsize=14)
    plt.tight_layout()
    plt.show()

# D·ªØ li·ªáu ƒë·∫ßu v√†o (copy t·ª´ b·∫°n)
summary_text = """==========================================================================================
YOLO                                                              --
‚îú‚îÄDetectionModel: 1-1                                             --
‚îÇ    ‚îî‚îÄSequential: 2-1                                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv: 3-1                                             (928)
‚îÇ    ‚îÇ    ‚îî‚îÄConv: 3-2                                             (18,560)
‚îÇ    ‚îÇ    ‚îî‚îÄC3k2: 3-3                                             (26,080)
‚îÇ    ‚îÇ    ‚îî‚îÄConv: 3-4                                             (147,712)
‚îÇ    ‚îÇ    ‚îî‚îÄC3k2: 3-5                                             (103,360)
‚îÇ    ‚îÇ    ‚îî‚îÄConv: 3-6                                             (590,336)
‚îÇ    ‚îÇ    ‚îî‚îÄA2C2f: 3-7                                            (689,408)
‚îÇ    ‚îÇ    ‚îî‚îÄConv: 3-8                                             (1,180,672)
‚îÇ    ‚îÇ    ‚îî‚îÄA2C2f: 3-9                                            (2,689,536)
‚îÇ    ‚îÇ    ‚îî‚îÄUpsample: 3-10                                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConcat: 3-11                                          --
‚îÇ    ‚îÇ    ‚îî‚îÄA2C2f: 3-12                                           (345,856)
‚îÇ    ‚îÇ    ‚îî‚îÄUpsample: 3-13                                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConcat: 3-14                                          --
‚îÇ    ‚îÇ    ‚îî‚îÄA2C2f: 3-15                                           (95,104)
‚îÇ    ‚îÇ    ‚îî‚îÄConv: 3-16                                            (147,712)
‚îÇ    ‚îÇ    ‚îî‚îÄConcat: 3-17                                          --
‚îÇ    ‚îÇ    ‚îî‚îÄA2C2f: 3-18                                           (296,704)
‚îÇ    ‚îÇ    ‚îî‚îÄConv: 3-19                                            (590,336)
‚îÇ    ‚îÇ    ‚îî‚îÄConcat: 3-20                                          --
‚îÇ    ‚îÇ    ‚îî‚îÄC3k2: 3-21                                            (1,511,424)
‚îÇ    ‚îÇ    ‚îî‚îÄDetect: 3-22                                          (820,956)
==========================================================================================
"""

# X·ª≠ l√Ω v√† v·∫Ω s∆° ƒë·ªì
G = parse_yolo_summary(summary_text)
visualize_yolo(G)









import locale
locale.getpreferredencoding = lambda: "UTF-8"

!ls {unique_save_path}/runs/detect/train/


from IPython.display import Image

Image(filename=f'{unique_save_path}/runs/detect/train/confusion_matrix.png', width=1000)





from IPython.display import Image

Image(filename=f'{unique_save_path}/runs/detect/train/results.png', width=1000)








data_path_working = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/Dataset/Student-Behavior-Recognition-2"
print(data_path_working)


import supervision as sv

ds = sv.DetectionDataset.from_yolo(
    images_directory_path=f"{data_path_working}/test/images",
    annotations_directory_path=f"{data_path_working}/test/labels",
    data_yaml_path=f"{data_path_working}/data.yaml"
)

ds.classes


import supervision
print(supervision.__version__)



pip install --upgrade supervision


from supervision.metrics.mean_average_precision import MeanAveragePrecision  # S·ª≠a ƒë∆∞·ªùng d·∫´n import

model = YOLO(f'/{unique_save_path}/runs/detect/train/weights/best.pt')

predictions = []
targets = []

# Gi·∫£ s·ª≠ ds l√† t·∫≠p d·ªØ li·ªáu (dataset) c·ªßa b·∫°n
for _, image, target in ds:
    results = model(image, verbose=False)[0]
    detections = sv.Detections.from_ultralytics(results)
    
    predictions.append(detections)
    targets.append(target)

# T√≠nh to√°n Mean Average Precision (mAP)
map_result = MeanAveragePrecision().update(predictions, targets).compute()

print("Mean Average Precision (mAP):", map_result)









map_result.plot()





unique_save_path= "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/yolov12s10032025_ver-dataset2/_ver1"


print(f'ƒê∆∞·ªùng d·∫´n: {unique_save_path}')


import supervision as sv

model = YOLO(f'/{unique_save_path}/runs/detect/train/weights/best.pt')


'''
√ù t∆∞·ªüng:
L·∫•y m·ªôt h√¨nh ·∫£nh ng·∫´u nhi√™n t·ª´ t·∫≠p d·ªØ li·ªáu.
D·ª± ƒëo√°n ƒë·ªëi t∆∞·ª£ng tr√™n ·∫£nh b·∫±ng m√¥ h√¨nh YOLO.
√Åp d·ª•ng NMS ƒë·ªÉ lo·∫°i b·ªè c√°c ph√°t hi·ªán tr√πng l·∫∑p.
V·∫Ω h·ªôp gi·ªõi h·∫°n v√† nh√£n l√™n ·∫£nh.
Hi·ªÉn th·ªã ·∫£nh ƒë√£ ƒë∆∞·ª£c ch√∫ th√≠ch.
'''
import random

# L·∫•y ng·∫´u nhi√™n ·∫£nh t·ª´ dataset
i = random.randint(0, len(ds))
image_path, image, target = ds[i]
print(f'Image path: {image_path}\n image: {image}\n target: {target}')

results = model(image, verbose=False)[0]
print(f'Result: {results}')
detections = sv.Detections.from_ultralytics(results).with_nms()
print('Display detections:', detections)
thread = 50/100
detections = detections[detections.confidence > thread]

box_annotator = sv.BoxAnnotator()
label_annotator = sv.LabelAnnotator()

# T·∫°o labels k·∫øt h·ª£p class name v√† confidence
labels = [
    f"{model.names[class_id]} {confidence:.0%}"  # S·ª≠ d·ª•ng model.names thay v√¨ ds.names
    for class_id, confidence in
    zip(detections.class_id, detections.confidence)
]

annotated_image = image.copy()

# V·∫Ω bounding boxes v√† labels
annotated_image = box_annotator.annotate(
    scene=annotated_image,
    detections=detections
)
annotated_image = label_annotator.annotate(
    scene=annotated_image,
    detections=detections,
    labels=labels  # Th√™m labels v√†o ƒë√¢y
)

sv.plot_image(annotated_image)








import glob
from IPython.display import Image, display

for imageName in glob.glob(f'{unique_save_path}/runs/detect/train/*.jpg')[:10]: #assuming JPG
    display(Image(filename=imageName))














import os
import cv2
from ultralytics import YOLO
import supervision as sv
from collections import Counter
import matplotlib.pyplot as plt
import numpy as np

# ----------------- C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N -----------------
# ----------------- C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N -----------------
unique_save_path = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/yolov12s10032025_ver-dataset2/_ver1"  # Thay b·∫±ng ƒë∆∞·ªùng d·∫´n th·ª±c t·∫ø ƒë·∫øn th∆∞ m·ª•c ch·ª©a m√¥ h√¨nh
data_path_working = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/Dataset"  # Thay b·∫±ng ƒë∆∞·ªùng d·∫´n th·ª±c t·∫ø ƒë·∫øn th∆∞ m·ª•c ch·ª©a d·ªØ li·ªáu

# Th∆∞ m·ª•c ch·ª©a ·∫£nh v√† ground truth (annotation) theo ƒë·ªãnh d·∫°ng YOLO
image_dir = os.path.join(data_path_working, "Student-Behavior-Recognition-2/test/images")
gt_dir = os.path.join(data_path_working, "Student-Behavior-Recognition-2/test/labels")

# Th∆∞ m·ª•c ƒë·ªÉ export nh·ªØng ·∫£nh c√≥ d·ª± ƒëo√°n sai
export_folder = os.path.join(unique_save_path, "wrong_predictions")
os.makedirs(export_folder, exist_ok=True)

# ----------------- H√ÄM H·ªñ TR·ª¢ -----------------
def compute_iou(box1, box2):
    """
    T√≠nh IoU gi·ªØa 2 bounding box v·ªõi ƒë·ªãnh d·∫°ng [x1, y1, x2, y2].
    """
    x_left = max(box1[0], box2[0])
    y_top = max(box1[1], box2[1])
    x_right = min(box1[2], box2[2])
    y_bottom = min(box1[3], box2[3])
    
    if x_right < x_left or y_bottom < y_top:
        return 0.0

    intersection_area = (x_right - x_left) * (y_bottom - y_top)
    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])
    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])
    
    iou = intersection_area / float(box1_area + box2_area - intersection_area)
    return iou

def parse_ground_truth(gt_file, img_width, img_height):
    """
    ƒê·ªçc file annotation ƒë·ªãnh d·∫°ng YOLO:
      M·ªói d√≤ng: <class_id> <x_center> <y_center> <width> <height>
    C√°c gi√° tr·ªã ƒë∆∞·ª£c chu·∫©n h√≥a theo k√≠ch th∆∞·ªõc ·∫£nh, chuy·ªÉn ƒë·ªïi sang ƒë·ªãnh d·∫°ng [x1, y1, x2, y2].
    Tr·∫£ v·ªÅ danh s√°ch c√°c tuple: (box, class_id)
    """
    items = []
    if not os.path.exists(gt_file):
        return items
    with open(gt_file, 'r') as f:
        for line in f.readlines():
            parts = line.strip().split()
            if len(parts) != 5:
                continue
            cls = int(parts[0])
            x_center = float(parts[1])
            y_center = float(parts[2])
            width = float(parts[3])
            height = float(parts[4])
            x1 = int((x_center - width/2) * img_width)
            y1 = int((y_center - height/2) * img_height)
            x2 = int((x_center + width/2) * img_width)
            y2 = int((y_center + height/2) * img_height)
            items.append(([x1, y1, x2, y2], cls))
    return items

# ----------------- L·∫§Y DANH S√ÅCH ·∫¢NH -----------------
image_files = [
    os.path.join(image_dir, f)
    for f in os.listdir(image_dir)
    if f.lower().endswith((".jpg", ".jpeg", ".png"))
]

# ----------------- KH·ªûI T·∫†O M√î H√åNH -----------------
model_path = os.path.join(unique_save_path, "runs/detect/train/weights/unfreezed_model.pt")
model = YOLO(model_path)

# Annotators ƒë·ªÉ v·∫Ω bounding box v√† label (n·∫øu c·∫ßn)
box_annotator = sv.BoxAnnotator()
label_annotator = sv.LabelAnnotator()

# ----------------- BI·∫æN TH·ªêNG K√ä -----------------
global_TP = 0
global_FP = 0
global_FN = 0
iou_threshold = 0.5  # Ng∆∞·ª°ng IoU ƒë·ªÉ x√°c ƒë·ªãnh matching
wrong_images_list = []  # L∆∞u c√°c ·∫£nh c√≥ d·ª± ƒëo√°n sai

# ----------------- X·ª¨ L√ù ·∫¢NH -----------------
for image_path in image_files:
    # ƒê·ªçc ·∫£nh
    image = cv2.imread(image_path)
    if image is None:
        print(f"Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh: {image_path}")
        continue
    img_height, img_width = image.shape[:2]
    
    # Ch·∫°y m√¥ h√¨nh YOLO ƒë·ªÉ d·ª± ƒëo√°n
    results = model(image, verbose=False)[0]
    detections = sv.Detections.from_ultralytics(results)
    
    # L·∫•y danh s√°ch bounding box d·ª± ƒëo√°n v√† class_id d·ª± ƒëo√°n
    pred_boxes = detections.xyxy if hasattr(detections, "xyxy") else []
    pred_class_ids = detections.class_id if hasattr(detections, "class_id") else []
    
    # L·∫•y ground truth t·ª´ file .txt t∆∞∆°ng ·ª©ng (v·ªõi c·∫£ box v√† true class)
    base_filename = os.path.splitext(os.path.basename(image_path))[0]
    gt_file = os.path.join(gt_dir, base_filename + ".txt")
    gt_items = parse_ground_truth(gt_file, img_width, img_height)
    
    TP_img = 0
    FP_img = 0
    misclassified_boxes = []  # L∆∞u tuple: (box, predicted_label, true_label)
    false_positive_boxes = [] # N·∫øu kh√¥ng c√≥ matching ground truth
    matched_gt = [False] * len(gt_items)
    
    for i, pred_box in enumerate(pred_boxes):
        best_iou = 0
        best_idx = -1
        for idx, (gt_box, gt_cls) in enumerate(gt_items):
            if matched_gt[idx]:
                continue
            iou = compute_iou(pred_box, gt_box)
            if iou > best_iou:
                best_iou = iou
                best_idx = idx
        # L·∫•y nh√£n d·ª± ƒëo√°n s·ª≠ d·ª•ng .get() ƒë·ªÉ ƒë·∫£m b·∫£o tr·∫£ v·ªÅ ƒë√∫ng true label n·∫øu c√≥
        if i < len(pred_class_ids):
            cid = int(pred_class_ids[i])
            predicted_label = model.names.get(cid, str(cid)) if hasattr(model, "names") else str(cid)
        else:
            predicted_label = "unknown"
        if best_iou >= iou_threshold and best_idx != -1:
            gt_cls = gt_items[best_idx][1]
            true_label = model.names.get(gt_cls, str(gt_cls)) if hasattr(model, "names") else str(gt_cls)
            matched_gt[best_idx] = True
            if predicted_label == true_label:
                TP_img += 1
            else:
                FP_img += 1
                misclassified_boxes.append((pred_box, predicted_label, true_label))
        else:
            FP_img += 1
            false_positive_boxes.append((pred_box, predicted_label, "none"))
    
    FN_img = len(gt_items) - TP_img
    global_TP += TP_img
    global_FP += FP_img
    global_FN += FN_img

    # N·∫øu c√≥ l·ªói (FP ho·∫∑c FN > 0), export ·∫£nh ƒë√£ annotate
    if FP_img > 0 or FN_img > 0:
        wrong_images_list.append(image_path)
        annotated_image = image.copy()
        annotated_image = box_annotator.annotate(scene=annotated_image, detections=detections)
        annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections)
        
        # V·ªõi m·ªói box b·ªã ph√¢n lo·∫°i sai, annotate ch·ªØ "predicted_label - true_label" ngay ph√≠a tr√™n bounding box
        for box, predicted_label, true_label in misclassified_boxes:
            x1, y1, x2, y2 = map(int, box)
            pos_y = y1 - 10 if y1 - 10 > 10 else y1 + 20
            text = f"{predicted_label} - 0"
            cv2.putText(annotated_image, text, (x1, pos_y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
        
        # N·∫øu mu·ªën annotate c√°c false positive kh√¥ng c√≥ matching ground truth, uncomment ƒëo·∫°n b√™n d∆∞·ªõi:
        # for box, predicted_label, _ in false_positive_boxes:
        #     x1, y1, x2, y2 = map(int, box)
        #     pos_y = y1 - 10 if y1 - 10 > 10 else y1 + 20
        #     text = f"{predicted_label} - none"
        #     cv2.putText(annotated_image, text, (x1, pos_y),
        #                 cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
        
        export_path = os.path.join(export_folder, os.path.basename(image_path))
        cv2.imwrite(export_path, annotated_image)
        print(f"Exported wrong prediction: {os.path.basename(image_path)}")

# ----------------- T·ªîNG K·∫æT -----------------
print("\n------------------ K·∫æT QU·∫¢ ------------------")
print("S·ªë ·∫£nh ƒë√£ x·ª≠ l√Ω:", len(image_files))
print("S·ªë ·∫£nh c√≥ d·ª± ƒëo√°n sai:", len(wrong_images_list))
print(f"T·ªïng TP: {global_TP}, T·ªïng FP: {global_FP}, T·ªïng FN: {global_FN}")

precision_overall = global_TP / (global_TP + global_FP) if (global_TP + global_FP) > 0 else 0
recall_overall = global_TP / (global_TP + global_FN) if (global_TP + global_FN) > 0 else 0
f1_overall = 2 * precision_overall * recall_overall / (precision_overall + recall_overall) if (precision_overall + recall_overall) > 0 else 0

print(f"ƒê·ªô ch√≠nh x√°c t·ªïng th·ªÉ (Precision): {precision_overall:.2f}")
print(f"ƒê·ªô nh·∫°y (Recall): {recall_overall:.2f}")
print(f"F1-score: {f1_overall:.2f}")






import os                     # Th∆∞ vi·ªán thao t√°c v·ªõi h·ªá th·ªëng file
import cv2                    # Th∆∞ vi·ªán x·ª≠ l√Ω ·∫£nh
import numpy as np            # Th∆∞ vi·ªán x·ª≠ l√Ω s·ªë li·ªáu
from ultralytics import YOLO   # Import m√¥ h√¨nh YOLO t·ª´ ultralytics
import supervision as sv      # Th∆∞ vi·ªán h·ªó tr·ª£ gi√°m s√°t (n·∫øu c·∫ßn)
import json                   # Th∆∞ vi·ªán x·ª≠ l√Ω JSON
import shutil                 # Th∆∞ vi·ªán h·ªó tr·ª£ sao ch√©p file, di chuy·ªÉn file,...
from datetime import datetime # Th∆∞ vi·ªán l√†m vi·ªác v·ªõi th·ªùi gian

# ----------------- C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N -----------------
# ƒê∆∞·ªùng d·∫´n ƒë·∫øn file m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
model_path = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/yolov12s10032025_ver-dataset2/_ver1/runs/detect/train/weights/best.pt"
# ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a d·ªØ li·ªáu (·∫£nh v√† file nh√£n ground truth)
data_path = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/Dataset/Student-Behavior-Recognition-2/test"

# ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a ·∫£nh v√† nh√£n
image_dir = os.path.join(data_path, "images")
gt_dir = os.path.join(data_path, "labels")

# T·∫°o th∆∞ m·ª•c xu·∫•t ·∫£nh c√≥ d·ª± ƒëo√°n sai v·ªõi t√™n d·ª±a tr√™n th·ªùi gian hi·ªán t·∫°i
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
export_base_folder = f"wrong_predictions_{timestamp}"
os.makedirs(export_base_folder, exist_ok=True)

# T·∫°o c√°c th∆∞ m·ª•c con cho t·ª´ng lo·∫°i l·ªói: false positives, false negatives, class errors
false_positive_dir = os.path.join(export_base_folder, "false_positives")
false_negative_dir = os.path.join(export_base_folder, "false_negatives")
class_error_dir = os.path.join(export_base_folder, "class_errors")

for dir_path in [false_positive_dir, false_negative_dir, class_error_dir]:
    os.makedirs(dir_path, exist_ok=True)

# ----------------- H√ÄM H·ªñ TR·ª¢ -----------------
def convert_yolo_to_xyxy(yolo_box, img_width, img_height):
    """
    Chuy·ªÉn ƒë·ªïi bounding box t·ª´ ƒë·ªãnh d·∫°ng YOLO (x_center, y_center, width, height)
    sang ƒë·ªãnh d·∫°ng (x1, y1, x2, y2) theo k√≠ch th∆∞·ªõc ·∫£nh.
    """
    x_center, y_center, width, height = yolo_box  # L·∫•y gi√° tr·ªã t·ªça ƒë·ªô trung t√¢m v√† k√≠ch th∆∞·ªõc box
    x1 = int((x_center - width/2) * img_width)      # T√≠nh x1
    y1 = int((y_center - height/2) * img_height)      # T√≠nh y1
    x2 = int((x_center + width/2) * img_width)        # T√≠nh x2
    y2 = int((y_center + height/2) * img_height)        # T√≠nh y2
    return [x1, y1, x2, y2]

def compute_iou(box1, box2):
    """
    T√≠nh Intersection over Union (IoU) gi·ªØa hai bounding box theo ƒë·ªãnh d·∫°ng [x1, y1, x2, y2].
    """
    x_left = max(box1[0], box2[0])   # T·ªça ƒë·ªô x c·ªßa ƒëi·ªÉm giao nhau b√™n tr√°i
    y_top = max(box1[1], box2[1])    # T·ªça ƒë·ªô y c·ªßa ƒëi·ªÉm giao nhau ph√≠a tr√™n
    x_right = min(box1[2], box2[2])  # T·ªça ƒë·ªô x c·ªßa ƒëi·ªÉm giao nhau b√™n ph·∫£i
    y_bottom = min(box1[3], box2[3]) # T·ªça ƒë·ªô y c·ªßa ƒëi·ªÉm giao nhau ph√≠a d∆∞·ªõi
    
    # N·∫øu kh√¥ng c√≥ giao nhau, tr·∫£ v·ªÅ IoU = 0
    if x_right < x_left or y_bottom < y_top:
        return 0.0

    # T√≠nh di·ªán t√≠ch giao nhau
    intersection_area = (x_right - x_left) * (y_bottom - y_top)
    # T√≠nh di·ªán t√≠ch c·ªßa t·ª´ng box
    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])
    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])
    
    # T√≠nh IoU = di·ªán t√≠ch giao nhau / (di·ªán t√≠ch h·ª£p c·ªßa 2 box)
    iou = intersection_area / float(box1_area + box2_area - intersection_area)
    return iou

def parse_ground_truth(gt_file, img_width, img_height):
    """
    ƒê·ªçc file annotation ƒë·ªãnh d·∫°ng YOLO v√† tr·∫£ v·ªÅ danh s√°ch bounding box c√πng v·ªõi class id.
    """
    boxes = []      # Danh s√°ch c√°c box (d∆∞·ªõi d·∫°ng [x1, y1, x2, y2])
    class_ids = []  # Danh s√°ch class id t∆∞∆°ng ·ª©ng v·ªõi c√°c box
    if not os.path.exists(gt_file):
        return boxes, class_ids  # N·∫øu file kh√¥ng t·ªìn t·∫°i th√¨ tr·∫£ v·ªÅ danh s√°ch r·ªóng
    
    with open(gt_file, 'r') as f:
        for line in f.readlines():
            parts = line.strip().split()  # T√°ch c√°c gi√° tr·ªã trong d√≤ng
            if len(parts) != 5:           # N·∫øu kh√¥ng ƒë·ªß 5 gi√° tr·ªã th√¨ b·ªè qua d√≤ng n√†y
                continue
                
            class_id, x_center, y_center, width, height = map(float, parts)
            class_ids.append(int(class_id))
            
            # Chuy·ªÉn ƒë·ªïi t·ª´ ƒë·ªãnh d·∫°ng YOLO sang [x1, y1, x2, y2]
            box = convert_yolo_to_xyxy([x_center, y_center, width, height], img_width, img_height)
            boxes.append(box)
            
    return boxes, class_ids

def draw_box(image, box, color, label=None, thickness=2):
    """
    V·∫Ω bounding box l√™n ·∫£nh v√† th√™m label n·∫øu c√≥.
    """
    x1, y1, x2, y2 = map(int, box)
    cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)  # V·∫Ω h√¨nh ch·ªØ nh·∫≠t
    
    if label:
        # T√≠nh k√≠ch th∆∞·ªõc ch·ªØ ƒë·ªÉ t·∫°o n·ªÅn cho label
        text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]
        # V·∫Ω n·ªÅn cho label (h·ªôp ch·ªØ)
        cv2.rectangle(image, (x1, y1 - text_size[1] - 10), (x1 + text_size[0], y1), color, -1)
        # V·∫Ω ch·ªØ label l√™n ·∫£nh
        cv2.putText(image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

# ----------------- KH·ªûI T·∫†O M√î H√åNH -----------------
model = YOLO(model_path)  # Kh·ªüi t·∫°o m√¥ h√¨nh YOLO v·ªõi file weights ƒë√£ cho
iou_threshold = 0.5       # Ng∆∞·ª°ng IoU ƒë·ªÉ x√°c ƒë·ªãnh true positive

# L·∫•y danh s√°ch t√™n l·ªõp t·ª´ m√¥ h√¨nh (n·∫øu c√≥)
class_names = model.names if hasattr(model, "names") else {}

# ----------------- BI·∫æN TH·ªêNG K√ä -----------------
stats = {
    "total_images": 0,         # T·ªïng s·ªë ·∫£nh ƒë√£ x·ª≠ l√Ω
    "wrong_images": 0,         # S·ªë ·∫£nh c√≥ l·ªói
    "total_objects": 0,        # T·ªïng s·ªë ƒë·ªëi t∆∞·ª£ng ground truth
    "false_positives": 0,      # S·ªë d·ª± ƒëo√°n th·ª´a
    "false_negatives": 0,      # S·ªë ƒë·ªëi t∆∞·ª£ng b·ªè s√≥t
    "class_errors": 0,         # S·ªë l·ªói nh·∫≠n d·∫°ng sai l·ªõp
    "class_error_details": {}, # Th·ªëng k√™ chi ti·∫øt l·ªói nh·∫≠n d·∫°ng (v√≠ d·ª•: "class A -> class B")
    "error_by_class": {}       # Th·ªëng k√™ l·ªói theo t·ª´ng l·ªõp ƒë·ªëi t∆∞·ª£ng
}

# ----------------- X·ª¨ L√ù ·∫¢NH -----------------
# L·∫•y danh s√°ch file ·∫£nh t·ª´ th∆∞ m·ª•c
image_files = [f for f in os.listdir(image_dir) if f.lower().endswith((".jpg", ".jpeg", ".png"))]
error_details = []  # Danh s√°ch l∆∞u chi ti·∫øt l·ªói cho m·ªói ·∫£nh

# L·∫∑p qua t·ª´ng ·∫£nh
for image_file in image_files:
    stats["total_images"] += 1  # C·∫≠p nh·∫≠t s·ªë ·∫£nh ƒë√£ x·ª≠ l√Ω
    
    # ƒê·ªçc ·∫£nh t·ª´ file
    image_path = os.path.join(image_dir, image_file)
    image = cv2.imread(image_path)
    if image is None:
        print(f"Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh: {image_path}")
        continue  # B·ªè qua ·∫£nh n·∫øu kh√¥ng ƒë·ªçc ƒë∆∞·ª£c
    
    img_height, img_width = image.shape[:2]  # L·∫•y k√≠ch th∆∞·ªõc ·∫£nh
    
    # ƒê·ªçc file ground truth t∆∞∆°ng ·ª©ng v·ªõi ·∫£nh
    base_filename = os.path.splitext(image_file)[0]
    gt_file = os.path.join(gt_dir, base_filename + ".txt")
    gt_boxes, gt_class_ids = parse_ground_truth(gt_file, img_width, img_height)
    
    stats["total_objects"] += len(gt_boxes)  # C·∫≠p nh·∫≠t s·ªë ƒë·ªëi t∆∞·ª£ng ground truth
    
    # Ch·∫°y m√¥ h√¨nh YOLO tr√™n ·∫£nh
    results = model(image, verbose=False)[0]
    
    # L·∫•y k·∫øt qu·∫£ d·ª± ƒëo√°n t·ª´ m√¥ h√¨nh
    pred_boxes = []        # Danh s√°ch c√°c bounding box d·ª± ƒëo√°n
    pred_class_ids = []    # Danh s√°ch class id d·ª± ƒëo√°n
    pred_conf_scores = []  # Danh s√°ch ƒë·ªô tin c·∫≠y d·ª± ƒëo√°n
    
    if len(results.boxes) > 0:
        for box in results.boxes:
            pred_boxes.append(box.xyxy[0].cpu().numpy())  # Chuy·ªÉn box v·ªÅ d·∫°ng numpy array
            pred_class_ids.append(int(box.cls.cpu().numpy()[0]))
            pred_conf_scores.append(float(box.conf.cpu().numpy()[0]))
    
    # Kh·ªüi t·∫°o danh s√°ch l∆∞u c√°c l·ªói cho ·∫£nh n√†y
    false_positives = []  # L·ªói d·ª± ƒëo√°n th·ª´a (FP)
    false_negatives = []  # L·ªói b·ªè s√≥t (FN)
    class_errors = []     # L·ªói nh·∫≠n d·∫°ng sai l·ªõp (CE)
    
    # T·∫°o b·∫£n sao ·∫£nh ƒë·ªÉ v·∫Ω l·ªói
    annotated_image = image.copy()
    has_error = False  # C·ªù ƒë√°nh d·∫•u c√≥ l·ªói trong ·∫£nh n√†y hay kh√¥ng
    
    # T·∫°o danh s√°ch ƒë√°nh d·∫•u c√°c ƒë·ªëi t∆∞·ª£ng ƒë√£ ƒë∆∞·ª£c gh√©p (matched) gi·ªØa ground truth v√† d·ª± ƒëo√°n
    matched_gt = [False] * len(gt_boxes)
    matched_pred = [False] * len(pred_boxes)
    
    # --------- B∆∞·ªõc 1: X·ª≠ l√Ω true positive v√† class error ---------
    for pred_idx, pred_box in enumerate(pred_boxes):
        best_iou = 0
        best_gt_idx = -1
        
        # T√¨m ground truth box c√≥ IoU l·ªõn nh·∫•t v·ªõi d·ª± ƒëo√°n hi·ªán t·∫°i
        for gt_idx, gt_box in enumerate(gt_boxes):
            iou = compute_iou(pred_box, gt_box)
            if iou > best_iou:
                best_iou = iou
                best_gt_idx = gt_idx
        
        # N·∫øu IoU v∆∞·ª£t ng∆∞·ª°ng, coi nh∆∞ d·ª± ƒëo√°n tr√πng kh·ªõp v·ªã tr√≠
        if best_iou >= iou_threshold:
            matched_pred[pred_idx] = True
            matched_gt[best_gt_idx] = True
            
            # Ki·ªÉm tra l·ªói nh·∫≠n d·∫°ng sai l·ªõp (class error)
            if pred_class_ids[pred_idx] != gt_class_ids[best_gt_idx]:
                has_error = True
                stats["class_errors"] += 1  # C·∫≠p nh·∫≠t th·ªëng k√™ l·ªói class
                
                # L·∫•y t√™n l·ªõp c·ªßa ground truth v√† d·ª± ƒëo√°n
                gt_class = class_names.get(gt_class_ids[best_gt_idx], str(gt_class_ids[best_gt_idx]))
                pred_class = class_names.get(pred_class_ids[pred_idx], str(pred_class_ids[pred_idx]))
                error_key = f"{gt_class} -> {pred_class}"  # T·∫°o key cho th·ªëng k√™ l·ªói chi ti·∫øt
                
                # C·∫≠p nh·∫≠t th·ªëng k√™ chi ti·∫øt l·ªói nh·∫≠n d·∫°ng
                if error_key not in stats["class_error_details"]:
                    stats["class_error_details"][error_key] = 0
                stats["class_error_details"][error_key] += 1
                
                # C·∫≠p nh·∫≠t th·ªëng k√™ l·ªói theo l·ªõp: ƒë·∫£m b·∫£o kh·ªüi t·∫°o ƒë·∫ßy ƒë·ªß c√°c key
                if gt_class not in stats["error_by_class"]:
                    stats["error_by_class"][gt_class] = {
                        "total": 0,
                        "false_positives": 0,
                        "false_negatives": 0,
                        "class_errors": 0
                    }
                stats["error_by_class"][gt_class]["total"] += 1
                stats["error_by_class"][gt_class]["class_errors"] += 1
                
                # L∆∞u th√¥ng tin l·ªói class cho ·∫£nh hi·ªán t·∫°i
                class_errors.append((
                    pred_box,
                    gt_class_ids[best_gt_idx],
                    pred_class_ids[pred_idx],
                    pred_conf_scores[pred_idx]
                ))
                
                # V·∫Ω box l·ªói class l√™n ·∫£nh (m√†u cam) k√®m nh√£n l·ªói
                gt_class_name = class_names.get(gt_class_ids[best_gt_idx], f"class_{gt_class_ids[best_gt_idx]}")
                pred_class_name = class_names.get(pred_class_ids[pred_idx], f"class_{pred_class_ids[pred_idx]}")
                label = f"L·ªói: {gt_class_name} -> {pred_class_name} ({pred_conf_scores[pred_idx]:.2f})"
                draw_box(annotated_image, pred_box, (0, 165, 255), label)
    
    # --------- B∆∞·ªõc 2: X√°c ƒë·ªãnh false positives (d·ª± ƒëo√°n th·ª´a) ---------
    for pred_idx, matched in enumerate(matched_pred):
        if not matched:  # N·∫øu d·ª± ƒëo√°n kh√¥ng ƒë∆∞·ª£c gh√©p v·ªõi b·∫•t k·ª≥ ground truth n√†o
            has_error = True
            stats["false_positives"] += 1
            
            pred_class = class_names.get(pred_class_ids[pred_idx], str(pred_class_ids[pred_idx]))
            # ƒê·∫£m b·∫£o kh·ªüi t·∫°o ƒë·∫ßy ƒë·ªß c√°c key cho l·ªõp d·ª± ƒëo√°n
            if pred_class not in stats["error_by_class"]:
                stats["error_by_class"][pred_class] = {
                    "total": 0,
                    "false_positives": 0,
                    "false_negatives": 0,
                    "class_errors": 0
                }
            stats["error_by_class"][pred_class]["false_positives"] += 1
            
            # L∆∞u th√¥ng tin false positive cho ·∫£nh hi·ªán t·∫°i
            false_positives.append((
                pred_boxes[pred_idx],
                pred_class_ids[pred_idx],
                pred_conf_scores[pred_idx]
            ))
            
            # V·∫Ω box false positive l√™n ·∫£nh (m√†u ƒë·ªè) k√®m nh√£n
            pred_class_name = class_names.get(pred_class_ids[pred_idx], f"class_{pred_class_ids[pred_idx]}")
            label = f"FP: {pred_class_name} ({pred_conf_scores[pred_idx]:.2f})"
            draw_box(annotated_image, pred_boxes[pred_idx], (0, 0, 255), label)
    
    # --------- B∆∞·ªõc 3: X√°c ƒë·ªãnh false negatives (b·ªè s√≥t ƒë·ªëi t∆∞·ª£ng) ---------
    for gt_idx, matched in enumerate(matched_gt):
        if not matched:  # N·∫øu ground truth kh√¥ng ƒë∆∞·ª£c gh√©p v·ªõi d·ª± ƒëo√°n n√†o
            has_error = True
            stats["false_negatives"] += 1
            
            gt_class = class_names.get(gt_class_ids[gt_idx], str(gt_class_ids[gt_idx]))
            # ƒê·∫£m b·∫£o kh·ªüi t·∫°o ƒë·∫ßy ƒë·ªß c√°c key cho l·ªõp ground truth
            if gt_class not in stats["error_by_class"]:
                stats["error_by_class"][gt_class] = {
                    "total": 0,
                    "false_positives": 0,
                    "false_negatives": 0,
                    "class_errors": 0
                }
            stats["error_by_class"][gt_class]["total"] += 1
            stats["error_by_class"][gt_class]["false_negatives"] += 1
            
            # L∆∞u th√¥ng tin false negative cho ·∫£nh hi·ªán t·∫°i
            false_negatives.append((
                gt_boxes[gt_idx],
                gt_class_ids[gt_idx]
            ))
            
            # V·∫Ω box false negative l√™n ·∫£nh (m√†u xanh l√°) k√®m nh√£n
            gt_class_name = class_names.get(gt_class_ids[gt_idx], f"class_{gt_class_ids[gt_idx]}")
            label = f"FN: {gt_class_name}"
            draw_box(annotated_image, gt_boxes[gt_idx], (0, 255, 0), label)
    
    # --------- Xu·∫•t ·∫£nh l·ªói n·∫øu c√≥ b·∫•t k·ª≥ l·ªói n√†o ---------
    if has_error:
        stats["wrong_images"] += 1
        
        # L∆∞u chi ti·∫øt l·ªói c·ªßa ·∫£nh v√†o danh s√°ch error_details
        image_error = {
            "image": image_file,
            "false_positives": len(false_positives),
            "false_negatives": len(false_negatives),
            "class_errors": len(class_errors),
            "details": {
                "false_positives": [
                    {
                        "box": box.tolist(),
                        "class": class_names.get(class_id, str(class_id)),
                        "confidence": conf
                    }
                    for box, class_id, conf in false_positives
                ],
                "false_negatives": [
                    {
                        "box": box,
                        "class": class_names.get(class_id, str(class_id))
                    }
                    for box, class_id in false_negatives
                ],
                "class_errors": [
                    {
                        "box": box.tolist(),
                        "gt_class": class_names.get(gt_class_id, str(gt_class_id)),
                        "pred_class": class_names.get(pred_class_id, str(pred_class_id)),
                        "confidence": conf
                    }
                    for box, gt_class_id, pred_class_id, conf in class_errors
                ]
            }
        }
        error_details.append(image_error)
        
        # Ghi t·ªïng s·ªë l·ªói l√™n ·∫£nh
        cv2.putText(
            annotated_image,
            f"FP: {len(false_positives)}, FN: {len(false_negatives)}, CE: {len(class_errors)}",
            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2
        )
        
        # L∆∞u ·∫£nh c√≥ l·ªói v√†o c√°c th∆∞ m·ª•c t∆∞∆°ng ·ª©ng
        if len(false_positives) > 0:
            fp_path = os.path.join(false_positive_dir, image_file)
            cv2.imwrite(fp_path, annotated_image)
            
        if len(false_negatives) > 0:
            fn_path = os.path.join(false_negative_dir, image_file)
            cv2.imwrite(fn_path, annotated_image)
            
        if len(class_errors) > 0:
            ce_path = os.path.join(class_error_dir, image_file)
            cv2.imwrite(ce_path, annotated_image)
            
        # L∆∞u ·∫£nh l·ªói v√†o th∆∞ m·ª•c g·ªëc ƒë·ªÉ d·ªÖ qu·∫£n l√Ω
        all_errors_path = os.path.join(export_base_folder, image_file)
        cv2.imwrite(all_errors_path, annotated_image)
        
        print(f"ƒê√£ x·ª≠ l√Ω ·∫£nh {image_file}: FP={len(false_positives)}, FN={len(false_negatives)}, CE={len(class_errors)}")

# ----------------- T·∫†O B√ÅO C√ÅO -----------------
# T√≠nh to√°n c√°c ch·ªâ s·ªë precision, recall v√† f1-score
precision = 0 if (stats["total_objects"] - stats["false_negatives"] + stats["false_positives"]) == 0 else \
           (stats["total_objects"] - stats["false_negatives"]) / (stats["total_objects"] - stats["false_negatives"] + stats["false_positives"])
           
recall = 0 if stats["total_objects"] == 0 else \
         (stats["total_objects"] - stats["false_negatives"]) / stats["total_objects"]
         
f1_score = 0 if (precision + recall) == 0 else 2 * precision * recall / (precision + recall)

# T·∫°o b√°o c√°o t·ªïng h·ª£p d·∫°ng JSON
report = {
    "summary": {
        "total_images": stats["total_images"],
        "wrong_images": stats["wrong_images"],
        "total_objects": stats["total_objects"],
        "false_positives": stats["false_positives"],
        "false_negatives": stats["false_negatives"],
        "class_errors": stats["class_errors"],
        "precision": precision,
        "recall": recall,
        "f1_score": f1_score
    },
    "class_error_details": stats["class_error_details"],
    "error_by_class": stats["error_by_class"],
    "image_errors": error_details
}

# L∆∞u b√°o c√°o d·∫°ng JSON v√†o file
report_path = os.path.join(export_base_folder, "error_report.json")
with open(report_path, "w", encoding="utf-8") as f:
    json.dump(report, f, indent=2, ensure_ascii=False)

# T·∫°o b√°o c√°o d·∫°ng text v√† l∆∞u v√†o file
report_txt_path = os.path.join(export_base_folder, "error_report.txt")
with open(report_txt_path, "w", encoding="utf-8") as f:
    f.write("=== B√ÅO C√ÅO L·ªñI D·ª∞ ƒêO√ÅN ===\n\n")
    f.write(f"T·ªïng s·ªë ·∫£nh ƒë√£ x·ª≠ l√Ω: {stats['total_images']}\n")
    f.write(f"S·ªë ·∫£nh c√≥ d·ª± ƒëo√°n sai: {stats['wrong_images']} ({stats['wrong_images']/stats['total_images']*100:.2f}%)\n")
    f.write(f"T·ªïng s·ªë ƒë·ªëi t∆∞·ª£ng ground truth: {stats['total_objects']}\n")
    f.write(f"S·ªë false positives (d·ª± ƒëo√°n th·ª´a): {stats['false_positives']}\n")
    f.write(f"S·ªë false negatives (b·ªè s√≥t): {stats['false_negatives']}\n")
    f.write(f"S·ªë class errors (nh·∫≠n d·∫°ng sai l·ªõp): {stats['class_errors']}\n\n")
    
    f.write(f"Precision: {precision:.4f}\n")
    f.write(f"Recall: {recall:.4f}\n")
    f.write(f"F1-score: {f1_score:.4f}\n\n")
    
    f.write("=== CHI TI·∫æT L·ªñI NH·∫¨N D·∫†NG L·ªöP ===\n\n")
    for error_key, count in sorted(stats["class_error_details"].items(), key=lambda x: x[1], reverse=True):
        f.write(f"{error_key}: {count}\n")
    
    f.write("\n=== TH·ªêNG K√ä L·ªñI THEO L·ªöP ƒê·ªêI T∆Ø·ª¢NG ===\n\n")
    for class_name, errors in sorted(stats["error_by_class"].items()):
        total_errors = errors.get("false_positives", 0) + errors.get("false_negatives", 0) + errors.get("class_errors", 0)
        f.write(f"L·ªõp '{class_name}': {total_errors} l·ªói\n")
        if "false_positives" in errors:
            f.write(f"  - False positives: {errors['false_positives']}\n")
        if "false_negatives" in errors:
            f.write(f"  - False negatives: {errors['false_negatives']}\n")
        if "class_errors" in errors:
            f.write(f"  - Class errors: {errors['class_errors']}\n")
        f.write("\n")

# In k·∫øt qu·∫£ t·ªïng quan ra m√†n h√¨nh console
print(f"\n=== K·∫æT QU·∫¢ ===")
print(f"ƒê√£ x·ª≠ l√Ω {stats['total_images']} ·∫£nh, t√¨m th·∫•y {stats['wrong_images']} ·∫£nh c√≥ d·ª± ƒëo√°n sai")
print(f"False positives: {stats['false_positives']}, False negatives: {stats['false_negatives']}, Class errors: {stats['class_errors']}")
print(f"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1_score:.4f}")
print(f"C√°c ·∫£nh c√≥ l·ªói ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: {export_base_folder}")
print(f"B√°o c√°o chi ti·∫øt ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: {report_path}")

