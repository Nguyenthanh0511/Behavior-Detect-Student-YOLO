














!nvidia-smi


import torch
print("CUDA Available:", torch.cuda.is_available())
print("Torch Version:", torch.__version__)
print("GPU Name:", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "No GPU detected")






# 1. Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# 2. Di chuyển đến thư mục bạn muốn lưu trong Drive
%cd /content/drive/MyDrive


!pip install flash-attn --only-binary :all:





!git clone https://github.com/sunsmarterjie/yolov12.git


!pip install git+https://github.com/sunsmarterjie/yolov12.git roboflow supervision flash-attn





!pip install roboflow supervision flash-attn==2.0.2


!nvcc -V


pip install flash-attn==2.0.2



import os
print(os.getcwd())


from roboflow import Roboflow
import os
import shutil

%cd "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/Dataset/"


rf = Roboflow(api_key="JutTY4tTGxWHjEqJiZNb")
project = rf.workspace("nhan-dien-hanh-vi-trong-lop-hoc").project("student-behavior-recognition")
version = project.version(2)
dataset = version.download("yolov12")

# # Tải version 3 của dataset với format YOLOv5
print(f"Dữ liệu đã tải về: {dataset.location}")

# Đường dẫn lưu trữ trong Google Drive
# drive_dataset_path = '/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/Dataset/'

# # Tạo thư mục nếu chưa tồn tại
# os.makedirs(drive_dataset_path, exist_ok=True)

# # Sao chép toàn bộ thư mục dataset sang Google Drive
# shutil.copytree(dataset.location, drive_dataset_path, dirs_exist_ok=True)

# print(f"Đã sao chép dataset đến: {drive_dataset_path}")

# # In ra cấu trúc thư mục để kiểm tra
# import subprocess
# print("\nCấu trúc thư mục:")
# subprocess.run(f"tree {drive_dataset_path}", shell=True)


# In ra cấu trúc thư mục để kiểm tra
import subprocess
print("\nCấu trúc thư mục:")
subprocess.run(f"tree {drive_dataset_path}", shell=True)


!ls {drive_dataset_path}





!sed -i '$d' {drive_dataset_path}/data.yaml
!echo -e "test: ../test/images\ntrain: ../train/images\nval: ../valid/images" >> {drive_dataset_path}/data.yaml


!cat {drive_dataset_path}/data.yaml








data_yaml_path = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/Dataset/Student-Behavior-Recognition-2/data.yaml"





import os
import yaml
from collections import defaultdict
from PIL import Image
import matplotlib.pyplot as plt
import cv2
import random
import seaborn as sns

def analyze_dataset(yaml_path):
    # 1. Đọc và in thông tin YAML
    print("1. Đọc file YAML:")
    with open(yaml_path, 'r') as f:
        data = yaml.safe_load(f)
    # print(f"Nội dung YAML: {data}")

    root_path = os.path.dirname(yaml_path)
    class_names = data['names']
    print(f"\nClasses: {class_names}")

    # 2. Kiểm tra cấu trúc thư mục
    print("\n2. Cấu trúc thư mục:")
    print(f"Root path: {root_path}")
    print("Nội dung root:")
    print(os.listdir(root_path))

    # 3. Thu thập thống kê
    stats = {
        'train': defaultdict(lambda: {'count': 0, 'sizes': [], 'examples': []}),
        'valid': defaultdict(lambda: {'count': 0, 'sizes': [], 'examples': []}),
        'test': defaultdict(lambda: {'count': 0, 'sizes': [], 'examples': []})
    }

    for split in ['train', 'valid', 'test']:
        images_dir = os.path.join(root_path, split, 'images')
        labels_dir = os.path.join(root_path, split, 'labels')

        # print(f"\nXử lý {split} set:")
        # print(f"Images dir: {images_dir}")
        # print(f"Labels dir: {labels_dir}")

        if not os.path.exists(images_dir) or not os.path.exists(labels_dir):
            print(f"Không tìm thấy thư mục images hoặc labels cho {split}")
            continue

        # In mẫu nội dung labels
        label_files = os.listdir(labels_dir)
        if label_files:
            print("\nMẫu nội dung labels:")
            for label_file in label_files[:2]:
                # print(f"\nFile: {label_file}")
                with open(os.path.join(labels_dir, label_file), 'r') as f:
                    print(f.read())

        # Xử lý từng ảnh
        for img_file in os.listdir(images_dir):
            if img_file.endswith(('.jpg', '.jpeg', '.png')):
                img_path = os.path.join(images_dir, img_file)
                label_path = os.path.join(labels_dir, img_file.rsplit('.', 1)[0] + '.txt')

                if os.path.exists(label_path):
                    try:
                        img = cv2.imread(img_path)
                        if img is None:
                            print(f"Không thể đọc ảnh: {img_path}")
                            continue
                        height, width = img.shape[:2]

                        with open(label_path, 'r') as f:
                            label_content = f.read().strip()
                            if label_content:
                                for line in label_content.split('\n'):
                                    try:
                                        parts = line.strip().split()
                                        if len(parts) == 5:
                                            class_id = int(parts[0])
                                            if class_id < len(class_names):
                                                class_name = class_names[class_id]
                                                stats[split][class_name]['count'] += 1
                                                stats[split][class_name]['sizes'].append((width, height))
                                                stats[split][class_name]['examples'].append((img_path, line))
                                        # else:
                                        #     # print(f"Format label không đúng: {line}")
                                    except ValueError as e:
                                        print(f"Lỗi parse label: {str(e)}")
                    except Exception as e:
                        print(f"Lỗi xử lý {img_path}: {str(e)}")

    # 4. Visualize kết quả
    # 4.1 Biểu đồ số lượng objects
    plt.figure(figsize=(12, 6))
    splits = list(stats.keys())
    x = np.arange(len(class_names))
    width = 0.25

    colors = ['#2ecc71', '#3498db', '#e74c3c']
    for i, (split, color) in enumerate(zip(splits, colors)):
        counts = [stats[split][class_name]['count'] for class_name in class_names]
        plt.bar(x + i*width, counts, width, label=split, color=color)

    plt.xlabel('Classes', fontsize=12)
    plt.ylabel('Số lượng objects', fontsize=12)
    plt.title('Phân bố số lượng objects', fontsize=14)
    plt.xticks(x + width, class_names, rotation=45)
    plt.legend()
    plt.tight_layout()
    plt.show()

    # 4.2 Hiển thị ảnh mẫu
    def plot_samples(split, class_name, num_samples=3):
        examples = stats[split][class_name]['examples']
        if not examples:
            return

        samples = random.sample(examples, min(num_samples, len(examples)))
        fig, axes = plt.subplots(1, len(samples), figsize=(15, 5))
        if len(samples) == 1:
            axes = [axes]

        for ax, (img_path, label) in zip(axes, samples):
            img = cv2.imread(img_path)
            if img is None:
                print(f"Không thể đọc ảnh: {img_path}")
                continue

            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            height, width = img.shape[:2]

            try:
                parts = label.strip().split()
                if len(parts) == 5:
                    _, x_center, y_center, w, h = map(float, parts)

                    x1 = int((x_center - w/2) * width)
                    y1 = int((y_center - h/2) * height)
                    x2 = int((x_center + w/2) * width)
                    y2 = int((y_center + h/2) * height)

                    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
            except Exception as e:
                print(f"Lỗi vẽ bbox: {str(e)}")

            ax.imshow(img)
            ax.axis('off')
            ax.set_title(f'{split} - {class_name}')

        plt.tight_layout()
        plt.show()

    print("\nHiển thị ảnh mẫu:")
    for class_name in class_names:
        for split in splits:
            if stats[split][class_name]['count'] > 0:
                plot_samples(split, class_name)

    # 4.3 Biểu đồ kích thước ảnh
    plt.figure(figsize=(10, 6))
    for split, color in zip(splits, colors):
        all_sizes = []
        for class_name in class_names:
            all_sizes.extend(stats[split][class_name]['sizes'])
        if all_sizes:
            widths, heights = zip(*all_sizes)
            plt.scatter(widths, heights, alpha=0.6, label=split, color=color)

    plt.xlabel('Width (pixels)')
    plt.ylabel('Height (pixels)')
    plt.title('Phân bố kích thước ảnh')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

    # 5. In thống kê chi tiết
    print("\nThống kê chi tiết:")
    for split in stats:
        print(f"\n=== {split.upper()} ===")
        total = 0
        for class_name in stats[split]:
            count = stats[split][class_name]['count']
            sizes = stats[split][class_name]['sizes']
            total += count

            if count > 0:
                avg_width = np.mean([s[0] for s in sizes])
                avg_height = np.mean([s[1] for s in sizes])
                print(f"\nClass: {class_name}")
                print(f"- Số lượng: {count}")
                print(f"- Kích thước trung bình: {avg_width:.0f}x{avg_height:.0f}")

        print(f"\nTổng số objects: {total}")
analyze_dataset(data_yaml_path)





import os
import yaml
import cv2
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import random
from collections import defaultdict

def analyze_dataset(yaml_path):
    """Phân tích dataset YOLO với các tính năng:
    - Kiểm tra label hợp lệ
    - Thống kê kích thước bounding box
    - Phát hiện bất thường
    - Trực quan hóa dữ liệu
    """
    
    # 1. Đọc file cấu hình YAML
    with open(yaml_path, 'r') as f:
        data = yaml.safe_load(f)
    root_dir = os.path.dirname(yaml_path)
    class_names = data['names']
    print(f"✅ Đã đọc cấu hình từ {yaml_path}")
    print(f"📦 Số lớp: {len(class_names)} - Tên lớp: {class_names}")

    # 2. Khởi tạo cấu trúc lưu trữ thống kê
    stats = {
        split: {
            cls: {
                'count': 0,
                'widths': [],
                'heights': [],
                'areas': [],
                'examples': [],
                'invalid': 0
            } for cls in class_names
        } for split in ['train', 'valid', 'test']
    }

    # 3. Duyệt qua các tập dữ liệu
    for split in ['train', 'valid', 'test']:
        img_dir = os.path.join(root_dir, split, 'images')
        label_dir = os.path.join(root_dir, split, 'labels')

        if not os.path.exists(img_dir):
            print(f"⛔ Thiếu thư mục ảnh {split}")
            continue

        # 4. Xử lý từng ảnh
        for img_file in os.listdir(img_dir):
            if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                continue

            img_path = os.path.join(img_dir, img_file)
            label_path = os.path.join(label_dir, os.path.splitext(img_file)[0] + '.txt')

            if not os.path.exists(label_path):
                continue

            try:
                # 5. Đọc kích thước ảnh
                img = cv2.imread(img_path)
                if img is None:
                    print(f"❌ Không đọc được ảnh: {img_path}")
                    continue
                img_h, img_w = img.shape[:2]

                # 6. Xử lý từng label
                with open(label_path, 'r') as f:
                    for line in f:
                        line = line.strip()
                        if not line:
                            continue

                        parts = line.split()
                        # 7. Validate định dạng label
                        if len(parts) != 5:
                            stats[split][class_names[0]]['invalid'] += 1  # Giả định lớp đầu tiên cho lỗi
                            continue

                        try:
                            # 8. Chuyển đổi và kiểm tra tọa độ
                            class_id, xc, yc, w, h = map(float, parts)
                            if not (0 <= xc <= 1 and 0 <= yc <= 1 and 0 <= w <= 1 and 0 <= h <= 1):
                                stats[split][class_names[int(class_id)]]['invalid'] += 1
                                continue

                            # 9. Tính toán kích thước thực tế
                            box_w = w * img_w
                            box_h = h * img_h
                            area = box_w * box_h

                            # 10. Cập nhật thống kê
                            cls_name = class_names[int(class_id)]
                            stats[split][cls_name]['count'] += 1
                            stats[split][cls_name]['widths'].append(box_w)
                            stats[split][cls_name]['heights'].append(box_h)
                            stats[split][cls_name]['areas'].append(area)
                            stats[split][cls_name]['examples'].append(img_path)

                        except (ValueError, IndexError) as e:
                            print(f"Lỗi xử lý label: {str(e)}")
                            continue

            except Exception as e:
                print(f"Lỗi xử lý ảnh {img_path}: {str(e)}")

    # 11. Phân tích và hiển thị kết quả
    _visualize_distributions(stats, class_names)
    _generate_report(stats, class_names)

def _visualize_distributions(stats, classes):
    """Trực quan hóa phân bố kích thước bounding box"""
    n_classes = len(classes)
    n_cols = 2  # Số cột tùy chọn
    n_rows = (n_classes + n_cols - 1) // n_cols  # Tính số hàng cần thiết
    
    plt.figure(figsize=(14, 5*n_rows))  # Điều chỉnh kích thước theo số hàng
    
    # Vẽ biểu đồ cho từng lớp
    for idx, cls in enumerate(classes, 1):
        plt.subplot(n_rows, n_cols, idx)  # Sửa thành grid động
        
        all_widths = []
        all_heights = []
        for split in ['train', 'valid', 'test']:
            all_widths.extend(stats[split][cls]['widths'])
            all_heights.extend(stats[split][cls]['heights'])
        
        if all_widths:
            sns.histplot(x=all_widths, kde=True, color='blue', label='Width')
            sns.histplot(x=all_heights, kde=True, color='red', label='Height')
            plt.title(f'Phân bố kích thước - {cls}')
            plt.xlabel('Pixel')
            plt.legend()
    
    plt.tight_layout()
    plt.show()
    
    # Biểu đồ boxplot
    plt.figure(figsize=(12, 6))
    data = []
    labels = []
    for cls in classes:
        for split in ['train', 'valid', 'test']:
            if stats[split][cls]['areas']:
                data.append(stats[split][cls]['areas'])
                labels.append(f"{cls}_{split}")
    
    plt.boxplot(data, vert=False, patch_artist=True)
    plt.yticks(np.arange(1, len(labels)+1), labels)
    plt.title('Phân bố diện tích bounding box')
    plt.xlabel('Diện tích (pixel²)')
    plt.show()

def _generate_report(stats, classes):
    """Tạo báo cáo chi tiết"""
    print("\n📈 BÁO CÁO CHI TIẾT")
    
    for split in ['train', 'valid', 'test']:
        print(f"\n🔍 {split.upper()}")
        total = 0
        
        for cls in classes:
            cls_stats = stats[split][cls]
            if cls_stats['count'] == 0:
                continue
                
            # Tính các chỉ số thống kê
            widths = cls_stats['widths']
            heights = cls_stats['heights']
            areas = cls_stats['areas']
            
            report = {
                'count': cls_stats['count'],
                'width': {
                    'min': np.min(widths),
                    'max': np.max(widths),
                    'mean': np.mean(widths),
                    'median': np.median(widths)
                },
                'height': {
                    'min': np.min(heights),
                    'max': np.max(heights),
                    'mean': np.mean(heights),
                    'median': np.median(heights)
                },
                'area': {
                    'min': np.min(areas),
                    'max': np.max(areas),
                    'mean': np.mean(areas)
                },
                'invalid': cls_stats['invalid']
            }

            # In báo cáo
            print(f"\n🏷️ Lớp: {cls}")
            print(f"   - Số lượng: {report['count']}")
            print(f"   - Chiều rộng (px):")
            print(f"     Min: {report['width']['min']:.1f} | Max: {report['width']['max']:.1f}")
            print(f"     Trung bình: {report['width']['mean']:.1f} | Median: {report['width']['median']:.1f}")
            print(f"   - Chiều cao (px):")
            print(f"     Min: {report['height']['min']:.1f} | Max: {report['height']['max']:.1f}")
            print(f"     Trung bình: {report['height']['mean']:.1f} | Median: {report['height']['median']:.1f}")
            print(f"   - Diện tích (px²):")
            print(f"     Min: {report['area']['min']:.1f} | Max: {report['area']['max']:.1f}")
            print(f"     Trung bình: {report['area']['mean']:.1f}")
            print(f"   - Label không hợp lệ: {report['invalid']}")

            total += report['count']
        
        print(f"\nTổng số objects: {total}")

# Chạy chương trình
if __name__ == "__main__":
    analyze_dataset(data_yaml_path)





import os
import shutil
import yaml
from collections import defaultdict

def export_invalid_labels(yaml_path, output_dir):
    """
    Export các ảnh và label không hợp lệ vào thư mục riêng
    Đồng thời tạo báo cáo chi tiết
    """
    # 1. Đọc cấu hình dataset
    with open(yaml_path, 'r') as f:
        data = yaml.safe_load(f)
    root_dir = os.path.dirname(yaml_path)
    class_names = data['names']
    
    # 2. Tạo thư mục output
    invalid_dir = os.path.join(output_dir, 'invalid')
    os.makedirs(os.path.join(invalid_dir, 'images'), exist_ok=True)
    os.makedirs(os.path.join(invalid_dir, 'labels'), exist_ok=True)
    
    report = {
        'total_images': 0,
        'invalid_images': 0,
        'details': []
    }
    
    # 3. Duyệt qua các tập dữ liệu
    for split in ['train', 'valid', 'test']:
        img_dir = os.path.join(root_dir, split, 'images')
        label_dir = os.path.join(root_dir, split, 'labels')
        
        if not os.path.exists(img_dir):
            continue
            
        # 4. Xử lý từng ảnh
        for img_file in os.listdir(img_dir):
            report['total_images'] += 1
            img_path = os.path.join(img_dir, img_file)
            label_path = os.path.join(label_dir, os.path.splitext(img_file)[0] + '.txt')
            
            invalid_reasons = []
            
            # 5. Kiểm tra label
            if not os.path.exists(label_path):
                invalid_reasons.append('Missing label file')
            else:
                with open(label_path, 'r') as f:
                    lines = f.readlines()
                    if not lines:
                        invalid_reasons.append('Empty label file')
                    
                    for line_idx, line in enumerate(lines, 1):
                        line = line.strip()
                        parts = line.split()
                        
                        # Kiểm tra định dạng
                        if len(parts) != 5:
                            invalid_reasons.append(f'Line {line_idx}: Invalid format')
                            continue
                            
                        try:
                            # Validate giá trị
                            class_id, xc, yc, w, h = map(float, parts)
                            if not (0 <= xc <= 1 and 0 <= yc <= 1 and 0 <= w <= 1 and 0 <= h <= 1):
                                invalid_reasons.append(f'Line {line_idx}: Invalid coordinates')
                            
                            # Kiểm tra class ID
                            if int(class_id) >= len(class_names):
                                invalid_reasons.append(f'Line {line_idx}: Invalid class ID {class_id}')
                                
                        except ValueError:
                            invalid_reasons.append(f'Line {line_idx}: Conversion error')
            
            # 6. Nếu có lỗi, copy sang thư mục invalid
            if invalid_reasons:
                report['invalid_images'] += 1
                # Copy ảnh
                shutil.copy(img_path, os.path.join(invalid_dir, 'images', img_file))
                # Copy label (nếu tồn tại)
                if os.path.exists(label_path):
                    shutil.copy(label_path, os.path.join(invalid_dir, 'labels', os.path.basename(label_path)))
                
                # Ghi log lỗi
                report['details'].append({
                    'image': img_path,
                    'reasons': invalid_reasons
                })
    
    # 7. Tạo báo cáo
    with open(os.path.join(output_dir, 'invalid_report.txt'), 'w') as f:
        f.write(f"Tổng số ảnh đã kiểm tra: {report['total_images']}\n")
        f.write(f"Số ảnh có label không hợp lệ: {report['invalid_images']}\n\n")
        
        f.write("Chi tiết các lỗi:\n")
        for entry in report['details']:
            f.write(f"\nẢnh: {entry['image']}\n")
            for reason in entry['reasons']:
                f.write(f" - {reason}\n")
    
    print(f"✅ Đã export {report['invalid_images']} ảnh lỗi vào: {invalid_dir}")
    print(f"✅ Báo cáo chi tiết: {os.path.join(output_dir, 'invalid_report.txt')}")

# Sử dụng
output_directory = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/yolov12s09032025_ver-dataset2/_ver1"
export_invalid_labels(data_yaml_path, output_directory)





import os
import cv2

def draw_bounding_boxes_for_image(image_path, label_path):
    """
    Đọc một ảnh và file label tương ứng, sau đó vẽ bounding box lên ảnh.
    
    Định dạng file label: mỗi dòng có 5 giá trị:
      class_id, xc, yc, w, h
    Trong đó:
      - xc, yc: tọa độ tâm bounding box (đã chuẩn hóa, giá trị từ 0 đến 1)
      - w, h: chiều rộng và chiều cao (đã chuẩn hóa)
    Trả về ảnh đã vẽ bounding box (dưới định dạng BGR)
    """
    # Đọc ảnh
    image = cv2.imread(image_path)
    if image is None:
        print("Không đọc được ảnh:", image_path)
        return None

    height, width = image.shape[:2]

    # Kiểm tra sự tồn tại của file label
    if not os.path.exists(label_path):
        print("Không tìm thấy file label cho ảnh:", image_path)
        return image  # Trả về ảnh gốc nếu không có label

    # Đọc file label
    with open(label_path, 'r') as f:
        lines = f.readlines()

    # Vẽ bounding box cho từng dòng annotation
    for line in lines:
        line = line.strip()
        if not line:
            continue  # Bỏ qua dòng trống

        parts = line.split()
        if len(parts) != 5:
            print(f"Định dạng không hợp lệ label_id:{label_path}, giá trị: ", line)
            continue

        try:
            class_id, xc, yc, w, h = map(float, parts)
        except ValueError:
            print("Lỗi chuyển đổi số trong dòng:", line)
            continue

        # Chuyển tọa độ chuẩn hóa sang tọa độ pixel
        x_min = int((xc - w/2) * width)
        y_min = int((yc - h/2) * height)
        x_max = int((xc + w/2) * width)
        y_max = int((yc + h/2) * height)

        # Vẽ bounding box và nhãn (dùng class_id)
        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)
        label_text = f"Class {int(class_id)}"
        cv2.putText(image, label_text, (x_min, y_min - 10), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    return image

def process_folder(image_folder, label_folder, output_folder):
    """
    Duyệt qua folder chứa ảnh và đối chiếu file label tương ứng từ folder label.
    Ảnh và label được coi là tương ứng nếu tên file (không phần mở rộng) trùng nhau.
    Ảnh đã xử lý (có bounding box) sẽ được lưu vào folder output.
    """
    os.makedirs(output_folder, exist_ok=True)

    for filename in os.listdir(image_folder):
        # Kiểm tra file có phải là ảnh không dựa vào phần mở rộng
        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):
            image_path = os.path.join(image_folder, filename)
            base, _ = os.path.splitext(filename)
            label_file = base + ".txt"
            label_path = os.path.join(label_folder, label_file)
            print(f"Đang xử lý ảnh: {image_path}")
            processed_image = draw_bounding_boxes_for_image(image_path, label_path)
            if processed_image is not None:
                output_path = os.path.join(output_folder, filename)
                cv2.imwrite(output_path, processed_image)
                print(f"Đã lưu ảnh: {output_path}")
        else:
            print("Bỏ qua file không phải ảnh:", filename)

if __name__ == "__main__":
    # Cập nhật đường dẫn tới folder chứa ảnh, folder chứa label và folder export
    image_folder = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/yolov12s09032025_ver-dataset2/_ver1/invalid/images"
    label_folder = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/yolov12s09032025_ver-dataset2/_ver1/invalid/labels"
    output_folder = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/yolov12s09032025_ver-dataset2/_ver1/invalid/visualize_images"
    
    process_folder(image_folder, label_folder, output_folder)






import os
import yaml
import cv2
import numpy as np
import shutil
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from collections import defaultdict
from imgaug import augmenters as iaa

# ========================== CẤU HÌNH ==========================
MIN_AREA = 100      # Diện tích tối thiểu (pixel²)
MIN_DIM = 10        # Kích thước tối thiểu (width/height)
AUGMENT_CLASSES = [ # Các lớp cần tăng cường dữ liệu
    "drinking", 
    "raising_hand"
]
# ===============================================================

def analyze_and_improve_dataset(yaml_path, output_dir):
    """Xử lý toàn bộ pipeline: phân tích, làm sạch, cân bằng dữ liệu"""
    
    # 1. Đọc cấu hình dataset
    with open(yaml_path, 'r') as f:
        data = yaml.safe_load(f)
    root_dir = os.path.dirname(yaml_path)
    class_names = data['names']
    class_ids = {name:i for i, name in enumerate(class_names)}
    
    # 2. Khởi tạo thư mục output
    for split in ['train', 'valid', 'test']:
        os.makedirs(os.path.join(output_dir, split, 'images'), exist_ok=True)
        os.makedirs(os.path.join(output_dir, split, 'labels'), exist_ok=True)

    # 3. Pipeline xử lý
    all_files = []
    stats = defaultdict(lambda: defaultdict(int))
    
    # 4. Xử lý từng tập dữ liệu gốc
    for split in ['train', 'valid', 'test']:
        img_dir = os.path.join(root_dir, split, 'images')
        label_dir = os.path.join(root_dir, split, 'labels')
        
        if not os.path.exists(img_dir):
            continue
            
        for img_file in os.listdir(img_dir):
            if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                continue
                
            img_path = os.path.join(img_dir, img_file)
            label_path = os.path.join(label_dir, os.path.splitext(img_file)[0] + '.txt')
            
            # 5. Lọc và chuẩn hóa labels
            valid_labels, class_dist = process_labels(
                label_path, 
                img_path, 
                class_ids,
                stats[split]
            )
            
            if valid_labels:
                # 6. Lưu dữ liệu đã lọc
                save_clean_data(
                    img_path,
                    valid_labels,
                    os.path.join(output_dir, split),
                    img_file
                )
                all_files.append((split, class_dist))
                
    # 7. Cân bằng dữ liệu
    balance_dataset(output_dir, class_names, all_files)
    
    # 8. Phân chia lại dữ liệu
    stratified_split(output_dir, class_names)
    
    return stats

def process_labels(label_path, img_path, class_ids, stats):
    """Xử lý và lọc labels"""
    valid_labels = []
    class_dist = defaultdict(int)
    
    try:
        img = cv2.imread(img_path)
        if img is None:
            return [], {}
            
        h, w = img.shape[:2]
        
        with open(label_path, 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                
                parts = line.split()
                # Kiểm tra định dạng
                if len(parts) != 5:
                    stats['invalid'] += 1
                    continue
                
                try:
                    class_id, xc, yc, bw, bh = map(float, parts)
                    # Validate giá trị
                    if not (0 <= xc <=1 and 0 <= yc <=1 and 0 <= bw <=1 and 0 <= bh <=1):
                        stats['invalid'] += 1
                        continue
                        
                    # Tính kích thước thực
                    box_w = bw * w
                    box_h = bh * h
                    area = box_w * box_h
                    
                    # Lọc outliers
                    if area < MIN_AREA or box_w < MIN_DIM or box_h < MIN_DIM:
                        stats['invalid'] += 1
                        continue
                        
                    # Cập nhật thống kê
                    cls_name = class_ids.inverse[int(class_id)]
                    stats[cls_name] += 1
                    class_dist[cls_name] += 1
                    
                    valid_labels.append(line)
                    
                except Exception as e:
                    stats['invalid'] += 1
                    
    except Exception as e:
        print(f"Error processing {label_path}: {str(e)}")
        
    return valid_labels, class_dist

def save_clean_data(img_path, labels, output_dir, img_file):
    """Lưu dữ liệu đã được làm sạch"""
    # Copy ảnh
    shutil.copy(img_path, os.path.join(output_dir, 'images', img_file))
    
    # Lưu label
    label_file = os.path.splitext(img_file)[0] + '.txt'
    with open(os.path.join(output_dir, 'labels', label_file), 'w') as f:
        f.write('\n'.join(labels))

def balance_dataset(data_dir, class_names, all_files):
    """Cân bằng dữ liệu bằng augmentation"""
    seq = iaa.Sequential([
        iaa.Fliplr(0.5),
        iaa.Affine(
            rotate=(-15, 15),
            scale=(0.8, 1.2)
        ),
        iaa.GaussianBlur(sigma=(0, 1.0))
    ])
    
    # Tính toán số lượng mẫu cho từng lớp
    class_counts = defaultdict(int)
    for _, dist in all_files:
        for cls, count in dist.items():
            class_counts[cls] += count

    # Nếu không có mẫu hợp lệ nào, bỏ qua bước augmentation
    if not class_counts:
        print("Không có mẫu hợp lệ để cân bằng. Bỏ qua bước augmentation.")
        return

    max_count = max(class_counts.values())
    
    # Tăng cường cho các lớp thiếu
    for cls in class_names:
        if class_counts[cls] < max_count // 2 and cls in AUGMENT_CLASSES:
            augment_class(
                data_dir, 
                cls, 
                target_count=max_count // 2,
                augmenter=seq
            )


def stratified_split(data_dir, class_names, ratios=(0.7, 0.2, 0.1)):
    """
    Phân chia dữ liệu theo tỷ lệ giữ nguyên phân phối lớp.
    Giả sử data_dir có cấu trúc:
        data_dir/
            images/
            labels/
    Mỗi ảnh có file label có cùng tên (đuôi .txt).
    Nếu file label có nhiều dòng, ta sử dụng dòng đầu tiên để lấy nhãn cho ảnh.
    
    Sau khi tách, các file sẽ được copy sang:
        data_dir/train/images, data_dir/train/labels,
        data_dir/valid/images, data_dir/valid/labels,
        data_dir/test/images, data_dir/test/labels.
    """
    images_dir = os.path.join(data_dir, "images")
    labels_dir = os.path.join(data_dir, "labels")
    
    # Lấy danh sách ảnh hợp lệ và nhãn tương ứng (sử dụng dòng label đầu tiên)
    image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]
    valid_image_files = []
    image_labels = []  # nhãn dạng tên lớp
    
    for img_file in image_files:
        base, _ = os.path.splitext(img_file)
        label_file = base + ".txt"
        label_path = os.path.join(labels_dir, label_file)
        if not os.path.exists(label_path):
            continue
        with open(label_path, 'r') as f:
            lines = f.readlines()
        if not lines:
            continue
        # Lấy dòng đầu tiên và trích xuất class_id
        try:
            first_line = lines[0].strip()
            parts = first_line.split()
            if len(parts) < 1:
                continue
            class_id = int(float(parts[0]))
            if class_id < len(class_names):
                label_name = class_names[class_id]
            else:
                label_name = "unknown"
            image_labels.append(label_name)
            valid_image_files.append(img_file)
        except Exception as e:
            continue

    if not valid_image_files:
        print("Không tìm thấy ảnh hợp lệ để phân chia.")
        return

    # Bước 1: Tách thành train và temp (với tỉ lệ train:  ratios[0])
    train_files, temp_files, train_labels, temp_labels = train_test_split(
        valid_image_files, image_labels, test_size=(1 - ratios[0]), stratify=image_labels, random_state=42
    )
    # Bước 2: Tách temp thành valid và test theo tỉ lệ valid:test = ratios[1]:ratios[2]
    valid_ratio = ratios[1] / (ratios[1] + ratios[2])
    valid_files, test_files, valid_labels, test_labels = train_test_split(
        temp_files, temp_labels, test_size=(1 - valid_ratio), stratify=temp_labels, random_state=42
    )

    # Tạo thư mục cho từng split
    for split in ['train', 'valid', 'test']:
        os.makedirs(os.path.join(data_dir, split, 'images'), exist_ok=True)
        os.makedirs(os.path.join(data_dir, split, 'labels'), exist_ok=True)

    def copy_files(file_list, split_name):
        for img_file in file_list:
            base, ext = os.path.splitext(img_file)
            src_img = os.path.join(images_dir, img_file)
            src_label = os.path.join(labels_dir, base + ".txt")
            dst_img = os.path.join(data_dir, split_name, 'images', img_file)
            dst_label = os.path.join(data_dir, split_name, 'labels', base + ".txt")
            shutil.copy(src_img, dst_img)
            shutil.copy(src_label, dst_label)

    copy_files(train_files, 'train')
    copy_files(valid_files, 'valid')
    copy_files(test_files, 'test')

    print("Stratified split hoàn tất:")
    print(f" - Train: {len(train_files)} ảnh")
    print(f" - Valid: {len(valid_files)} ảnh")
    print(f" - Test:  {len(test_files)} ảnh")


def visualize_improvements(stats_before, stats_after):
    """
    Trực quan hóa kết quả cải thiện dữ liệu.
    stats_before và stats_after là các dictionary có dạng:
        { 'class1': count1, 'class2': count2, ... , 'invalid': count_invalid }
    Hàm sẽ tạo biểu đồ cột so sánh số lượng mẫu trước và sau cải thiện.
    """
    # Lấy tập hợp tất cả các key từ cả hai dictionary
    all_keys = set(stats_before.keys()).union(set(stats_after.keys()))
    
    data = []
    for key in all_keys:
        data.append({
            'class': key,
            'before': stats_before.get(key, 0),
            'after': stats_after.get(key, 0)
        })
    
    df = pd.DataFrame(data)
    df_melt = df.melt(id_vars='class', value_vars=['before', 'after'], 
                      var_name='stage', value_name='count')
    
    plt.figure(figsize=(10, 6))
    sns.barplot(data=df_melt, x='class', y='count', hue='stage')
    plt.title("So sánh số lượng mẫu trước và sau cải thiện")
    plt.xlabel("Lớp")
    plt.ylabel("Số lượng mẫu")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

# ====================== CHẠY CHƯƠNG TRÌNH ======================
if __name__ == "__main__":
    input_yaml = data_yaml_path
    output_dir = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/yolov12s09032025_ver-dataset2/_ver1/invalid/improved_dataset"
    
    print("🔄 Đang xử lý dữ liệu...")
    stats = analyze_and_improve_dataset(input_yaml, output_dir)
    
    print("✅ Hoàn thành! Kết quả:")
    print(f" - Đã xử lý {sum(stats['train'].values())} mẫu huấn luyện")
    print(f" - Loại bỏ {stats['train']['invalid']} label không hợp lệ")
    
     # Đây chỉ là dữ liệu mẫu minh họa
    # stats_before = {"drinking": 120, "raising_hand": 80, "invalid": 30}
    # stats_after  = {"drinking": 150, "raising_hand": 100, "invalid": 10}
    # visualize_improvements(original_stats, stats)





import os
import yaml
import cv2
import numpy as np
import shutil
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.model_selection import train_test_split
from collections import defaultdict
from imgaug import augmenters as iaa

# ========================== CẤU HÌNH ==========================
MIN_AREA = 100      # Diện tích tối thiểu (pixel²) của bounding box
MIN_DIM = 10        # Kích thước tối thiểu (chiều rộng hoặc chiều cao) của bounding box
AUGMENT_CLASSES = [ # Danh sách các lớp cần tăng cường dữ liệu (sử dụng augmentation)
    "drinking", 
    "raising_hand"
]
# ===============================================================

def analyze_and_improve_dataset(yaml_path, output_dir):
    """
    Hàm chính xử lý toàn bộ pipeline:
      - Đọc cấu hình dataset từ file YAML
      - Làm sạch dữ liệu bằng cách lọc các label không hợp lệ
      - Lưu ảnh và label đã làm sạch vào thư mục output theo cấu trúc train/valid/test
      - Cân bằng dữ liệu thông qua augmentation cho các lớp có số lượng mẫu ít
      - Phân chia lại dữ liệu thành các tập train, valid, test với phân phối lớp cố định
      
    Đầu vào:
        yaml_path: Đường dẫn đến file cấu hình dataset (YAML)
        output_dir: Thư mục đầu ra chứa dữ liệu đã được xử lý
    Trả về:
        stats: Thống kê kết quả xử lý cho từng tập dữ liệu
    """
    # 1. Đọc cấu hình dataset từ file YAML
    with open(yaml_path, 'r') as f:
        data = yaml.safe_load(f)
    # Lấy thư mục gốc của dataset từ đường dẫn YAML
    root_dir = os.path.dirname(yaml_path)
    # Danh sách tên lớp (ví dụ: ["drinking", "raising_hand", ...])
    class_names = data['names']
    
    # 2. Khởi tạo thư mục đầu ra cho từng tập: train, valid, test
    for split in ['train', 'valid', 'test']:
        os.makedirs(os.path.join(output_dir, split, 'images'), exist_ok=True)
        os.makedirs(os.path.join(output_dir, split, 'labels'), exist_ok=True)

    # 3. Khởi tạo biến lưu danh sách file và thống kê dữ liệu
    all_files = []  # Danh sách chứa tuple (split, class distribution) cho mỗi ảnh
    stats = defaultdict(lambda: defaultdict(int))  # Thống kê cho từng tập: ví dụ, stats['train']

    # 4. Duyệt qua các tập dữ liệu gốc (train, valid, test)
    for split in ['train', 'valid', 'test']:
        img_dir = os.path.join(root_dir, split, 'images')
        label_dir = os.path.join(root_dir, split, 'labels')
        
        # Nếu thư mục ảnh không tồn tại, bỏ qua tập này
        if not os.path.exists(img_dir):
            continue
            
        # Duyệt qua từng file ảnh trong thư mục
        for img_file in os.listdir(img_dir):
            # Kiểm tra file có phải là ảnh dựa vào phần mở rộng
            if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                continue
                
            img_path = os.path.join(img_dir, img_file)
            # Xác định file label tương ứng (giả sử có cùng tên file, đuôi .txt)
            label_path = os.path.join(label_dir, os.path.splitext(img_file)[0] + '.txt')
            
            # 5. Lọc và chuẩn hóa label (chỉ giữ lại những dòng label hợp lệ)
            valid_labels, class_dist = process_labels(
                label_path, 
                img_path, 
                class_names,
                stats[split]
            )
            
            # Nếu có ít nhất một label hợp lệ, lưu ảnh và label đã xử lý
            if valid_labels:
                save_clean_data(
                    img_path,
                    valid_labels,
                    os.path.join(output_dir, split),
                    img_file
                )
                # Lưu thống kê của ảnh vào danh sách all_files
                all_files.append((split, class_dist))
            
            #---- Save folder lable không hợp lệ
            if invalid_labels:
                save_invalid_data(
                    img_path,
                    invalid_labels,
                    os.path.join(output_dir, split),
                    img_file
                )
            
    # 7. Cân bằng dữ liệu: tăng cường dữ liệu cho các lớp có số lượng mẫu thấp
    balance_dataset(output_dir, class_names, all_files)
    
    # 8. Phân chia lại dữ liệu thành các tập train, valid, test theo phân phối lớp cố định
    stratified_split(output_dir, class_names)
    
    return stats

def process_labels(label_path, img_path, class_names, stats):
    """
    Xử lý và lọc label của ảnh.
    
    Các bước:
      - Đọc ảnh để lấy kích thước (width, height)
      - Đọc file label, duyệt từng dòng và kiểm tra:
          * Dòng label phải có đúng 5 giá trị: class_id, xc, yc, bw, bh
          * Các giá trị xc, yc, bw, bh phải nằm trong khoảng [0, 1]
          * Kích thước thực của bounding box (tính từ kích thước ảnh) phải đạt yêu cầu
            (diện tích >= MIN_AREA, width và height >= MIN_DIM)
      - Nếu dòng label hợp lệ, cập nhật thống kê và thêm vào danh sách valid_labels
      - Nếu không hợp lệ, tăng thống kê stats['invalid']
    
    Đầu vào:
        label_path: Đường dẫn file label
        img_path: Đường dẫn ảnh (để lấy kích thước)
        class_names: Danh sách tên lớp
        stats: Dictionary thống kê cho tập dữ liệu hiện tại
    Trả về:
        valid_labels: Danh sách dòng label hợp lệ
        class_dist: Phân bố lớp (dictionary) cho ảnh này
    """
    valid_labels = []
    class_dist = defaultdict(int)
    
    try:
        # Đọc ảnh để lấy kích thước
        img = cv2.imread(img_path)
        if img is None:
            return [], {}
            
        h, w = img.shape[:2]
        
        # Đọc file label
        with open(label_path, 'r') as f:
            for line in f:
                line = line.strip()
                # Bỏ qua dòng trống
                if not line:
                    continue
                
                parts = line.split()
                # Kiểm tra định dạng: phải có đúng 5 giá trị
                if len(parts) != 5:
                    stats['invalid'] += 1
                    continue
                
                try:
                    # Chuyển đổi các giá trị thành float
                    class_id, xc, yc, bw, bh = map(float, parts)
                    # Kiểm tra các giá trị tọa độ và kích thước phải nằm trong khoảng [0, 1]
                    if not (0 <= xc <= 1 and 0 <= yc <= 1 and 0 <= bw <= 1 and 0 <= bh <= 1):
                        stats['invalid'] += 1
                        continue
                        
                    # Tính kích thước thực của bounding box dựa vào kích thước ảnh
                    box_w = bw * w
                    box_h = bh * h
                    area = box_w * box_h
                    
                    # Lọc các box có kích thước quá nhỏ
                    if area < MIN_AREA or box_w < MIN_DIM or box_h < MIN_DIM:
                        stats['invalid'] += 1
                        continue
                        
                    # Lấy tên lớp từ class_id sử dụng danh sách class_names
                    cls_name = class_names[int(class_id)]
                    # Cập nhật thống kê cho lớp này
                    stats[cls_name] += 1
                    class_dist[cls_name] += 1
                    
                    # Nếu dòng label hợp lệ, thêm vào danh sách valid_labels
                    valid_labels.append(line)
                    
                except Exception as e:
                    stats['invalid'] += 1
                    
    except Exception as e:
        print(f"Error processing {label_path}: {str(e)}")
        
    return valid_labels, class_dist

def save_clean_data(img_path, labels, output_dir, img_file):
    """
    Lưu dữ liệu đã làm sạch vào thư mục đầu ra.
      - Copy ảnh gốc vào thư mục 'images'
      - Ghi các dòng label hợp lệ vào file label trong thư mục 'labels'
      
    Đầu vào:
        img_path: Đường dẫn ảnh gốc
        labels: Danh sách dòng label hợp lệ
        output_dir: Thư mục đầu ra của tập dữ liệu (train/valid/test)
        img_file: Tên file ảnh
    """
    # Copy ảnh gốc vào thư mục output/images
    shutil.copy(img_path, os.path.join(output_dir, 'images', img_file))
    
    # Tạo tên file label dựa trên tên file ảnh (đổi đuôi thành .txt)
    label_file = os.path.splitext(img_file)[0] + '.txt'
    # Ghi nội dung các dòng label hợp lệ vào file label mới
    with open(os.path.join(output_dir, 'labels', label_file), 'w') as f:
        f.write('\n'.join(labels))

def save_invalid_data(img_path, invalid_labels, output_dir, img_file):
    """
    Lưu các label không hợp lệ vào thư mục invalid của mỗi split.
    """
    invalid_images_dir = os.path.join(output_dir, 'invalid', 'images')
    invalid_labels_dir = os.path.join(output_dir, 'invalid', 'labels')
    # Copy ảnh gốc vào thư mục invalid images
    shutil.copy(img_path, os.path.join(invalid_images_dir, img_file))
    # Lưu file label không hợp lệ
    label_file = os.path.splitext(img_file)[0] + '.txt'
    with open(os.path.join(invalid_labels_dir, label_file), 'w') as f:
        f.write('\n'.join(invalid_labels))

def augment_class(data_dir, cls, target_count, augmenter, class_names):
    """
    Tăng cường dữ liệu cho lớp cụ thể thông qua augmentation.
    Phiên bản này đơn giản: tìm các ảnh mà file label chứa lớp 'cls' và áp dụng augmentation.
    (Lưu ý: Trong thực tế cần cập nhật lại tọa độ bounding box cho ảnh tăng cường)
    
    Đầu vào:
        data_dir: Thư mục dữ liệu (chứa tập train)
        cls: Tên lớp cần tăng cường (ví dụ: "drinking")
        target_count: Số lượng mẫu mong muốn sau khi tăng cường cho lớp này
        augmenter: Đối tượng augmentation (imgaug)
        class_names: Danh sách tên lớp
    """
    print(f"Augmenting class '{cls}' to reach {target_count} samples.")
    # Xác định thư mục chứa ảnh và label của tập train
    train_images_dir = os.path.join(data_dir, "train", "images")
    train_labels_dir = os.path.join(data_dir, "train", "labels")
    
    # Tìm danh sách các file label có chứa lớp cần tăng cường
    images_to_augment = []
    for label_file in os.listdir(train_labels_dir):
        label_path = os.path.join(train_labels_dir, label_file)
        with open(label_path, 'r') as f:
            lines = f.readlines()
        # Nếu trong file label có ít nhất một dòng chứa lớp 'cls', thêm tên file ảnh vào danh sách
        for line in lines:
            parts = line.strip().split()
            if len(parts) < 1:
                continue
            try:
                class_id = int(float(parts[0]))
                if class_names[class_id] == cls:
                    images_to_augment.append(label_file.replace(".txt", ""))
                    break
            except:
                continue
    
    # Tính số lượng mẫu hiện có và số mẫu cần tăng cường thêm
    current_count = len(images_to_augment)
    augment_needed = target_count - current_count
    if augment_needed <= 0:
        print(f"Không cần tăng cường thêm cho lớp '{cls}'.")
        return
    
    print(f"Cần tăng cường {augment_needed} mẫu cho lớp '{cls}'.")
    
    # Áp dụng augmentation cho các ảnh của lớp 'cls'
    aug_index = 0
    for img_name in images_to_augment:
        # Giả sử ảnh có định dạng .jpg (có thể điều chỉnh nếu cần)
        img_path = os.path.join(train_images_dir, img_name + ".jpg")
        label_path = os.path.join(train_labels_dir, img_name + ".txt")
        
        # Đọc ảnh từ file
        image = cv2.imread(img_path)
        if image is None:
            continue
        
        # Áp dụng augmentation vào ảnh
        image_aug = augmenter.augment_image(image)
        
        # Tạo tên file mới cho ảnh và label tăng cường
        new_img_name = f"{img_name}_aug_{aug_index}.jpg"
        new_label_name = f"{img_name}_aug_{aug_index}.txt"
        # Lưu ảnh tăng cường vào thư mục train/images
        cv2.imwrite(os.path.join(train_images_dir, new_img_name), image_aug)
        # Copy file label gốc sang tên mới (trong thực tế cần cập nhật bounding box nếu ảnh thay đổi)
        shutil.copy(label_path, os.path.join(train_labels_dir, new_label_name))
        
        aug_index += 1
        if aug_index >= augment_needed:
            break

def balance_dataset(data_dir, class_names, all_files):
    """
    Cân bằng dữ liệu bằng cách tăng cường dữ liệu (augmentation) cho các lớp có số lượng mẫu thấp.
    
    Đầu vào:
        data_dir: Thư mục chứa dữ liệu đã làm sạch (bao gồm các tập train, valid, test)
        class_names: Danh sách tên lớp
        all_files: Danh sách các tuple (split, class distribution) thu được từ quá trình xử lý
    """
    # Khởi tạo đối tượng augmenter với các kỹ thuật augmentation
    seq = iaa.Sequential([
        iaa.Fliplr(0.5),               # Lật ảnh ngang với xác suất 50%
        iaa.Affine(                    # Biến đổi affine: xoay và scale ảnh
            rotate=(-15, 15),
            scale=(0.8, 1.2)
        ),
        iaa.GaussianBlur(sigma=(0, 1.0)) # Áp dụng Gaussian blur với sigma từ 0 đến 1.0
    ])
    
    # Tính số lượng mẫu cho từng lớp từ thống kê đã thu thập được
    class_counts = defaultdict(int)
    for _, dist in all_files:
        for cls, count in dist.items():
            class_counts[cls] += count

    # Nếu không có mẫu hợp lệ nào, bỏ qua bước augmentation
    if not class_counts:
        print("Không có mẫu hợp lệ để cân bằng. Bỏ qua bước augmentation.")
        return

    # Lấy số lượng mẫu lớn nhất của các lớp
    max_count = max(class_counts.values())
    
    # Duyệt qua từng lớp, nếu số mẫu của lớp nhỏ hơn một nửa của lớp có số mẫu nhiều nhất
    # và lớp đó nằm trong danh sách cần augmentation, tiến hành tăng cường dữ liệu.
    for cls in class_names:
        if class_counts[cls] < max_count // 2 and cls in AUGMENT_CLASSES:
            augment_class(
                data_dir, 
                cls, 
                target_count=max_count // 2,
                augmenter=seq,
                class_names=class_names
            )

def stratified_split(data_dir, class_names, ratios=(0.7, 0.2, 0.1)):
    """
    Phân chia dữ liệu thành các tập train, valid, test theo tỷ lệ giữ nguyên phân phối lớp.
    
    Giả sử cấu trúc dữ liệu ban đầu trong data_dir là:
        data_dir/
            images/   (chứa tất cả ảnh)
            labels/   (chứa tất cả file label, có cùng tên với ảnh)
    
    Mỗi ảnh được gán nhãn dựa vào dòng label đầu tiên trong file label.
    
    Sau khi phân chia, các file sẽ được copy sang:
        data_dir/train/images, data_dir/train/labels,
        data_dir/valid/images, data_dir/valid/labels,
        data_dir/test/images, data_dir/test/labels.
    """
    images_dir = os.path.join(data_dir, "images")
    labels_dir = os.path.join(data_dir, "labels")
    
    # Lấy danh sách các file ảnh hợp lệ và gán nhãn cho từng ảnh từ file label đầu tiên
    image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]
    valid_image_files = []
    image_labels = []  # Danh sách nhãn dạng tên lớp
    
    for img_file in image_files:
        base, _ = os.path.splitext(img_file)
        label_file = base + ".txt"
        label_path = os.path.join(labels_dir, label_file)
        # Nếu file label không tồn tại, bỏ qua ảnh này
        if not os.path.exists(label_path):
            continue
        with open(label_path, 'r') as f:
            lines = f.readlines()
        if not lines:
            continue
        # Lấy dòng đầu tiên và trích xuất class_id
        try:
            first_line = lines[0].strip()
            parts = first_line.split()
            if len(parts) < 1:
                continue
            class_id = int(float(parts[0]))
            if class_id < len(class_names):
                label_name = class_names[class_id]
            else:
                label_name = "unknown"
            image_labels.append(label_name)
            valid_image_files.append(img_file)
        except Exception as e:
            continue

    if not valid_image_files:
        print("Không tìm thấy ảnh hợp lệ để phân chia.")
        return

    # Sử dụng train_test_split có phân tầng để chia dữ liệu
    # Bước 1: Tách thành tập train và tập tạm (temp) với tập train chiếm tỷ lệ ratios[0]
    train_files, temp_files, train_labels, temp_labels = train_test_split(
        valid_image_files, image_labels, test_size=(1 - ratios[0]), stratify=image_labels, random_state=42
    )
    # Bước 2: Tách tập tạm thành tập valid và test theo tỷ lệ ratios[1]:ratios[2]
    valid_ratio = ratios[1] / (ratios[1] + ratios[2])
    valid_files, test_files, valid_labels, test_labels = train_test_split(
        temp_files, temp_labels, test_size=(1 - valid_ratio), stratify=temp_labels, random_state=42
    )

    # Tạo thư mục cho từng tập (train, valid, test)
    for split in ['train', 'valid', 'test']:
        os.makedirs(os.path.join(data_dir, split, 'images'), exist_ok=True)
        os.makedirs(os.path.join(data_dir, split, 'labels'), exist_ok=True)

    # Hàm nội bộ: copy file từ thư mục gốc sang thư mục của từng tập
    def copy_files(file_list, split_name):
        for img_file in file_list:
            base, ext = os.path.splitext(img_file)
            src_img = os.path.join(images_dir, img_file)
            src_label = os.path.join(labels_dir, base + ".txt")
            dst_img = os.path.join(data_dir, split_name, 'images', img_file)
            dst_label = os.path.join(data_dir, split_name, 'labels', base + ".txt")
            shutil.copy(src_img, dst_img)
            shutil.copy(src_label, dst_label)

    # Copy file ảnh và label sang các thư mục tương ứng
    copy_files(train_files, 'train')
    copy_files(valid_files, 'valid')
    copy_files(test_files, 'test')

    print("Stratified split hoàn tất:")
    print(f" - Train: {len(train_files)} ảnh")
    print(f" - Valid: {len(valid_files)} ảnh")
    print(f" - Test:  {len(test_files)} ảnh")

def visualize_improvements(stats_before, stats_after):
    """
    Trực quan hóa kết quả cải thiện dữ liệu bằng biểu đồ cột so sánh số lượng mẫu của từng lớp
    trước và sau khi cải thiện.
    
    Đầu vào:
        stats_before: Dictionary thống kê trước khi cải thiện, ví dụ: {"drinking": 120, "raising_hand": 80, "invalid": 30}
        stats_after: Dictionary thống kê sau khi cải thiện, ví dụ: {"drinking": 150, "raising_hand": 100, "invalid": 10}
    """
    # Tập hợp tất cả các lớp xuất hiện trong cả stats_before và stats_after
    all_keys = set(stats_before.keys()).union(set(stats_after.keys()))
    
    data = []
    # Tạo danh sách dictionary với thông tin thống kê của từng lớp
    for key in all_keys:
        data.append({
            'class': key,
            'before': stats_before.get(key, 0),
            'after': stats_after.get(key, 0)
        })
    
    # Chuyển danh sách thành DataFrame để trực quan hóa bằng seaborn
    df = pd.DataFrame(data)
    # "Melt" DataFrame để có định dạng phù hợp cho barplot (dạng long)
    df_melt = df.melt(id_vars='class', value_vars=['before', 'after'], 
                      var_name='stage', value_name='count')
    
    plt.figure(figsize=(10, 6))
    sns.barplot(data=df_melt, x='class', y='count', hue='stage')
    plt.title("So sánh số lượng mẫu trước và sau cải thiện")
    plt.xlabel("Lớp")
    plt.ylabel("Số lượng mẫu")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

# ====================== CHẠY CHƯƠNG TRÌNH ======================
if __name__ == "__main__":
    # Cập nhật đường dẫn file YAML của dataset của bạn
    data_yaml_path = "/path/to/dataset.yaml"
    input_yaml = data_yaml_path
    
    # Đường dẫn thư mục đầu ra chứa dữ liệu đã cải thiện
    # output_dir = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/yolov12s09032025_ver-dataset2/_ver1/invalid/improved_dataset"
    output_dir = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/yolov12s09032025_ver-dataset2/Imporved_data"
    
    print("🔄 Đang xử lý dữ liệu...")
    # Gọi hàm pipeline xử lý và nhận kết quả thống kê
    stats = analyze_and_improve_dataset(input_yaml, output_dir)
    
    print("✅ Hoàn thành! Kết quả:")
    print(f" - Đã xử lý {sum(stats['train'].values())} mẫu huấn luyện")
    print(f" - Loại bỏ {stats['train']['invalid']} label không hợp lệ")
    
    # Ví dụ trực quan hóa cải thiện (sử dụng dữ liệu mẫu minh họa)
    stats_before = {"drinking": 120, "raising_hand": 80, "invalid": 30}
    stats_after  = {"drinking": 150, "raising_hand": 100, "invalid": 10}
    visualize_improvements(stats_before, stats_after)









import os
import shutil
from datetime import datetime
from ultralytics import YOLO
import torch
print(torch.__version__)  # Check PyTorch version
print(torch.cuda.get_device_name(0))  # Check GPU model
print(torch.backends.cuda.flash_sdp_enabled())  # Check if FlashAttention is available



def get_unique_path(base_path):
    """
    Tạo đường dẫn duy nhất bằng cách thêm phiên bản nếu thư mục đã tồn tại

    Args:
        base_path (str): Đường dẫn gốc muốn tạo

    Returns:
        str: Đường dẫn duy nhất
    """
    # Nếu thư mục chưa tồn tại, trả về ngay
    if not os.path.exists(base_path):
        return f"{base_path}_ver{1}"

    # Nếu đã tồn tại, tìm phiên bản tiếp theo
    version = 2
    while True:
        versioned_path = f"{base_path}_ver{version}"
        if not os.path.exists(versioned_path):
            return versioned_path
        version += 1








import torch
print(torch.cuda.is_available())






import torch
print("CUDA Available:", torch.cuda.is_available())
print("CUDA Version:", torch.version.cuda)
print("Torch Version:", torch.__version__)
print("GPU Count:", torch.cuda.device_count())
if torch.cuda.is_available():
    print("GPU Name:", torch.cuda.get_device_name(0))



import pandas as pd
# Tạo đường dẫn lưu trữ với thư mục theo ngày
current_date = datetime.now().strftime("%d%m%Y")
nameYoloFamily = 'yolov12s'
### base
ver_dataset = 2
base_save_path = f'/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/{nameYoloFamily}{current_date}_ver-dataset{ver_dataset}/'

# Lấy đường dẫn duy nhất ----------------------------------Đường dẫn này cũng là quan trọng. Vì các báo cáo dưới đều càn đến
unique_save_path = get_unique_path(base_save_path)
# Tạo thư mục
os.makedirs(unique_save_path, exist_ok=True)

# Tạo mô hình và huấn luyện
model_filename = f'{nameYoloFamily}{current_date}.pt'
full_model_path = os.path.join(unique_save_path, model_filename)
# Tạo mô hình YOLO và cấu hình
model = YOLO(f'{nameYoloFamily}.yaml')

# Thay đổi thư mục làm việc
%cd "{unique_save_path}"
# Huấn luyện mô hình

path_data_yaml = '/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/Dataset/Student-Behavior-Recognition-2/data.yaml'
#------------------ Traning model
'''
Giả sử bạn bắt đầu với batch size = 32 và learning rate = 0.001.

Nếu bạn tăng batch size lên 64, bạn có thể tăng learning rate lên 0.001 * (64/32) = 0.002.

Nếu bạn giảm batch size xuống 16, bạn có thể giảm learning rate xuống 0.001 * (16/32) = 0.0005.
'''
batch_size = 32
num_epochs = 500
# Khởi tạo log
log_data = []

results = model.train(
    data = path_data_yaml,
    epochs= num_epochs,
    patience= 50,  # Số epoch đợi để dừng nếu không cải thiện
    save_period=-1,  # Lưu checkpoint sau mỗi epoch
    save=True,
    optimizer='Adam',  # Lựa chọn optimizer
    lrf=0.001*(batch_size/32),
    batch=batch_size
)
# Lưu mô hình cuối cùng
if not os.path.exists(full_model_path):
    model.save(full_model_path)
else:
  print(f"Mô hình đã tồn tại tại: {full_model_path}")



# In thông tin về mô hình đã lưu
print(f"Mô hình đã được lưu tại: {full_model_path}")

# Kiểm tra và in kích thước file
model_size = os.path.getsize(full_model_path) / (1024 * 1024)  # Chuyển sang MB
print(f"Kích thước mô hình: {model_size:.2f} MB")


# Đảm bảo sử dụng UTF-8 encoding
log_path = os.path.join(unique_save_path, 'training_log_2.txt')
with open(log_path, 'w', encoding='utf-8') as log_file:
    log_file.write(f"Mô hình: {nameYoloFamily}\n")
    log_file.write(f"Ngày huấn luyện: {current_date}\n")
    log_file.write(f"Số epochs: {num_epochs} \n")
    log_file.write(f"Kích thước mô hình: {model_size:.2f} MB\n")
    # log_file.write(f"Đường dẫn thư mục runs: {runs_destination_path}\n")

print(f"Đã ghi log tại: {log_path}")












model = YOLO(f'/{unique_save_path}/runs/detect/train/weights/best.pt')



model_summary = model.info()
if isinstance(model_summary, tuple):
    model_summary = model_summary[0]  # Lấy phần tử đầu tiên nếu là tuple


!pip install torchinfo





from torchinfo import summary
summary(model)





# Kiểm tra requires_grad của các tham số
for name, param in model.named_parameters():
    print(f"{name}: {param.requires_grad}")





# Mở khóa toàn bộ các tham số
for param in model.model.parameters():
    param.requires_grad = True
%cd /home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/yolov12s10032025_ver-dataset2/_ver1/runs/detect/train/weights
model.save("unfreezed_model.pt")  # Định dạng mặc định của YOLO
# Kiểm tra lại
print(f"Trainable params: {sum(p.numel() for p in model.model.parameters() if p.requires_grad)}")





import matplotlib.pyplot as plt
import networkx as nx
import re

def parse_yolo_summary(summary_text):
    """Phân tích YOLO summary thành danh sách các layers và kết nối."""
    G = nx.DiGraph()
    lines = summary_text.strip().split("\n")[2:-2]  # Bỏ dòng tiêu đề và tổng kết

    prev_layer = None  # Theo dõi lớp trước để tạo kết nối
    layer_colors = {
        'Conv': 'lightblue', 'C3k2': 'lightgreen', 'A2C2f': 'lightcoral',
        'Concat': 'orange', 'Upsample': 'purple', 'Detect': 'red'
    }

    for line in lines:
        match = re.search(r'(\w+): (\d+-\d+)\s+\(([\d,]+)?\)', line)
        if match:
            layer_type, layer_index, params = match.groups()
            params = int(params.replace(",", "")) if params else 0

            # Thêm node
            G.add_node(layer_index, label=f"{layer_type}\n{layer_index}",
                       color=layer_colors.get(layer_type, 'gray'), size=params)

            # Kết nối với lớp trước đó (giả định nối tuyến tính)
            if prev_layer:
                G.add_edge(prev_layer, layer_index)

            prev_layer = layer_index  # Cập nhật lớp trước đó

    return G

def visualize_yolo(G):
    """Vẽ sơ đồ kiến trúc YOLO."""
    plt.figure(figsize=(12, 8))
    pos = nx.spring_layout(G, seed=42, k=1.2)

    # Kích thước node dựa trên số lượng tham số
    node_sizes = [max(300, G.nodes[n]['size'] // 20) for n in G.nodes]
    node_colors = [G.nodes[n]['color'] for n in G.nodes]

    nx.draw(G, pos, with_labels=True, labels={n: G.nodes[n]['label'] for n in G.nodes},
            node_size=node_sizes, node_color=node_colors, font_size=10,
            font_weight='bold', edge_color='gray', arrows=True)

    plt.title("YOLOv12 Architecture", fontsize=14)
    plt.tight_layout()
    plt.show()

# Dữ liệu đầu vào (copy từ bạn)
summary_text = """==========================================================================================
YOLO                                                              --
├─DetectionModel: 1-1                                             --
│    └─Sequential: 2-1                                            --
│    │    └─Conv: 3-1                                             (928)
│    │    └─Conv: 3-2                                             (18,560)
│    │    └─C3k2: 3-3                                             (26,080)
│    │    └─Conv: 3-4                                             (147,712)
│    │    └─C3k2: 3-5                                             (103,360)
│    │    └─Conv: 3-6                                             (590,336)
│    │    └─A2C2f: 3-7                                            (689,408)
│    │    └─Conv: 3-8                                             (1,180,672)
│    │    └─A2C2f: 3-9                                            (2,689,536)
│    │    └─Upsample: 3-10                                        --
│    │    └─Concat: 3-11                                          --
│    │    └─A2C2f: 3-12                                           (345,856)
│    │    └─Upsample: 3-13                                        --
│    │    └─Concat: 3-14                                          --
│    │    └─A2C2f: 3-15                                           (95,104)
│    │    └─Conv: 3-16                                            (147,712)
│    │    └─Concat: 3-17                                          --
│    │    └─A2C2f: 3-18                                           (296,704)
│    │    └─Conv: 3-19                                            (590,336)
│    │    └─Concat: 3-20                                          --
│    │    └─C3k2: 3-21                                            (1,511,424)
│    │    └─Detect: 3-22                                          (820,956)
==========================================================================================
"""

# Xử lý và vẽ sơ đồ
G = parse_yolo_summary(summary_text)
visualize_yolo(G)









import locale
locale.getpreferredencoding = lambda: "UTF-8"

!ls {unique_save_path}/runs/detect/train/


from IPython.display import Image

Image(filename=f'{unique_save_path}/runs/detect/train/confusion_matrix.png', width=1000)





from IPython.display import Image

Image(filename=f'{unique_save_path}/runs/detect/train/results.png', width=1000)








data_path_working = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/Dataset/Student-Behavior-Recognition-2"
print(data_path_working)


import supervision as sv

ds = sv.DetectionDataset.from_yolo(
    images_directory_path=f"{data_path_working}/test/images",
    annotations_directory_path=f"{data_path_working}/test/labels",
    data_yaml_path=f"{data_path_working}/data.yaml"
)

ds.classes


import supervision
print(supervision.__version__)



pip install --upgrade supervision


from supervision.metrics.mean_average_precision import MeanAveragePrecision  # Sửa đường dẫn import

model = YOLO(f'/{unique_save_path}/runs/detect/train/weights/best.pt')

predictions = []
targets = []

# Giả sử ds là tập dữ liệu (dataset) của bạn
for _, image, target in ds:
    results = model(image, verbose=False)[0]
    detections = sv.Detections.from_ultralytics(results)
    
    predictions.append(detections)
    targets.append(target)

# Tính toán Mean Average Precision (mAP)
map_result = MeanAveragePrecision().update(predictions, targets).compute()

print("Mean Average Precision (mAP):", map_result)









map_result.plot()





unique_save_path= "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/yolov12s10032025_ver-dataset2/_ver1"


print(f'Đường dẫn: {unique_save_path}')


import supervision as sv

model = YOLO(f'/{unique_save_path}/runs/detect/train/weights/best.pt')


'''
Ý tưởng:
Lấy một hình ảnh ngẫu nhiên từ tập dữ liệu.
Dự đoán đối tượng trên ảnh bằng mô hình YOLO.
Áp dụng NMS để loại bỏ các phát hiện trùng lặp.
Vẽ hộp giới hạn và nhãn lên ảnh.
Hiển thị ảnh đã được chú thích.
'''
import random

# Lấy ngẫu nhiên ảnh từ dataset
i = random.randint(0, len(ds))
image_path, image, target = ds[i]
print(f'Image path: {image_path}\n image: {image}\n target: {target}')

results = model(image, verbose=False)[0]
print(f'Result: {results}')
detections = sv.Detections.from_ultralytics(results).with_nms()
print('Display detections:', detections)
thread = 50/100
detections = detections[detections.confidence > thread]

box_annotator = sv.BoxAnnotator()
label_annotator = sv.LabelAnnotator()

# Tạo labels kết hợp class name và confidence
labels = [
    f"{model.names[class_id]} {confidence:.0%}"  # Sử dụng model.names thay vì ds.names
    for class_id, confidence in
    zip(detections.class_id, detections.confidence)
]

annotated_image = image.copy()

# Vẽ bounding boxes và labels
annotated_image = box_annotator.annotate(
    scene=annotated_image,
    detections=detections
)
annotated_image = label_annotator.annotate(
    scene=annotated_image,
    detections=detections,
    labels=labels  # Thêm labels vào đây
)

sv.plot_image(annotated_image)








import glob
from IPython.display import Image, display

for imageName in glob.glob(f'{unique_save_path}/runs/detect/train/*.jpg')[:10]: #assuming JPG
    display(Image(filename=imageName))














import os
import cv2
from ultralytics import YOLO
import supervision as sv
from collections import Counter
import matplotlib.pyplot as plt
import numpy as np

# ----------------- CẤU HÌNH ĐƯỜNG DẪN -----------------
# ----------------- CẤU HÌNH ĐƯỜNG DẪN -----------------
unique_save_path = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/yolov12s10032025_ver-dataset2/_ver1"  # Thay bằng đường dẫn thực tế đến thư mục chứa mô hình
data_path_working = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/Dataset"  # Thay bằng đường dẫn thực tế đến thư mục chứa dữ liệu

# Thư mục chứa ảnh và ground truth (annotation) theo định dạng YOLO
image_dir = os.path.join(data_path_working, "Student-Behavior-Recognition-2/test/images")
gt_dir = os.path.join(data_path_working, "Student-Behavior-Recognition-2/test/labels")

# Thư mục để export những ảnh có dự đoán sai
export_folder = os.path.join(unique_save_path, "wrong_predictions")
os.makedirs(export_folder, exist_ok=True)

# ----------------- HÀM HỖ TRỢ -----------------
def compute_iou(box1, box2):
    """
    Tính IoU giữa 2 bounding box với định dạng [x1, y1, x2, y2].
    """
    x_left = max(box1[0], box2[0])
    y_top = max(box1[1], box2[1])
    x_right = min(box1[2], box2[2])
    y_bottom = min(box1[3], box2[3])
    
    if x_right < x_left or y_bottom < y_top:
        return 0.0

    intersection_area = (x_right - x_left) * (y_bottom - y_top)
    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])
    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])
    
    iou = intersection_area / float(box1_area + box2_area - intersection_area)
    return iou

def parse_ground_truth(gt_file, img_width, img_height):
    """
    Đọc file annotation định dạng YOLO:
      Mỗi dòng: <class_id> <x_center> <y_center> <width> <height>
    Các giá trị được chuẩn hóa theo kích thước ảnh, chuyển đổi sang định dạng [x1, y1, x2, y2].
    Trả về danh sách các tuple: (box, class_id)
    """
    items = []
    if not os.path.exists(gt_file):
        return items
    with open(gt_file, 'r') as f:
        for line in f.readlines():
            parts = line.strip().split()
            if len(parts) != 5:
                continue
            cls = int(parts[0])
            x_center = float(parts[1])
            y_center = float(parts[2])
            width = float(parts[3])
            height = float(parts[4])
            x1 = int((x_center - width/2) * img_width)
            y1 = int((y_center - height/2) * img_height)
            x2 = int((x_center + width/2) * img_width)
            y2 = int((y_center + height/2) * img_height)
            items.append(([x1, y1, x2, y2], cls))
    return items

# ----------------- LẤY DANH SÁCH ẢNH -----------------
image_files = [
    os.path.join(image_dir, f)
    for f in os.listdir(image_dir)
    if f.lower().endswith((".jpg", ".jpeg", ".png"))
]

# ----------------- KHỞI TẠO MÔ HÌNH -----------------
model_path = os.path.join(unique_save_path, "runs/detect/train/weights/unfreezed_model.pt")
model = YOLO(model_path)

# Annotators để vẽ bounding box và label (nếu cần)
box_annotator = sv.BoxAnnotator()
label_annotator = sv.LabelAnnotator()

# ----------------- BIẾN THỐNG KÊ -----------------
global_TP = 0
global_FP = 0
global_FN = 0
iou_threshold = 0.5  # Ngưỡng IoU để xác định matching
wrong_images_list = []  # Lưu các ảnh có dự đoán sai

# ----------------- XỬ LÝ ẢNH -----------------
for image_path in image_files:
    # Đọc ảnh
    image = cv2.imread(image_path)
    if image is None:
        print(f"Không đọc được ảnh: {image_path}")
        continue
    img_height, img_width = image.shape[:2]
    
    # Chạy mô hình YOLO để dự đoán
    results = model(image, verbose=False)[0]
    detections = sv.Detections.from_ultralytics(results)
    
    # Lấy danh sách bounding box dự đoán và class_id dự đoán
    pred_boxes = detections.xyxy if hasattr(detections, "xyxy") else []
    pred_class_ids = detections.class_id if hasattr(detections, "class_id") else []
    
    # Lấy ground truth từ file .txt tương ứng (với cả box và true class)
    base_filename = os.path.splitext(os.path.basename(image_path))[0]
    gt_file = os.path.join(gt_dir, base_filename + ".txt")
    gt_items = parse_ground_truth(gt_file, img_width, img_height)
    
    TP_img = 0
    FP_img = 0
    misclassified_boxes = []  # Lưu tuple: (box, predicted_label, true_label)
    false_positive_boxes = [] # Nếu không có matching ground truth
    matched_gt = [False] * len(gt_items)
    
    for i, pred_box in enumerate(pred_boxes):
        best_iou = 0
        best_idx = -1
        for idx, (gt_box, gt_cls) in enumerate(gt_items):
            if matched_gt[idx]:
                continue
            iou = compute_iou(pred_box, gt_box)
            if iou > best_iou:
                best_iou = iou
                best_idx = idx
        # Lấy nhãn dự đoán sử dụng .get() để đảm bảo trả về đúng true label nếu có
        if i < len(pred_class_ids):
            cid = int(pred_class_ids[i])
            predicted_label = model.names.get(cid, str(cid)) if hasattr(model, "names") else str(cid)
        else:
            predicted_label = "unknown"
        if best_iou >= iou_threshold and best_idx != -1:
            gt_cls = gt_items[best_idx][1]
            true_label = model.names.get(gt_cls, str(gt_cls)) if hasattr(model, "names") else str(gt_cls)
            matched_gt[best_idx] = True
            if predicted_label == true_label:
                TP_img += 1
            else:
                FP_img += 1
                misclassified_boxes.append((pred_box, predicted_label, true_label))
        else:
            FP_img += 1
            false_positive_boxes.append((pred_box, predicted_label, "none"))
    
    FN_img = len(gt_items) - TP_img
    global_TP += TP_img
    global_FP += FP_img
    global_FN += FN_img

    # Nếu có lỗi (FP hoặc FN > 0), export ảnh đã annotate
    if FP_img > 0 or FN_img > 0:
        wrong_images_list.append(image_path)
        annotated_image = image.copy()
        annotated_image = box_annotator.annotate(scene=annotated_image, detections=detections)
        annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections)
        
        # Với mỗi box bị phân loại sai, annotate chữ "predicted_label - true_label" ngay phía trên bounding box
        for box, predicted_label, true_label in misclassified_boxes:
            x1, y1, x2, y2 = map(int, box)
            pos_y = y1 - 10 if y1 - 10 > 10 else y1 + 20
            text = f"{predicted_label} - 0"
            cv2.putText(annotated_image, text, (x1, pos_y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
        
        # Nếu muốn annotate các false positive không có matching ground truth, uncomment đoạn bên dưới:
        # for box, predicted_label, _ in false_positive_boxes:
        #     x1, y1, x2, y2 = map(int, box)
        #     pos_y = y1 - 10 if y1 - 10 > 10 else y1 + 20
        #     text = f"{predicted_label} - none"
        #     cv2.putText(annotated_image, text, (x1, pos_y),
        #                 cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
        
        export_path = os.path.join(export_folder, os.path.basename(image_path))
        cv2.imwrite(export_path, annotated_image)
        print(f"Exported wrong prediction: {os.path.basename(image_path)}")

# ----------------- TỔNG KẾT -----------------
print("\n------------------ KẾT QUẢ ------------------")
print("Số ảnh đã xử lý:", len(image_files))
print("Số ảnh có dự đoán sai:", len(wrong_images_list))
print(f"Tổng TP: {global_TP}, Tổng FP: {global_FP}, Tổng FN: {global_FN}")

precision_overall = global_TP / (global_TP + global_FP) if (global_TP + global_FP) > 0 else 0
recall_overall = global_TP / (global_TP + global_FN) if (global_TP + global_FN) > 0 else 0
f1_overall = 2 * precision_overall * recall_overall / (precision_overall + recall_overall) if (precision_overall + recall_overall) > 0 else 0

print(f"Độ chính xác tổng thể (Precision): {precision_overall:.2f}")
print(f"Độ nhạy (Recall): {recall_overall:.2f}")
print(f"F1-score: {f1_overall:.2f}")






import os                     # Thư viện thao tác với hệ thống file
import cv2                    # Thư viện xử lý ảnh
import numpy as np            # Thư viện xử lý số liệu
from ultralytics import YOLO   # Import mô hình YOLO từ ultralytics
import supervision as sv      # Thư viện hỗ trợ giám sát (nếu cần)
import json                   # Thư viện xử lý JSON
import shutil                 # Thư viện hỗ trợ sao chép file, di chuyển file,...
from datetime import datetime # Thư viện làm việc với thời gian

# ----------------- CẤU HÌNH ĐƯỜNG DẪN -----------------
# Đường dẫn đến file mô hình đã huấn luyện
model_path = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/StaticModels/yolov12s10032025_ver-dataset2/_ver1/runs/detect/train/weights/best.pt"
# Đường dẫn đến thư mục chứa dữ liệu (ảnh và file nhãn ground truth)
data_path = "/home/minhnv/Documents/ntt/AiIot/FinalPorject/CodingYOLOv12/Dataset/Student-Behavior-Recognition-2/test"

# Đường dẫn đến thư mục chứa ảnh và nhãn
image_dir = os.path.join(data_path, "images")
gt_dir = os.path.join(data_path, "labels")

# Tạo thư mục xuất ảnh có dự đoán sai với tên dựa trên thời gian hiện tại
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
export_base_folder = f"wrong_predictions_{timestamp}"
os.makedirs(export_base_folder, exist_ok=True)

# Tạo các thư mục con cho từng loại lỗi: false positives, false negatives, class errors
false_positive_dir = os.path.join(export_base_folder, "false_positives")
false_negative_dir = os.path.join(export_base_folder, "false_negatives")
class_error_dir = os.path.join(export_base_folder, "class_errors")

for dir_path in [false_positive_dir, false_negative_dir, class_error_dir]:
    os.makedirs(dir_path, exist_ok=True)

# ----------------- HÀM HỖ TRỢ -----------------
def convert_yolo_to_xyxy(yolo_box, img_width, img_height):
    """
    Chuyển đổi bounding box từ định dạng YOLO (x_center, y_center, width, height)
    sang định dạng (x1, y1, x2, y2) theo kích thước ảnh.
    """
    x_center, y_center, width, height = yolo_box  # Lấy giá trị tọa độ trung tâm và kích thước box
    x1 = int((x_center - width/2) * img_width)      # Tính x1
    y1 = int((y_center - height/2) * img_height)      # Tính y1
    x2 = int((x_center + width/2) * img_width)        # Tính x2
    y2 = int((y_center + height/2) * img_height)        # Tính y2
    return [x1, y1, x2, y2]

def compute_iou(box1, box2):
    """
    Tính Intersection over Union (IoU) giữa hai bounding box theo định dạng [x1, y1, x2, y2].
    """
    x_left = max(box1[0], box2[0])   # Tọa độ x của điểm giao nhau bên trái
    y_top = max(box1[1], box2[1])    # Tọa độ y của điểm giao nhau phía trên
    x_right = min(box1[2], box2[2])  # Tọa độ x của điểm giao nhau bên phải
    y_bottom = min(box1[3], box2[3]) # Tọa độ y của điểm giao nhau phía dưới
    
    # Nếu không có giao nhau, trả về IoU = 0
    if x_right < x_left or y_bottom < y_top:
        return 0.0

    # Tính diện tích giao nhau
    intersection_area = (x_right - x_left) * (y_bottom - y_top)
    # Tính diện tích của từng box
    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])
    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])
    
    # Tính IoU = diện tích giao nhau / (diện tích hợp của 2 box)
    iou = intersection_area / float(box1_area + box2_area - intersection_area)
    return iou

def parse_ground_truth(gt_file, img_width, img_height):
    """
    Đọc file annotation định dạng YOLO và trả về danh sách bounding box cùng với class id.
    """
    boxes = []      # Danh sách các box (dưới dạng [x1, y1, x2, y2])
    class_ids = []  # Danh sách class id tương ứng với các box
    if not os.path.exists(gt_file):
        return boxes, class_ids  # Nếu file không tồn tại thì trả về danh sách rỗng
    
    with open(gt_file, 'r') as f:
        for line in f.readlines():
            parts = line.strip().split()  # Tách các giá trị trong dòng
            if len(parts) != 5:           # Nếu không đủ 5 giá trị thì bỏ qua dòng này
                continue
                
            class_id, x_center, y_center, width, height = map(float, parts)
            class_ids.append(int(class_id))
            
            # Chuyển đổi từ định dạng YOLO sang [x1, y1, x2, y2]
            box = convert_yolo_to_xyxy([x_center, y_center, width, height], img_width, img_height)
            boxes.append(box)
            
    return boxes, class_ids

def draw_box(image, box, color, label=None, thickness=2):
    """
    Vẽ bounding box lên ảnh và thêm label nếu có.
    """
    x1, y1, x2, y2 = map(int, box)
    cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)  # Vẽ hình chữ nhật
    
    if label:
        # Tính kích thước chữ để tạo nền cho label
        text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]
        # Vẽ nền cho label (hộp chữ)
        cv2.rectangle(image, (x1, y1 - text_size[1] - 10), (x1 + text_size[0], y1), color, -1)
        # Vẽ chữ label lên ảnh
        cv2.putText(image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

# ----------------- KHỞI TẠO MÔ HÌNH -----------------
model = YOLO(model_path)  # Khởi tạo mô hình YOLO với file weights đã cho
iou_threshold = 0.5       # Ngưỡng IoU để xác định true positive

# Lấy danh sách tên lớp từ mô hình (nếu có)
class_names = model.names if hasattr(model, "names") else {}

# ----------------- BIẾN THỐNG KÊ -----------------
stats = {
    "total_images": 0,         # Tổng số ảnh đã xử lý
    "wrong_images": 0,         # Số ảnh có lỗi
    "total_objects": 0,        # Tổng số đối tượng ground truth
    "false_positives": 0,      # Số dự đoán thừa
    "false_negatives": 0,      # Số đối tượng bỏ sót
    "class_errors": 0,         # Số lỗi nhận dạng sai lớp
    "class_error_details": {}, # Thống kê chi tiết lỗi nhận dạng (ví dụ: "class A -> class B")
    "error_by_class": {}       # Thống kê lỗi theo từng lớp đối tượng
}

# ----------------- XỬ LÝ ẢNH -----------------
# Lấy danh sách file ảnh từ thư mục
image_files = [f for f in os.listdir(image_dir) if f.lower().endswith((".jpg", ".jpeg", ".png"))]
error_details = []  # Danh sách lưu chi tiết lỗi cho mỗi ảnh

# Lặp qua từng ảnh
for image_file in image_files:
    stats["total_images"] += 1  # Cập nhật số ảnh đã xử lý
    
    # Đọc ảnh từ file
    image_path = os.path.join(image_dir, image_file)
    image = cv2.imread(image_path)
    if image is None:
        print(f"Không đọc được ảnh: {image_path}")
        continue  # Bỏ qua ảnh nếu không đọc được
    
    img_height, img_width = image.shape[:2]  # Lấy kích thước ảnh
    
    # Đọc file ground truth tương ứng với ảnh
    base_filename = os.path.splitext(image_file)[0]
    gt_file = os.path.join(gt_dir, base_filename + ".txt")
    gt_boxes, gt_class_ids = parse_ground_truth(gt_file, img_width, img_height)
    
    stats["total_objects"] += len(gt_boxes)  # Cập nhật số đối tượng ground truth
    
    # Chạy mô hình YOLO trên ảnh
    results = model(image, verbose=False)[0]
    
    # Lấy kết quả dự đoán từ mô hình
    pred_boxes = []        # Danh sách các bounding box dự đoán
    pred_class_ids = []    # Danh sách class id dự đoán
    pred_conf_scores = []  # Danh sách độ tin cậy dự đoán
    
    if len(results.boxes) > 0:
        for box in results.boxes:
            pred_boxes.append(box.xyxy[0].cpu().numpy())  # Chuyển box về dạng numpy array
            pred_class_ids.append(int(box.cls.cpu().numpy()[0]))
            pred_conf_scores.append(float(box.conf.cpu().numpy()[0]))
    
    # Khởi tạo danh sách lưu các lỗi cho ảnh này
    false_positives = []  # Lỗi dự đoán thừa (FP)
    false_negatives = []  # Lỗi bỏ sót (FN)
    class_errors = []     # Lỗi nhận dạng sai lớp (CE)
    
    # Tạo bản sao ảnh để vẽ lỗi
    annotated_image = image.copy()
    has_error = False  # Cờ đánh dấu có lỗi trong ảnh này hay không
    
    # Tạo danh sách đánh dấu các đối tượng đã được ghép (matched) giữa ground truth và dự đoán
    matched_gt = [False] * len(gt_boxes)
    matched_pred = [False] * len(pred_boxes)
    
    # --------- Bước 1: Xử lý true positive và class error ---------
    for pred_idx, pred_box in enumerate(pred_boxes):
        best_iou = 0
        best_gt_idx = -1
        
        # Tìm ground truth box có IoU lớn nhất với dự đoán hiện tại
        for gt_idx, gt_box in enumerate(gt_boxes):
            iou = compute_iou(pred_box, gt_box)
            if iou > best_iou:
                best_iou = iou
                best_gt_idx = gt_idx
        
        # Nếu IoU vượt ngưỡng, coi như dự đoán trùng khớp vị trí
        if best_iou >= iou_threshold:
            matched_pred[pred_idx] = True
            matched_gt[best_gt_idx] = True
            
            # Kiểm tra lỗi nhận dạng sai lớp (class error)
            if pred_class_ids[pred_idx] != gt_class_ids[best_gt_idx]:
                has_error = True
                stats["class_errors"] += 1  # Cập nhật thống kê lỗi class
                
                # Lấy tên lớp của ground truth và dự đoán
                gt_class = class_names.get(gt_class_ids[best_gt_idx], str(gt_class_ids[best_gt_idx]))
                pred_class = class_names.get(pred_class_ids[pred_idx], str(pred_class_ids[pred_idx]))
                error_key = f"{gt_class} -> {pred_class}"  # Tạo key cho thống kê lỗi chi tiết
                
                # Cập nhật thống kê chi tiết lỗi nhận dạng
                if error_key not in stats["class_error_details"]:
                    stats["class_error_details"][error_key] = 0
                stats["class_error_details"][error_key] += 1
                
                # Cập nhật thống kê lỗi theo lớp: đảm bảo khởi tạo đầy đủ các key
                if gt_class not in stats["error_by_class"]:
                    stats["error_by_class"][gt_class] = {
                        "total": 0,
                        "false_positives": 0,
                        "false_negatives": 0,
                        "class_errors": 0
                    }
                stats["error_by_class"][gt_class]["total"] += 1
                stats["error_by_class"][gt_class]["class_errors"] += 1
                
                # Lưu thông tin lỗi class cho ảnh hiện tại
                class_errors.append((
                    pred_box,
                    gt_class_ids[best_gt_idx],
                    pred_class_ids[pred_idx],
                    pred_conf_scores[pred_idx]
                ))
                
                # Vẽ box lỗi class lên ảnh (màu cam) kèm nhãn lỗi
                gt_class_name = class_names.get(gt_class_ids[best_gt_idx], f"class_{gt_class_ids[best_gt_idx]}")
                pred_class_name = class_names.get(pred_class_ids[pred_idx], f"class_{pred_class_ids[pred_idx]}")
                label = f"Lỗi: {gt_class_name} -> {pred_class_name} ({pred_conf_scores[pred_idx]:.2f})"
                draw_box(annotated_image, pred_box, (0, 165, 255), label)
    
    # --------- Bước 2: Xác định false positives (dự đoán thừa) ---------
    for pred_idx, matched in enumerate(matched_pred):
        if not matched:  # Nếu dự đoán không được ghép với bất kỳ ground truth nào
            has_error = True
            stats["false_positives"] += 1
            
            pred_class = class_names.get(pred_class_ids[pred_idx], str(pred_class_ids[pred_idx]))
            # Đảm bảo khởi tạo đầy đủ các key cho lớp dự đoán
            if pred_class not in stats["error_by_class"]:
                stats["error_by_class"][pred_class] = {
                    "total": 0,
                    "false_positives": 0,
                    "false_negatives": 0,
                    "class_errors": 0
                }
            stats["error_by_class"][pred_class]["false_positives"] += 1
            
            # Lưu thông tin false positive cho ảnh hiện tại
            false_positives.append((
                pred_boxes[pred_idx],
                pred_class_ids[pred_idx],
                pred_conf_scores[pred_idx]
            ))
            
            # Vẽ box false positive lên ảnh (màu đỏ) kèm nhãn
            pred_class_name = class_names.get(pred_class_ids[pred_idx], f"class_{pred_class_ids[pred_idx]}")
            label = f"FP: {pred_class_name} ({pred_conf_scores[pred_idx]:.2f})"
            draw_box(annotated_image, pred_boxes[pred_idx], (0, 0, 255), label)
    
    # --------- Bước 3: Xác định false negatives (bỏ sót đối tượng) ---------
    for gt_idx, matched in enumerate(matched_gt):
        if not matched:  # Nếu ground truth không được ghép với dự đoán nào
            has_error = True
            stats["false_negatives"] += 1
            
            gt_class = class_names.get(gt_class_ids[gt_idx], str(gt_class_ids[gt_idx]))
            # Đảm bảo khởi tạo đầy đủ các key cho lớp ground truth
            if gt_class not in stats["error_by_class"]:
                stats["error_by_class"][gt_class] = {
                    "total": 0,
                    "false_positives": 0,
                    "false_negatives": 0,
                    "class_errors": 0
                }
            stats["error_by_class"][gt_class]["total"] += 1
            stats["error_by_class"][gt_class]["false_negatives"] += 1
            
            # Lưu thông tin false negative cho ảnh hiện tại
            false_negatives.append((
                gt_boxes[gt_idx],
                gt_class_ids[gt_idx]
            ))
            
            # Vẽ box false negative lên ảnh (màu xanh lá) kèm nhãn
            gt_class_name = class_names.get(gt_class_ids[gt_idx], f"class_{gt_class_ids[gt_idx]}")
            label = f"FN: {gt_class_name}"
            draw_box(annotated_image, gt_boxes[gt_idx], (0, 255, 0), label)
    
    # --------- Xuất ảnh lỗi nếu có bất kỳ lỗi nào ---------
    if has_error:
        stats["wrong_images"] += 1
        
        # Lưu chi tiết lỗi của ảnh vào danh sách error_details
        image_error = {
            "image": image_file,
            "false_positives": len(false_positives),
            "false_negatives": len(false_negatives),
            "class_errors": len(class_errors),
            "details": {
                "false_positives": [
                    {
                        "box": box.tolist(),
                        "class": class_names.get(class_id, str(class_id)),
                        "confidence": conf
                    }
                    for box, class_id, conf in false_positives
                ],
                "false_negatives": [
                    {
                        "box": box,
                        "class": class_names.get(class_id, str(class_id))
                    }
                    for box, class_id in false_negatives
                ],
                "class_errors": [
                    {
                        "box": box.tolist(),
                        "gt_class": class_names.get(gt_class_id, str(gt_class_id)),
                        "pred_class": class_names.get(pred_class_id, str(pred_class_id)),
                        "confidence": conf
                    }
                    for box, gt_class_id, pred_class_id, conf in class_errors
                ]
            }
        }
        error_details.append(image_error)
        
        # Ghi tổng số lỗi lên ảnh
        cv2.putText(
            annotated_image,
            f"FP: {len(false_positives)}, FN: {len(false_negatives)}, CE: {len(class_errors)}",
            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2
        )
        
        # Lưu ảnh có lỗi vào các thư mục tương ứng
        if len(false_positives) > 0:
            fp_path = os.path.join(false_positive_dir, image_file)
            cv2.imwrite(fp_path, annotated_image)
            
        if len(false_negatives) > 0:
            fn_path = os.path.join(false_negative_dir, image_file)
            cv2.imwrite(fn_path, annotated_image)
            
        if len(class_errors) > 0:
            ce_path = os.path.join(class_error_dir, image_file)
            cv2.imwrite(ce_path, annotated_image)
            
        # Lưu ảnh lỗi vào thư mục gốc để dễ quản lý
        all_errors_path = os.path.join(export_base_folder, image_file)
        cv2.imwrite(all_errors_path, annotated_image)
        
        print(f"Đã xử lý ảnh {image_file}: FP={len(false_positives)}, FN={len(false_negatives)}, CE={len(class_errors)}")

# ----------------- TẠO BÁO CÁO -----------------
# Tính toán các chỉ số precision, recall và f1-score
precision = 0 if (stats["total_objects"] - stats["false_negatives"] + stats["false_positives"]) == 0 else \
           (stats["total_objects"] - stats["false_negatives"]) / (stats["total_objects"] - stats["false_negatives"] + stats["false_positives"])
           
recall = 0 if stats["total_objects"] == 0 else \
         (stats["total_objects"] - stats["false_negatives"]) / stats["total_objects"]
         
f1_score = 0 if (precision + recall) == 0 else 2 * precision * recall / (precision + recall)

# Tạo báo cáo tổng hợp dạng JSON
report = {
    "summary": {
        "total_images": stats["total_images"],
        "wrong_images": stats["wrong_images"],
        "total_objects": stats["total_objects"],
        "false_positives": stats["false_positives"],
        "false_negatives": stats["false_negatives"],
        "class_errors": stats["class_errors"],
        "precision": precision,
        "recall": recall,
        "f1_score": f1_score
    },
    "class_error_details": stats["class_error_details"],
    "error_by_class": stats["error_by_class"],
    "image_errors": error_details
}

# Lưu báo cáo dạng JSON vào file
report_path = os.path.join(export_base_folder, "error_report.json")
with open(report_path, "w", encoding="utf-8") as f:
    json.dump(report, f, indent=2, ensure_ascii=False)

# Tạo báo cáo dạng text và lưu vào file
report_txt_path = os.path.join(export_base_folder, "error_report.txt")
with open(report_txt_path, "w", encoding="utf-8") as f:
    f.write("=== BÁO CÁO LỖI DỰ ĐOÁN ===\n\n")
    f.write(f"Tổng số ảnh đã xử lý: {stats['total_images']}\n")
    f.write(f"Số ảnh có dự đoán sai: {stats['wrong_images']} ({stats['wrong_images']/stats['total_images']*100:.2f}%)\n")
    f.write(f"Tổng số đối tượng ground truth: {stats['total_objects']}\n")
    f.write(f"Số false positives (dự đoán thừa): {stats['false_positives']}\n")
    f.write(f"Số false negatives (bỏ sót): {stats['false_negatives']}\n")
    f.write(f"Số class errors (nhận dạng sai lớp): {stats['class_errors']}\n\n")
    
    f.write(f"Precision: {precision:.4f}\n")
    f.write(f"Recall: {recall:.4f}\n")
    f.write(f"F1-score: {f1_score:.4f}\n\n")
    
    f.write("=== CHI TIẾT LỖI NHẬN DẠNG LỚP ===\n\n")
    for error_key, count in sorted(stats["class_error_details"].items(), key=lambda x: x[1], reverse=True):
        f.write(f"{error_key}: {count}\n")
    
    f.write("\n=== THỐNG KÊ LỖI THEO LỚP ĐỐI TƯỢNG ===\n\n")
    for class_name, errors in sorted(stats["error_by_class"].items()):
        total_errors = errors.get("false_positives", 0) + errors.get("false_negatives", 0) + errors.get("class_errors", 0)
        f.write(f"Lớp '{class_name}': {total_errors} lỗi\n")
        if "false_positives" in errors:
            f.write(f"  - False positives: {errors['false_positives']}\n")
        if "false_negatives" in errors:
            f.write(f"  - False negatives: {errors['false_negatives']}\n")
        if "class_errors" in errors:
            f.write(f"  - Class errors: {errors['class_errors']}\n")
        f.write("\n")

# In kết quả tổng quan ra màn hình console
print(f"\n=== KẾT QUẢ ===")
print(f"Đã xử lý {stats['total_images']} ảnh, tìm thấy {stats['wrong_images']} ảnh có dự đoán sai")
print(f"False positives: {stats['false_positives']}, False negatives: {stats['false_negatives']}, Class errors: {stats['class_errors']}")
print(f"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1_score:.4f}")
print(f"Các ảnh có lỗi đã được lưu vào: {export_base_folder}")
print(f"Báo cáo chi tiết đã được lưu vào: {report_path}")

